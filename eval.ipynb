{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Running on host:  submit-1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# BOILER PLATE, MUST BE RUN ON SUBMIT NODE\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import socket\n",
    "print(\"Running on host: \", socket.gethostname())\n",
    "\n",
    "import sys \n",
    "lib_path = '/fsx_0/user/tranx/experiments'\n",
    "if lib_path not in sys.path:\n",
    "    sys.path.append(lib_path)\n",
    "#=================================================\n",
    "    \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "import time\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from lib import eval_helper\n",
    "from lib import utils\n",
    "from lib import slurm\n",
    "from lib.slurm import run_sbatch_job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch --parsable --job-name=eval_vqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_vqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch vqa 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9675"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"eval_plan\": \"Llama31_336px\",\n",
    "    \"json_config\": \"/fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_vqa.json\",\n",
    "    \"checkpoint_dir\": \"/fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch\",\n",
    "    \"benchmark_name\": \"vqa\",\n",
    "    \"checkpoint_id\": \"2000\"\n",
    "}\n",
    "\n",
    "job = run_job(\n",
    "    sbatch_base_script=\"/fsx_0/user/tranx/experiments/eval/sbash_eval.sh\",\n",
    "    sbatch_overwrite={\n",
    "        \"job-name\": \"eval_\" + params[\"benchmark_name\"]\n",
    "    },\n",
    "    positional_env_vars=list(params.values())\n",
    ")\n",
    "\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch --parsable --job-name=eval_mmmu /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmmu.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmmu 2000\n",
      "sbatch --parsable --job-name=eval_mmmu /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmmu.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmmu 3000\n",
      "sbatch --parsable --job-name=eval_mmmu /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmmu.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmmu 4000\n",
      "sbatch --parsable --job-name=eval_mmmu /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmmu.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmmu 5000\n",
      "sbatch --parsable --job-name=eval_mmmu /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmmu.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmmu 6000\n",
      "sbatch --parsable --job-name=eval_mmmu /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmmu.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmmu 7000\n",
      "sbatch --parsable --job-name=eval_mmmu /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmmu.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmmu 8000\n",
      "sbatch --parsable --job-name=eval_docvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_docvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch docvqa 2000\n",
      "sbatch --parsable --job-name=eval_docvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_docvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch docvqa 3000\n",
      "sbatch --parsable --job-name=eval_docvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_docvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch docvqa 4000\n",
      "sbatch --parsable --job-name=eval_docvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_docvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch docvqa 5000\n",
      "sbatch --parsable --job-name=eval_docvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_docvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch docvqa 6000\n",
      "sbatch --parsable --job-name=eval_docvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_docvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch docvqa 7000\n",
      "sbatch --parsable --job-name=eval_docvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_docvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch docvqa 8000\n",
      "sbatch --parsable --job-name=eval_mathvista /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mathvista.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mathvista 2000\n",
      "sbatch --parsable --job-name=eval_mathvista /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mathvista.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mathvista 3000\n",
      "sbatch --parsable --job-name=eval_mathvista /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mathvista.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mathvista 4000\n",
      "sbatch --parsable --job-name=eval_mathvista /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mathvista.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mathvista 5000\n",
      "sbatch --parsable --job-name=eval_mathvista /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mathvista.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mathvista 6000\n",
      "sbatch --parsable --job-name=eval_mathvista /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mathvista.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mathvista 7000\n",
      "sbatch --parsable --job-name=eval_mathvista /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mathvista.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mathvista 8000\n",
      "sbatch --parsable --job-name=eval_ai2d /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_ai2d.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch ai2d 2000\n",
      "sbatch --parsable --job-name=eval_ai2d /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_ai2d.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch ai2d 3000\n",
      "sbatch --parsable --job-name=eval_ai2d /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_ai2d.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch ai2d 4000\n",
      "sbatch --parsable --job-name=eval_ai2d /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_ai2d.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch ai2d 5000\n",
      "sbatch --parsable --job-name=eval_ai2d /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_ai2d.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch ai2d 6000\n",
      "sbatch --parsable --job-name=eval_ai2d /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_ai2d.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch ai2d 7000\n",
      "sbatch --parsable --job-name=eval_ai2d /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_ai2d.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch ai2d 8000\n",
      "sbatch --parsable --job-name=eval_chartqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_chartqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch chartqa 2000\n",
      "sbatch --parsable --job-name=eval_chartqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_chartqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch chartqa 3000\n",
      "sbatch --parsable --job-name=eval_chartqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_chartqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch chartqa 4000\n",
      "sbatch --parsable --job-name=eval_chartqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_chartqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch chartqa 5000\n",
      "sbatch --parsable --job-name=eval_chartqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_chartqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch chartqa 6000\n",
      "sbatch --parsable --job-name=eval_chartqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_chartqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch chartqa 7000\n",
      "sbatch --parsable --job-name=eval_chartqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_chartqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch chartqa 8000\n",
      "sbatch --parsable --job-name=eval_vqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_vqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch vqa 2000\n",
      "sbatch --parsable --job-name=eval_vqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_vqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch vqa 3000\n",
      "sbatch --parsable --job-name=eval_vqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_vqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch vqa 4000\n",
      "sbatch --parsable --job-name=eval_vqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_vqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch vqa 5000\n",
      "sbatch --parsable --job-name=eval_vqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_vqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch vqa 6000\n",
      "sbatch --parsable --job-name=eval_vqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_vqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch vqa 7000\n",
      "sbatch --parsable --job-name=eval_vqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_vqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch vqa 8000\n",
      "sbatch --parsable --job-name=eval_textvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_textvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch textvqa 2000\n",
      "sbatch --parsable --job-name=eval_textvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_textvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch textvqa 3000\n",
      "sbatch --parsable --job-name=eval_textvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_textvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch textvqa 4000\n",
      "sbatch --parsable --job-name=eval_textvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_textvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch textvqa 5000\n",
      "sbatch --parsable --job-name=eval_textvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_textvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch textvqa 6000\n",
      "sbatch --parsable --job-name=eval_textvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_textvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch textvqa 7000\n",
      "sbatch --parsable --job-name=eval_textvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_textvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch textvqa 8000\n",
      "sbatch --parsable --job-name=eval_infographics_w_ocr /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics_w_ocr.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics_w_ocr 2000\n",
      "sbatch --parsable --job-name=eval_infographics_w_ocr /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics_w_ocr.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics_w_ocr 3000\n",
      "sbatch --parsable --job-name=eval_infographics_w_ocr /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics_w_ocr.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics_w_ocr 4000\n",
      "sbatch --parsable --job-name=eval_infographics_w_ocr /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics_w_ocr.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics_w_ocr 5000\n",
      "sbatch --parsable --job-name=eval_infographics_w_ocr /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics_w_ocr.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics_w_ocr 6000\n",
      "sbatch --parsable --job-name=eval_infographics_w_ocr /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics_w_ocr.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics_w_ocr 7000\n",
      "sbatch --parsable --job-name=eval_infographics_w_ocr /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics_w_ocr.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics_w_ocr 8000\n",
      "sbatch --parsable --job-name=eval_infographics /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics 2000\n",
      "sbatch --parsable --job-name=eval_infographics /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics 3000\n",
      "sbatch --parsable --job-name=eval_infographics /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics 4000\n",
      "sbatch --parsable --job-name=eval_infographics /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics 5000\n",
      "sbatch --parsable --job-name=eval_infographics /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics 6000\n",
      "sbatch --parsable --job-name=eval_infographics /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics 7000\n",
      "sbatch --parsable --job-name=eval_infographics /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics 8000\n",
      "sbatch --parsable --job-name=eval_mmbench /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmbench.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmbench 2000\n",
      "sbatch --parsable --job-name=eval_mmbench /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmbench.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmbench 3000\n",
      "sbatch --parsable --job-name=eval_mmbench /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmbench.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmbench 4000\n",
      "sbatch --parsable --job-name=eval_mmbench /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmbench.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmbench 5000\n",
      "sbatch --parsable --job-name=eval_mmbench /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmbench.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmbench 6000\n",
      "sbatch --parsable --job-name=eval_mmbench /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmbench.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmbench 7000\n",
      "sbatch --parsable --job-name=eval_mmbench /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_336px /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmbench.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmbench 8000\n"
     ]
    }
   ],
   "source": [
    "# Llama31\n",
    "EVAL_PLAN = \"Llama31_336px\"\n",
    "BASE_SCRIPT = \"/fsx_0/user/tranx/experiments/eval/sbash_eval.sh\"\n",
    "CONFIG_DIR_LLAMA31 = \"/fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31\"\n",
    "CHECKPOINT_DIR_LLAMA31 = \"/fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch\"\n",
    "\n",
    "all_benchmarks = \"mmmu docvqa mathvista ai2d chartqa vqa textvqa infographics_w_ocr infographics mmbench\"\n",
    "checkpoint_start = 2000\n",
    "checkpoint_end = 8000\n",
    "checkpoint_int = 1000\n",
    "\n",
    "job_dict = {}\n",
    "for benchmark in all_benchmarks.split():\n",
    "    job_dict[benchmark] = {}\n",
    "\n",
    "    for chk in range(checkpoint_start, checkpoint_end + checkpoint_int, checkpoint_int):\n",
    "        params = {\n",
    "            \"eval_plan\": EVAL_PLAN,\n",
    "            \"json_config\": f\"{CONFIG_DIR_LLAMA31}/eval_{benchmark}.json\",\n",
    "            \"checkpoint_dir\": CHECKPOINT_DIR_LLAMA31,\n",
    "            \"benchmark_name\": benchmark,\n",
    "            \"checkpoint_id\": str(chk)\n",
    "        }\n",
    "\n",
    "        assert os.path.exists(params[\"json_config\"])\n",
    "        assert os.path.exists(f\"{params['checkpoint_dir']}/checkpoint-{chk}\")\n",
    "\n",
    "        job_id = run_sbatch_job(\n",
    "            sbatch_base_script=BASE_SCRIPT,\n",
    "            sbatch_overwrite={\n",
    "                \"job-name\": f\"eval_{benchmark}\"\n",
    "            },\n",
    "            positional_env_vars=list(params.values())\n",
    "        )\n",
    "\n",
    "        job_dict[benchmark][chk] = int(job_id)\n",
    "\n",
    "with open(f'job_dict_{EVAL_PLAN}.json', 'w') as f:\n",
    "    json.dump(job_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m checkpoints \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m8500\u001b[39m, \u001b[38;5;241m9000\u001b[39m, \u001b[38;5;241m9500\u001b[39m]\n\u001b[1;32m      5\u001b[0m job_dict_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_dict_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEVAL_PLAN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(job_dict_json)\n\u001b[1;32m      8\u001b[0m BASE_SCRIPT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/fsx_0/user/tranx/experiments/eval/sbash_eval.sh\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m CONFIG_DIR_LLAMA31 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Llama31\n",
    "EVAL_PLAN = \"Llama31_336px_8500_9500\"\n",
    "checkpoints = [8500, 9000, 9500]\n",
    "\n",
    "job_dict_json = f'job_dict_{EVAL_PLAN}.json'\n",
    "assert not os.path.exists(job_dict_json)\n",
    "\n",
    "BASE_SCRIPT = \"/fsx_0/user/tranx/experiments/eval/sbash_eval.sh\"\n",
    "CONFIG_DIR_LLAMA31 = \"/fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31\"\n",
    "CHECKPOINT_DIR_LLAMA31 = \"/fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch\"\n",
    "\n",
    "all_benchmarks = \"mmmu docvqa mathvista ai2d chartqa vqa textvqa infographics_w_ocr infographics mmbench\"\n",
    "\n",
    "job_dict = {}\n",
    "for benchmark in all_benchmarks.split():\n",
    "    job_dict[benchmark] = {}\n",
    "\n",
    "    for chk in checkpoints:\n",
    "        params = {\n",
    "            \"eval_plan\": EVAL_PLAN,\n",
    "            \"json_config\": f\"{CONFIG_DIR_LLAMA31}/eval_{benchmark}.json\",\n",
    "            \"checkpoint_dir\": CHECKPOINT_DIR_LLAMA31,\n",
    "            \"benchmark_name\": benchmark,\n",
    "            \"checkpoint_id\": str(chk)\n",
    "        }\n",
    "\n",
    "        assert os.path.exists(params[\"json_config\"])\n",
    "        assert os.path.exists(f\"{params['checkpoint_dir']}/checkpoint-{chk}\")\n",
    "\n",
    "        job_id = run_job(\n",
    "            sbatch_base_script=BASE_SCRIPT,\n",
    "            sbatch_overwrite={\n",
    "                \"job-name\": f\"eval_{benchmark}\"\n",
    "            },\n",
    "            positional_env_vars=list(params.values())\n",
    "        )\n",
    "\n",
    "        job_dict[benchmark][chk] = int(job_id)\n",
    "\n",
    "with open(job_dict_json, 'w') as f:\n",
    "    json.dump(job_dict, f, indent=4)\n",
    "\n",
    "print(f\"Saved job_dict to {job_dict_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mmmu': {2000: 9759,\n",
       "  3000: 9760,\n",
       "  4000: 9761,\n",
       "  5000: 9762,\n",
       "  6000: 9763,\n",
       "  7000: 9764,\n",
       "  8000: 9765},\n",
       " 'docvqa': {2000: 9766,\n",
       "  3000: 9767,\n",
       "  4000: 9768,\n",
       "  5000: 9769,\n",
       "  6000: 9770,\n",
       "  7000: 9771,\n",
       "  8000: 9772},\n",
       " 'mathvista': {2000: 9773,\n",
       "  3000: 9774,\n",
       "  4000: 9775,\n",
       "  5000: 9776,\n",
       "  6000: 9777,\n",
       "  7000: 9778,\n",
       "  8000: 9779},\n",
       " 'ai2d': {2000: 9780,\n",
       "  3000: 9781,\n",
       "  4000: 9782,\n",
       "  5000: 9783,\n",
       "  6000: 9784,\n",
       "  7000: 9785,\n",
       "  8000: 9786},\n",
       " 'chartqa': {2000: 9787,\n",
       "  3000: 9788,\n",
       "  4000: 9789,\n",
       "  5000: 9790,\n",
       "  6000: 9791,\n",
       "  7000: 9792,\n",
       "  8000: 9793},\n",
       " 'vqa': {2000: 9794,\n",
       "  3000: 9795,\n",
       "  4000: 9796,\n",
       "  5000: 9797,\n",
       "  6000: 9798,\n",
       "  7000: 9799,\n",
       "  8000: 9800},\n",
       " 'textvqa': {2000: 9801,\n",
       "  3000: 9802,\n",
       "  4000: 9803,\n",
       "  5000: 9804,\n",
       "  6000: 9805,\n",
       "  7000: 9806,\n",
       "  8000: 9807},\n",
       " 'infographics_w_ocr': {2000: 9808,\n",
       "  3000: 9809,\n",
       "  4000: 9810,\n",
       "  5000: 9811,\n",
       "  6000: 9812,\n",
       "  7000: 9813,\n",
       "  8000: 9814},\n",
       " 'infographics': {2000: 9815,\n",
       "  3000: 9816,\n",
       "  4000: 9817,\n",
       "  5000: 9818,\n",
       "  6000: 9819,\n",
       "  7000: 9820,\n",
       "  8000: 9821},\n",
       " 'mmbench': {2000: 9822,\n",
       "  3000: 9823,\n",
       "  4000: 9824,\n",
       "  5000: 9825,\n",
       "  6000: 9826,\n",
       "  7000: 9827,\n",
       "  8000: 9828}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama31 - 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch --parsable --job-name=eval_mmmu /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_10k /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmmu.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmmu 10000\n",
      "sbatch --parsable --job-name=eval_docvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_10k /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_docvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch docvqa 10000\n",
      "sbatch --parsable --job-name=eval_mathvista /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_10k /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mathvista.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mathvista 10000\n",
      "sbatch --parsable --job-name=eval_ai2d /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_10k /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_ai2d.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch ai2d 10000\n",
      "sbatch --parsable --job-name=eval_chartqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_10k /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_chartqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch chartqa 10000\n",
      "sbatch --parsable --job-name=eval_vqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_10k /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_vqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch vqa 10000\n",
      "sbatch --parsable --job-name=eval_textvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_10k /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_textvqa.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch textvqa 10000\n",
      "sbatch --parsable --job-name=eval_infographics_w_ocr /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_10k /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics_w_ocr.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics_w_ocr 10000\n",
      "sbatch --parsable --job-name=eval_infographics /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_10k /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch infographics 10000\n",
      "sbatch --parsable --job-name=eval_mmbench /fsx_0/user/tranx/experiments/eval/sbash_eval.sh Llama31_10k /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmbench.json /fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch mmbench 10000\n",
      "job_dict saved to job_dict_Llama31_10k.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mmmu': {10000: 10008},\n",
       " 'docvqa': {10000: 10009},\n",
       " 'mathvista': {10000: 10010},\n",
       " 'ai2d': {10000: 10011},\n",
       " 'chartqa': {10000: 10012},\n",
       " 'vqa': {10000: 10013},\n",
       " 'textvqa': {10000: 10014},\n",
       " 'infographics_w_ocr': {10000: 10015},\n",
       " 'infographics': {10000: 10016},\n",
       " 'mmbench': {10000: 10017}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_dict_lm31_10k = eval_helper.run_eval_plan(\n",
    "    eval_base_sbatch=\"/fsx_0/user/tranx/experiments/eval/sbash_eval.sh\",\n",
    "    eval_plan=\"Llama31_10k\",\n",
    "    eval_config_dir=\"/fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31\",\n",
    "    checkpoint_dir=\"/fsx_0/checkpoints/tranx/MM9-Pretrain-70B/Llama31_336px_128nodes_bz32_scratch\",\n",
    "    checkpoints=[10000],\n",
    "    # benchmarks=[\"mathvista\"]\n",
    ")\n",
    "\n",
    "job_dict_lm31_10k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama31 - fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch --parsable --job-name=eval_mmmu /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmmu.json /fsx_0/checkpoints/tranx/fb_llama3.1 mmmu 8000\n",
      "sbatch --parsable --job-name=eval_mmmu /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmmu.json /fsx_0/checkpoints/tranx/fb_llama3.1 mmmu 10000\n",
      "sbatch --parsable --job-name=eval_docvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_docvqa.json /fsx_0/checkpoints/tranx/fb_llama3.1 docvqa 8000\n",
      "sbatch --parsable --job-name=eval_docvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_docvqa.json /fsx_0/checkpoints/tranx/fb_llama3.1 docvqa 10000\n",
      "sbatch --parsable --job-name=eval_mathvista /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mathvista.json /fsx_0/checkpoints/tranx/fb_llama3.1 mathvista 8000\n",
      "sbatch --parsable --job-name=eval_mathvista /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mathvista.json /fsx_0/checkpoints/tranx/fb_llama3.1 mathvista 10000\n",
      "sbatch --parsable --job-name=eval_ai2d /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_ai2d.json /fsx_0/checkpoints/tranx/fb_llama3.1 ai2d 8000\n",
      "sbatch --parsable --job-name=eval_ai2d /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_ai2d.json /fsx_0/checkpoints/tranx/fb_llama3.1 ai2d 10000\n",
      "sbatch --parsable --job-name=eval_chartqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_chartqa.json /fsx_0/checkpoints/tranx/fb_llama3.1 chartqa 8000\n",
      "sbatch --parsable --job-name=eval_chartqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_chartqa.json /fsx_0/checkpoints/tranx/fb_llama3.1 chartqa 10000\n",
      "sbatch --parsable --job-name=eval_vqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_vqa.json /fsx_0/checkpoints/tranx/fb_llama3.1 vqa 8000\n",
      "sbatch --parsable --job-name=eval_vqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_vqa.json /fsx_0/checkpoints/tranx/fb_llama3.1 vqa 10000\n",
      "sbatch --parsable --job-name=eval_textvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_textvqa.json /fsx_0/checkpoints/tranx/fb_llama3.1 textvqa 8000\n",
      "sbatch --parsable --job-name=eval_textvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_textvqa.json /fsx_0/checkpoints/tranx/fb_llama3.1 textvqa 10000\n",
      "sbatch --parsable --job-name=eval_infographics_w_ocr /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics_w_ocr.json /fsx_0/checkpoints/tranx/fb_llama3.1 infographics_w_ocr 8000\n",
      "sbatch --parsable --job-name=eval_infographics_w_ocr /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics_w_ocr.json /fsx_0/checkpoints/tranx/fb_llama3.1 infographics_w_ocr 10000\n",
      "sbatch --parsable --job-name=eval_infographics /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics.json /fsx_0/checkpoints/tranx/fb_llama3.1 infographics 8000\n",
      "sbatch --parsable --job-name=eval_infographics /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_infographics.json /fsx_0/checkpoints/tranx/fb_llama3.1 infographics 10000\n",
      "sbatch --parsable --job-name=eval_mmbench /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmbench.json /fsx_0/checkpoints/tranx/fb_llama3.1 mmbench 8000\n",
      "sbatch --parsable --job-name=eval_mmbench /fsx_0/user/tranx/experiments/eval/sbash_eval.sh FBL_Llama31 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31/eval_mmbench.json /fsx_0/checkpoints/tranx/fb_llama3.1 mmbench 10000\n",
      "job_dict saved to job_dict_FBL_Llama31.json\n"
     ]
    }
   ],
   "source": [
    "job_dict_fb_lm31 = eval_helper.run_eval_plan(\n",
    "    eval_base_sbatch=\"/fsx_0/user/tranx/experiments/eval/sbash_eval.sh\",\n",
    "    eval_plan=\"FBL_Llama31\",\n",
    "    eval_config_dir=\"/fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval_31\",\n",
    "    checkpoint_dir=\"/fsx_0/checkpoints/tranx/fb_llama3.1\",\n",
    "    checkpoints=[8000, 10000],\n",
    "    # benchmarks=[\"mathvista\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MH19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10500, 11500, 12500, 13500, 14500, 15500, 16500, 17500, 18500]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoints = [10500 + i*1000 for i in range(9)]\n",
    "checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found existing job_dict: eval/logs/job_dict_MH19_10500_18500.json",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m job_dict_mh19 \u001b[38;5;241m=\u001b[39m \u001b[43meval_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_eval_plan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_base_sbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/fsx_0/user/tranx/experiments/eval/sbash_eval.sh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_plan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMH19_10500_18500\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_config_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/fsx_0/checkpoints/tranx/MM9-Pretrain-70B/MH19_336px_128nodes_bz32_resume\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10500\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# benchmarks=[\"mathvista\"]\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hpcaas/.mounts/fs-06bc3d6b93146dddd/user/tranx/experiments/eval_helper.py:41\u001b[0m, in \u001b[0;36mrun_eval_plan\u001b[0;34m(eval_base_sbatch, eval_plan, eval_config_dir, checkpoint_dir, checkpoints, benchmarks, rerun_if_exists)\u001b[0m\n\u001b[1;32m     39\u001b[0m job_dict_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval/logs/job_dict_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_plan\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(job_dict_json) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rerun_if_exists:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound existing job_dict: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_dict_json\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m benchmarks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     benchmarks \u001b[38;5;241m=\u001b[39m ALL_BENCHMARKS\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found existing job_dict: eval/logs/job_dict_MH19_10500_18500.json"
     ]
    }
   ],
   "source": [
    "job_dict_mh19 = eval_helper.run_eval_plan(\n",
    "    eval_base_sbatch=\"/fsx_0/user/tranx/experiments/eval/sbash_eval.sh\",\n",
    "    eval_plan=\"MH19_10500_18500\",\n",
    "    eval_config_dir=\"/fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval\",\n",
    "    checkpoint_dir=\"/fsx_0/checkpoints/tranx/MM9-Pretrain-70B/MH19_336px_128nodes_bz32_resume\",\n",
    "    checkpoints=[10500 + i*1000 for i in range(9)],\n",
    "    # benchmarks=[\"mathvista\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got result for mmmu - 10500\n",
      "Got result for mmmu - 11500\n",
      "Got result for mmmu - 12500\n",
      "Got result for mmmu - 13500\n",
      "Got result for mmmu - 14500\n",
      "Got result for mmmu - 15500\n",
      "Got result for mmmu - 16500\n",
      "Got result for mmmu - 17500\n",
      "Got result for mmmu - 18500\n",
      "Got result for docvqa - 10500\n",
      "Got result for docvqa - 11500\n",
      "Got result for docvqa - 12500\n",
      "Got result for docvqa - 13500\n",
      "Got result for docvqa - 14500\n",
      "Got result for docvqa - 15500\n",
      "Got result for docvqa - 16500\n",
      "Got result for docvqa - 17500\n",
      "Got result for docvqa - 18500\n",
      "Got result for mathvista - 10500\n",
      "Got result for mathvista - 11500\n",
      "Got result for mathvista - 12500\n",
      "Got result for mathvista - 13500\n",
      "Got result for mathvista - 14500\n",
      "Got result for mathvista - 15500\n",
      "Got result for mathvista - 16500\n",
      "Got result for mathvista - 17500\n",
      "Got result for mathvista - 18500\n",
      "Got result for ai2d - 10500\n",
      "Got result for ai2d - 11500\n",
      "Got result for ai2d - 12500\n",
      "Got result for ai2d - 13500\n",
      "Got result for ai2d - 14500\n",
      "Got result for ai2d - 15500\n",
      "Got result for ai2d - 16500\n",
      "Got result for ai2d - 17500\n",
      "Got result for ai2d - 18500\n",
      "Got result for chartqa - 10500\n",
      "Got result for chartqa - 11500\n",
      "Got result for chartqa - 12500\n",
      "Got result for chartqa - 13500\n",
      "Got result for chartqa - 14500\n",
      "Got result for chartqa - 15500\n",
      "Got result for chartqa - 16500\n",
      "Got result for chartqa - 17500\n",
      "Got result for chartqa - 18500\n",
      "Got result for vqa - 10500\n",
      "Got result for vqa - 11500\n",
      "Got result for vqa - 12500\n",
      "Got result for vqa - 13500\n",
      "Got result for vqa - 14500\n",
      "Got result for vqa - 15500\n",
      "Got result for vqa - 16500\n",
      "Got result for vqa - 17500\n",
      "Got result for vqa - 18500\n",
      "Got result for textvqa - 10500\n",
      "Got result for textvqa - 11500\n",
      "Got result for textvqa - 12500\n",
      "Got result for textvqa - 13500\n",
      "Got result for textvqa - 14500\n",
      "Got result for textvqa - 15500\n",
      "Got result for textvqa - 16500\n",
      "Got result for textvqa - 17500\n",
      "Got result for textvqa - 18500\n",
      "Got result for infographics_w_ocr - 10500\n",
      "Got result for infographics_w_ocr - 11500\n",
      "Got result for infographics_w_ocr - 12500\n",
      "Got result for infographics_w_ocr - 13500\n",
      "Got result for infographics_w_ocr - 14500\n",
      "Got result for infographics_w_ocr - 15500\n",
      "Got result for infographics_w_ocr - 16500\n",
      "Got result for infographics_w_ocr - 17500\n",
      "Got result for infographics_w_ocr - 18500\n",
      "Got result for infographics - 10500\n",
      "Got result for infographics - 11500\n",
      "Got result for infographics - 12500\n",
      "Got result for infographics - 13500\n",
      "Got result for infographics - 14500\n",
      "Got result for infographics - 15500\n",
      "Got result for infographics - 16500\n",
      "Got result for infographics - 17500\n",
      "Got result for infographics - 18500\n",
      "Got result for mmbench - 10500\n",
      "Got result for mmbench - 11500\n",
      "Got result for mmbench - 12500\n",
      "Got result for mmbench - 13500\n",
      "Got result for mmbench - 14500\n",
      "Got result for mmbench - 15500\n",
      "Got result for mmbench - 16500\n",
      "Got result for mmbench - 17500\n",
      "Got result for mmbench - 18500\n"
     ]
    }
   ],
   "source": [
    "df = eval_helper.get_eval_scores(job_dict_mh19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mmmu/accuracy                                    0.5878\n",
       "mmmu/mllm_eval_accuracy                          0.5889\n",
       "docvqa/anls_total_score                          0.6201\n",
       "docvqa/mllm_evaluation_anls_score                0.6216\n",
       "mathvista/accuracy                                0.377\n",
       "ai2d/accuracy                                    0.7704\n",
       "chartqa/accuracy                                 0.4914\n",
       "vqa/accuracy                                     0.7035\n",
       "vqa/mllm_evaluation_accuracy                     0.7256\n",
       "textvqa/accuracy                                 66.898\n",
       "textvqa/mllm_eval_accuracy                       71.578\n",
       "infographics_w_ocr/anls_total_score              0.6256\n",
       "infographics_w_ocr/mllm_evaluation_anls_score    0.5712\n",
       "infographics/anls_total_score                    0.4798\n",
       "infographics/mllm_evaluation_anls_score          0.4177\n",
       "mmbench/overall                                  0.7422\n",
       "Name: 17500, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[17500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m job_dict_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_dict_Llama31_336px_8500_9500.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(job_dict_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 5\u001b[0m     job_dict \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m eval_helper\u001b[38;5;241m.\u001b[39mget_eval_scores(job_dict)\n\u001b[1;32m      8\u001b[0m df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# job_dict_file = 'job_dict_Llama31_336px.json'\n",
    "job_dict_file = 'job_dict_Llama31_336px_8500_9500.json'\n",
    "\n",
    "with open(job_dict_file, 'r') as f:\n",
    "    job_dict = json.load(f)\n",
    "\n",
    "df = eval_helper.get_eval_scores(job_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got result for mmmu - 8000\n",
      "Got result for mmmu - 10000\n",
      "Got result for docvqa - 8000\n",
      "Got result for docvqa - 10000\n",
      "Got result for mathvista - 8000\n",
      "Got result for mathvista - 10000\n",
      "Got result for ai2d - 8000\n",
      "Got result for ai2d - 10000\n",
      "Got result for chartqa - 8000\n",
      "Got result for chartqa - 10000\n",
      "Got result for vqa - 8000\n",
      "Got result for vqa - 10000\n",
      "Got result for textvqa - 8000\n",
      "Got result for textvqa - 10000\n",
      "Got result for infographics_w_ocr - 8000\n",
      "Got result for infographics_w_ocr - 10000\n",
      "Got result for infographics - 8000\n",
      "Got result for infographics - 10000\n",
      "Got result for mmbench - 8000\n",
      "Got result for mmbench - 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmmu/accuracy</th>\n",
       "      <th>mmmu/mllm_eval_accuracy</th>\n",
       "      <th>docvqa/anls_total_score</th>\n",
       "      <th>docvqa/mllm_evaluation_anls_score</th>\n",
       "      <th>mathvista/accuracy</th>\n",
       "      <th>ai2d/accuracy</th>\n",
       "      <th>chartqa/accuracy</th>\n",
       "      <th>vqa/accuracy</th>\n",
       "      <th>vqa/mllm_evaluation_accuracy</th>\n",
       "      <th>textvqa/accuracy</th>\n",
       "      <th>textvqa/mllm_eval_accuracy</th>\n",
       "      <th>infographics_w_ocr/anls_total_score</th>\n",
       "      <th>infographics_w_ocr/mllm_evaluation_anls_score</th>\n",
       "      <th>infographics/anls_total_score</th>\n",
       "      <th>infographics/mllm_evaluation_anls_score</th>\n",
       "      <th>mmbench/overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.5156</td>\n",
       "      <td>0.5386</td>\n",
       "      <td>0.5411</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>0.4746</td>\n",
       "      <td>0.6831</td>\n",
       "      <td>0.7137</td>\n",
       "      <td>59.028</td>\n",
       "      <td>65.38</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.4384</td>\n",
       "      <td>0.3746</td>\n",
       "      <td>0.6635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.4744</td>\n",
       "      <td>0.4822</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.5432</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.6953</td>\n",
       "      <td>0.4578</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.7224</td>\n",
       "      <td>59.414</td>\n",
       "      <td>65.708</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.5354</td>\n",
       "      <td>0.4472</td>\n",
       "      <td>0.3785</td>\n",
       "      <td>0.6772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mmmu/accuracy mmmu/mllm_eval_accuracy docvqa/anls_total_score  \\\n",
       "8000         0.5067                  0.5156                  0.5386   \n",
       "10000        0.4744                  0.4822                    0.54   \n",
       "\n",
       "      docvqa/mllm_evaluation_anls_score mathvista/accuracy ai2d/accuracy  \\\n",
       "8000                             0.5411              0.344        0.7121   \n",
       "10000                            0.5432              0.348        0.6953   \n",
       "\n",
       "      chartqa/accuracy vqa/accuracy vqa/mllm_evaluation_accuracy  \\\n",
       "8000            0.4746       0.6831                       0.7137   \n",
       "10000           0.4578       0.6931                       0.7224   \n",
       "\n",
       "      textvqa/accuracy textvqa/mllm_eval_accuracy  \\\n",
       "8000            59.028                      65.38   \n",
       "10000           59.414                     65.708   \n",
       "\n",
       "      infographics_w_ocr/anls_total_score  \\\n",
       "8000                               0.5902   \n",
       "10000                               0.592   \n",
       "\n",
       "      infographics_w_ocr/mllm_evaluation_anls_score  \\\n",
       "8000                                          0.536   \n",
       "10000                                        0.5354   \n",
       "\n",
       "      infographics/anls_total_score infographics/mllm_evaluation_anls_score  \\\n",
       "8000                         0.4384                                  0.3746   \n",
       "10000                        0.4472                                  0.3785   \n",
       "\n",
       "      mmbench/overall  \n",
       "8000           0.6635  \n",
       "10000          0.6772  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_dict_file = 'job_dict_FBL_Llama31.json'\n",
    "with open(job_dict_file, 'r') as f:\n",
    "    job_dict = json.load(f)\n",
    "\n",
    "df2 = eval_helper.get_eval_scores(job_dict)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200, 400, 600, 800, 1000]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoints = list(range(200, 1000 + 200, 200))\n",
    "# len(checkpoints) * len(eval_helper.ALL_BENCHMARKS)\n",
    "# checkpoints = [4800]\n",
    "checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch --parsable --job-name=eval_mmmu /fsx_0/user/tranx/experiments/eval/sbash_eval.sh stage2_MH19_336px_128nodes_exp_4800 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval/eval_mmmu.json /fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp mmmu 4800\n",
      "sbatch --parsable --job-name=eval_docvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh stage2_MH19_336px_128nodes_exp_4800 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval/eval_docvqa.json /fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp docvqa 4800\n",
      "sbatch --parsable --job-name=eval_mathvista /fsx_0/user/tranx/experiments/eval/sbash_eval.sh stage2_MH19_336px_128nodes_exp_4800 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval/eval_mathvista.json /fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp mathvista 4800\n",
      "sbatch --parsable --job-name=eval_ai2d /fsx_0/user/tranx/experiments/eval/sbash_eval.sh stage2_MH19_336px_128nodes_exp_4800 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval/eval_ai2d.json /fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp ai2d 4800\n",
      "sbatch --parsable --job-name=eval_chartqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh stage2_MH19_336px_128nodes_exp_4800 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval/eval_chartqa.json /fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp chartqa 4800\n",
      "sbatch --parsable --job-name=eval_vqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh stage2_MH19_336px_128nodes_exp_4800 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval/eval_vqa.json /fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp vqa 4800\n",
      "sbatch --parsable --job-name=eval_textvqa /fsx_0/user/tranx/experiments/eval/sbash_eval.sh stage2_MH19_336px_128nodes_exp_4800 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval/eval_textvqa.json /fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp textvqa 4800\n",
      "sbatch --parsable --job-name=eval_infographics_w_ocr /fsx_0/user/tranx/experiments/eval/sbash_eval.sh stage2_MH19_336px_128nodes_exp_4800 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval/eval_infographics_w_ocr.json /fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp infographics_w_ocr 4800\n",
      "sbatch --parsable --job-name=eval_infographics /fsx_0/user/tranx/experiments/eval/sbash_eval.sh stage2_MH19_336px_128nodes_exp_4800 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval/eval_infographics.json /fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp infographics 4800\n",
      "sbatch --parsable --job-name=eval_mmbench /fsx_0/user/tranx/experiments/eval/sbash_eval.sh stage2_MH19_336px_128nodes_exp_4800 /fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval/eval_mmbench.json /fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp mmbench 4800\n",
      "job_dict saved to eval/logs/job_dict_stage2_MH19_336px_128nodes_exp_4800.json\n"
     ]
    }
   ],
   "source": [
    "for c in checkpoints:\n",
    "    plan_dict = eval_helper.run_eval_plan(\n",
    "        eval_base_sbatch=\"/fsx_0/user/tranx/experiments/eval/sbash_eval.sh\",\n",
    "        # eval_plan=f\"stage2_MH19_336px_128nodes_exp_{c}\",\n",
    "        eval_plan=f\"stage2_MH19_336px_128nodes_exp28_{c}\",\n",
    "        eval_config_dir=\"/fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval\",\n",
    "        checkpoint_dir=\"/fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp28\",\n",
    "        checkpoints=[c],\n",
    "        rerun_if_exists=True\n",
    "    )\n",
    "\n",
    "# for c in checkpoints:\n",
    "#     plan_dict = eval_helper.run_eval_plan(\n",
    "#         eval_base_sbatch=\"/fsx_0/user/tranx/experiments/eval/sbash_eval.sh\",\n",
    "#         eval_plan=f\"stage2_MH19_336px_128nodes_exp_{c}\",\n",
    "#         eval_config_dir=\"/fsx_0/user/tranx/eval/llm_mm_aligner/experiments/aws_adel/eval\",\n",
    "#         checkpoint_dir=\"/fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp\",\n",
    "#         checkpoints=[c],\n",
    "#         rerun_if_exists=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200 eval/logs/job_dict_stage2_MH19_336px_128nodes_exp_3200.json\n",
      "Got result for mmmu - 3200: [('mmmu/accounting', 0.6333333333333333), ('mmmu/agriculture', 0.6), ('mmmu/architecture_and_engineering', 0.3333333333333333), ('mmmu/art', 0.6), ('mmmu/art_theory', 0.7666666666666667), ('mmmu/basic_medical_science', 0.7), ('mmmu/biology', 0.36666666666666664), ('mmmu/chemistry', 0.3333333333333333), ('mmmu/clinical_medicine', 0.6), ('mmmu/computer_science', 0.5666666666666667), ('mmmu/design', 0.7333333333333333), ('mmmu/diagnostics_and_laboratory_medicine', 0.36666666666666664), ('mmmu/economics', 0.6333333333333333), ('mmmu/electronics', 0.36666666666666664), ('mmmu/energy_and_power', 0.43333333333333335), ('mmmu/finance', 0.5), ('mmmu/geography', 0.5666666666666667), ('mmmu/history', 0.8), ('mmmu/literature', 0.8666666666666667), ('mmmu/manage', 0.5333333333333333), ('mmmu/marketing', 0.5666666666666667), ('mmmu/materials', 0.5), ('mmmu/math', 0.5666666666666667), ('mmmu/mechanical_engineering', 0.3333333333333333), ('mmmu/music', 0.3333333333333333), ('mmmu/pharmacy', 0.7666666666666667), ('mmmu/physics', 0.4666666666666667), ('mmmu/psychology', 0.7), ('mmmu/public_health', 0.6333333333333333), ('mmmu/sociology', 0.6666666666666666), ('mmmu/accuracy', 0.5611111111111111), ('mmmu/mllm_eval_accuracy', 0.5688888888888889)]\n",
      "Got result for docvqa - 3200: [('docvqa/anls_total_score', 0.6640880634124493), ('docvqa/mllm_evaluation_anls_score', 0.6634133266479652), ('docvqa/mmllm_fixed_anls_score', 0.7021403504963396)]\n",
      "Got result for mathvista - 3200: [('mathvista/accuracy', 0.379)]\n",
      "Got result for ai2d - 3200: [('ai2d/accuracy', 0.7908031088082902)]\n",
      "Got result for chartqa - 3200: [('chartqa/accuracy', 0.5030746512008956)]\n",
      "Got result for vqa - 3200: [('vqa/accuracy', 0.7282199999999778), ('vqa/recall', 0.7576399999999741), ('vqa/bleu', 0.023279016837477684), ('vqa/mllm_evaluation_accuracy', 0.7522039999999759)]\n",
      "Got result for textvqa - 3200: [('textvqa/accuracy', 69.40600000000035), ('textvqa/mllm_eval_accuracy', 74.03000000000036)]\n",
      "Got result for infographics_w_ocr - 3200: [('infographics_w_ocr/anls_total_score', 0.6429400579120222), ('infographics_w_ocr/mllm_evaluation_anls_score', 0.5884253631895616), ('infographics_w_ocr/answer_type_multi_span_score', 0.5402503683724129), ('infographics_w_ocr/answer_type_non_extractive_score', 0.6324377852406786), ('infographics_w_ocr/answer_type_question_span_score', 0.6962243921237135), ('infographics_w_ocr/answer_type_single_span_score', 0.6538366030276421), ('infographics_w_ocr/evidence_type_figure_score', 0.6214902776544455), ('infographics_w_ocr/evidence_type_map_score', 0.5762054364777137), ('infographics_w_ocr/evidence_type_table_list_score', 0.6436928996343314), ('infographics_w_ocr/evidence_type_text_score', 0.6936491906854457), ('infographics_w_ocr/evidence_type_visual_layout_score', 0.5767280602473487), ('infographics_w_ocr/reasoning_type_arithmetic_score', 0.6210779517286364), ('infographics_w_ocr/reasoning_type_comparison_score', 0.5125325401030927), ('infographics_w_ocr/reasoning_type_counting_score', 0.6277972027972027)]\n",
      "Got result for infographics - 3200: [('infographics/anls_total_score', 0.5442911927818022), ('infographics/mllm_evaluation_anls_score', 0.48164092110639845), ('infographics/answer_type_multi_span_score', 0.36575683119083485), ('infographics/answer_type_non_extractive_score', 0.5436266165018426), ('infographics/answer_type_question_span_score', 0.6816990879490878), ('infographics/answer_type_single_span_score', 0.5579889843295365), ('infographics/evidence_type_figure_score', 0.5314863415557626), ('infographics/evidence_type_map_score', 0.5370796835781139), ('infographics/evidence_type_table_list_score', 0.5050513875051371), ('infographics/evidence_type_text_score', 0.5819960900001305), ('infographics/evidence_type_visual_layout_score', 0.5087834108404902), ('infographics/reasoning_type_arithmetic_score', 0.5032837406125076), ('infographics/reasoning_type_comparison_score', 0.4798490257466455), ('infographics/reasoning_type_counting_score', 0.5682400932400932)]\n",
      "Got result for mmbench - 3200: [('mmbench/attribute_comparison', 0.5681818181818182), ('mmbench/attribute_recognition', 0.8450704225352113), ('mmbench/celebrity_recognition', 0.9191919191919192), ('mmbench/function_reasoning', 0.8481012658227848), ('mmbench/future_prediction', 0.6), ('mmbench/image_quality', 0.5853658536585366), ('mmbench/image_scene', 0.9519230769230769), ('mmbench/image_style', 0.9245283018867925), ('mmbench/image_topic', 0.8888888888888888), ('mmbench/nature_relation', 0.8125), ('mmbench/object_localization', 0.49382716049382713), ('mmbench/ocr', 0.7948717948717948), ('mmbench/physical_property_reasoning', 0.68), ('mmbench/physical_relation', 0.3333333333333333), ('mmbench/spatial_relationship', 0.4), ('mmbench/structuralized_imagetext_understanding', 0.6493506493506493), ('mmbench/overall', 0.7392020300278188)]\n",
      "3400 eval/logs/job_dict_stage2_MH19_336px_128nodes_exp_3400.json\n",
      "Got result for mmmu - 3400: [('mmmu/accounting', 0.36666666666666664), ('mmmu/agriculture', 0.5), ('mmmu/architecture_and_engineering', 0.5), ('mmmu/art', 0.6333333333333333), ('mmmu/art_theory', 0.7333333333333333), ('mmmu/basic_medical_science', 0.7), ('mmmu/biology', 0.36666666666666664), ('mmmu/chemistry', 0.4666666666666667), ('mmmu/clinical_medicine', 0.7), ('mmmu/computer_science', 0.7333333333333333), ('mmmu/design', 0.7333333333333333), ('mmmu/diagnostics_and_laboratory_medicine', 0.5), ('mmmu/economics', 0.5333333333333333), ('mmmu/electronics', 0.4), ('mmmu/energy_and_power', 0.4666666666666667), ('mmmu/finance', 0.5333333333333333), ('mmmu/geography', 0.5666666666666667), ('mmmu/history', 0.8), ('mmmu/literature', 0.8333333333333334), ('mmmu/manage', 0.5666666666666667), ('mmmu/marketing', 0.6666666666666666), ('mmmu/materials', 0.4666666666666667), ('mmmu/math', 0.36666666666666664), ('mmmu/mechanical_engineering', 0.3333333333333333), ('mmmu/music', 0.3333333333333333), ('mmmu/pharmacy', 0.7), ('mmmu/physics', 0.36666666666666664), ('mmmu/psychology', 0.6333333333333333), ('mmmu/public_health', 0.6333333333333333), ('mmmu/sociology', 0.7333333333333333), ('mmmu/accuracy', 0.5622222222222222), ('mmmu/mllm_eval_accuracy', 0.5766666666666667)]\n",
      "Got result for docvqa - 3400: [('docvqa/anls_total_score', 0.6662842594918789), ('docvqa/mllm_evaluation_anls_score', 0.6652847094750739), ('docvqa/mmllm_fixed_anls_score', 0.7038201111199454)]\n",
      "Got result for mathvista - 3400: [('mathvista/accuracy', 0.393)]\n",
      "Got result for ai2d - 3400: [('ai2d/accuracy', 0.7924222797927462)]\n",
      "Got result for chartqa - 3400: [('chartqa/accuracy', 0.5096414068533369)]\n",
      "Got result for vqa - 3400: [('vqa/accuracy', 0.7282879999999772), ('vqa/recall', 0.7565879999999746), ('vqa/bleu', 0.0), ('vqa/mllm_evaluation_accuracy', 0.7515359999999767)]\n",
      "Got result for textvqa - 3400: [('textvqa/accuracy', 68.54800000000031), ('textvqa/mllm_eval_accuracy', 73.23600000000035)]\n",
      "Got result for infographics_w_ocr - 3400: [('infographics_w_ocr/anls_total_score', 0.6471130009735296), ('infographics_w_ocr/mllm_evaluation_anls_score', 0.5970165747874483), ('infographics_w_ocr/answer_type_multi_span_score', 0.5277120512481788), ('infographics_w_ocr/answer_type_non_extractive_score', 0.6390618272625507), ('infographics_w_ocr/answer_type_question_span_score', 0.6982436569472379), ('infographics_w_ocr/answer_type_single_span_score', 0.659930244634008), ('infographics_w_ocr/evidence_type_figure_score', 0.6248130697058113), ('infographics_w_ocr/evidence_type_map_score', 0.5709190149784209), ('infographics_w_ocr/evidence_type_table_list_score', 0.6465013479258935), ('infographics_w_ocr/evidence_type_text_score', 0.6959895225650007), ('infographics_w_ocr/evidence_type_visual_layout_score', 0.5823225535681384), ('infographics_w_ocr/reasoning_type_arithmetic_score', 0.624204990215264), ('infographics_w_ocr/reasoning_type_comparison_score', 0.541245895871541), ('infographics_w_ocr/reasoning_type_counting_score', 0.6452797202797204)]\n",
      "Got result for infographics - 3400: [('infographics/anls_total_score', 0.5471520650683339), ('infographics/mllm_evaluation_anls_score', 0.4829317131228439), ('infographics/answer_type_multi_span_score', 0.4026163000965545), ('infographics/answer_type_non_extractive_score', 0.5401711609668212), ('infographics/answer_type_question_span_score', 0.7024932866279021), ('infographics/answer_type_single_span_score', 0.5578557144446681), ('infographics/evidence_type_figure_score', 0.5357241352483342), ('infographics/evidence_type_map_score', 0.49143320011514335), ('infographics/evidence_type_table_list_score', 0.5112195185734529), ('infographics/evidence_type_text_score', 0.5846294022832487), ('infographics/evidence_type_visual_layout_score', 0.5070947987109717), ('infographics/reasoning_type_arithmetic_score', 0.49051821466205014), ('infographics/reasoning_type_comparison_score', 0.48506441211224355), ('infographics/reasoning_type_counting_score', 0.580128205128205)]\n",
      "Got result for mmbench - 3400: [('mmbench/attribute_comparison', 0.5681818181818182), ('mmbench/attribute_recognition', 0.8309859154929577), ('mmbench/celebrity_recognition', 0.9595959595959596), ('mmbench/function_reasoning', 0.8481012658227848), ('mmbench/future_prediction', 0.6), ('mmbench/image_quality', 0.5853658536585366), ('mmbench/image_scene', 0.9615384615384616), ('mmbench/image_style', 0.9056603773584906), ('mmbench/image_topic', 0.8888888888888888), ('mmbench/nature_relation', 0.8333333333333334), ('mmbench/object_localization', 0.4567901234567901), ('mmbench/ocr', 0.8205128205128205), ('mmbench/physical_property_reasoning', 0.6533333333333333), ('mmbench/physical_relation', 0.4166666666666667), ('mmbench/spatial_relationship', 0.4), ('mmbench/structuralized_imagetext_understanding', 0.6753246753246753), ('mmbench/overall', 0.7446592804291632)]\n",
      "3600 eval/logs/job_dict_stage2_MH19_336px_128nodes_exp_3600.json\n",
      "Got result for mmmu - 3600: [('mmmu/accounting', 0.5), ('mmmu/agriculture', 0.5666666666666667), ('mmmu/architecture_and_engineering', 0.26666666666666666), ('mmmu/art', 0.6666666666666666), ('mmmu/art_theory', 0.8666666666666667), ('mmmu/basic_medical_science', 0.6), ('mmmu/biology', 0.3333333333333333), ('mmmu/chemistry', 0.4), ('mmmu/clinical_medicine', 0.6333333333333333), ('mmmu/computer_science', 0.4666666666666667), ('mmmu/design', 0.7333333333333333), ('mmmu/diagnostics_and_laboratory_medicine', 0.4666666666666667), ('mmmu/economics', 0.5666666666666667), ('mmmu/electronics', 0.4), ('mmmu/energy_and_power', 0.4666666666666667), ('mmmu/finance', 0.5333333333333333), ('mmmu/geography', 0.5333333333333333), ('mmmu/history', 0.8), ('mmmu/literature', 0.9), ('mmmu/manage', 0.4666666666666667), ('mmmu/marketing', 0.6), ('mmmu/materials', 0.36666666666666664), ('mmmu/math', 0.43333333333333335), ('mmmu/mechanical_engineering', 0.3333333333333333), ('mmmu/music', 0.3333333333333333), ('mmmu/pharmacy', 0.6666666666666666), ('mmmu/physics', 0.5), ('mmmu/psychology', 0.6), ('mmmu/public_health', 0.7), ('mmmu/sociology', 0.6666666666666666), ('mmmu/accuracy', 0.5455555555555556), ('mmmu/mllm_eval_accuracy', 0.5466666666666666)]\n",
      "Got result for docvqa - 3600: [('docvqa/anls_total_score', 0.6673320053456222), ('docvqa/mllm_evaluation_anls_score', 0.66831914101801), ('docvqa/mmllm_fixed_anls_score', 0.7068702981118987)]\n",
      "Got result for mathvista - 3600: [('mathvista/accuracy', 0.39)]\n",
      "Got result for ai2d - 3600: [('ai2d/accuracy', 0.8069948186528497)]\n",
      "Got result for chartqa - 3600: [('chartqa/accuracy', 0.5095766623262165)]\n",
      "Got result for vqa - 3600: [('vqa/accuracy', 0.7248559999999767), ('vqa/recall', 0.7542519999999742), ('vqa/bleu', 0.027971595525741577), ('vqa/mllm_evaluation_accuracy', 0.7488479999999759)]\n",
      "Got result for textvqa - 3600: [('textvqa/accuracy', 68.49600000000034), ('textvqa/mllm_eval_accuracy', 73.19000000000035)]\n",
      "Got result for infographics_w_ocr - 3600: [('infographics_w_ocr/anls_total_score', 0.6484489445356911), ('infographics_w_ocr/mllm_evaluation_anls_score', 0.5965838510927669), ('infographics_w_ocr/answer_type_multi_span_score', 0.5357902204494556), ('infographics_w_ocr/answer_type_non_extractive_score', 0.6404180659605616), ('infographics_w_ocr/answer_type_question_span_score', 0.7011794466477335), ('infographics_w_ocr/answer_type_single_span_score', 0.6604707771186143), ('infographics_w_ocr/evidence_type_figure_score', 0.6247968013105916), ('infographics_w_ocr/evidence_type_map_score', 0.5896708901659397), ('infographics_w_ocr/evidence_type_table_list_score', 0.6551548544784905), ('infographics_w_ocr/evidence_type_text_score', 0.6966182941099536), ('infographics_w_ocr/evidence_type_visual_layout_score', 0.5722394099010877), ('infographics_w_ocr/reasoning_type_arithmetic_score', 0.6259743966079581), ('infographics_w_ocr/reasoning_type_comparison_score', 0.5448196517831402), ('infographics_w_ocr/reasoning_type_counting_score', 0.6404428904428904)]\n",
      "Got result for infographics - 3600: [('infographics/anls_total_score', 0.5496827239760246), ('infographics/mllm_evaluation_anls_score', 0.4876385734970513), ('infographics/answer_type_multi_span_score', 0.3991648633927753), ('infographics/answer_type_non_extractive_score', 0.5463191118706491), ('infographics/answer_type_question_span_score', 0.6709304050650204), ('infographics/answer_type_single_span_score', 0.5620574935011181), ('infographics/evidence_type_figure_score', 0.5381051174079604), ('infographics/evidence_type_map_score', 0.5299723184988182), ('infographics/evidence_type_table_list_score', 0.5186647897424309), ('infographics/evidence_type_text_score', 0.5916394584698487), ('infographics/evidence_type_visual_layout_score', 0.4699430454156177), ('infographics/reasoning_type_arithmetic_score', 0.4979376787595964), ('infographics/reasoning_type_comparison_score', 0.49499427146429703), ('infographics/reasoning_type_counting_score', 0.5825174825174824)]\n",
      "Got result for mmbench - 3600: [('mmbench/attribute_comparison', 0.5681818181818182), ('mmbench/attribute_recognition', 0.8309859154929577), ('mmbench/celebrity_recognition', 0.9494949494949495), ('mmbench/function_reasoning', 0.8607594936708861), ('mmbench/future_prediction', 0.6), ('mmbench/image_quality', 0.5609756097560976), ('mmbench/image_scene', 0.9519230769230769), ('mmbench/image_style', 0.8867924528301887), ('mmbench/image_topic', 0.8888888888888888), ('mmbench/nature_relation', 0.7708333333333334), ('mmbench/object_localization', 0.4444444444444444), ('mmbench/ocr', 0.7948717948717948), ('mmbench/physical_property_reasoning', 0.6533333333333333), ('mmbench/physical_relation', 0.4166666666666667), ('mmbench/spatial_relationship', 0.4), ('mmbench/structuralized_imagetext_understanding', 0.6493506493506493), ('mmbench/overall', 0.7346576364351671)]\n",
      "3800 eval/logs/job_dict_stage2_MH19_336px_128nodes_exp_3800.json\n",
      "Got result for mmmu - 3800: [('mmmu/accounting', 0.4), ('mmmu/agriculture', 0.6), ('mmmu/architecture_and_engineering', 0.4), ('mmmu/art', 0.7), ('mmmu/art_theory', 0.7666666666666667), ('mmmu/basic_medical_science', 0.6666666666666666), ('mmmu/biology', 0.43333333333333335), ('mmmu/chemistry', 0.3333333333333333), ('mmmu/clinical_medicine', 0.5666666666666667), ('mmmu/computer_science', 0.6666666666666666), ('mmmu/design', 0.8), ('mmmu/diagnostics_and_laboratory_medicine', 0.4666666666666667), ('mmmu/economics', 0.5666666666666667), ('mmmu/electronics', 0.36666666666666664), ('mmmu/energy_and_power', 0.5666666666666667), ('mmmu/finance', 0.4), ('mmmu/geography', 0.6), ('mmmu/history', 0.8), ('mmmu/literature', 0.9), ('mmmu/manage', 0.4666666666666667), ('mmmu/marketing', 0.5), ('mmmu/materials', 0.4666666666666667), ('mmmu/math', 0.5333333333333333), ('mmmu/mechanical_engineering', 0.5), ('mmmu/music', 0.4), ('mmmu/pharmacy', 0.7), ('mmmu/physics', 0.36666666666666664), ('mmmu/psychology', 0.6333333333333333), ('mmmu/public_health', 0.7), ('mmmu/sociology', 0.7666666666666667), ('mmmu/accuracy', 0.5677777777777778), ('mmmu/mllm_eval_accuracy', 0.5844444444444444)]\n",
      "Got result for docvqa - 3800: [('docvqa/anls_total_score', 0.6616529263076446), ('docvqa/mllm_evaluation_anls_score', 0.6633989390774641), ('docvqa/mmllm_fixed_anls_score', 0.7019972711244351)]\n",
      "Got result for mathvista - 3800: [('mathvista/accuracy', 0.387)]\n",
      "Got result for ai2d - 3800: [('ai2d/accuracy', 0.7924222797927462)]\n",
      "Got result for chartqa - 3800: [('chartqa/accuracy', 0.5189239580937337)]\n",
      "Got result for vqa - 3800: [('vqa/accuracy', 0.7256639999999778), ('vqa/recall', 0.7551119999999752), ('vqa/bleu', 0.021624036133289337), ('vqa/mllm_evaluation_accuracy', 0.7498759999999771)]\n",
      "Got result for textvqa - 3800: [('textvqa/accuracy', 68.29400000000028), ('textvqa/mllm_eval_accuracy', 72.97200000000034)]\n",
      "Got result for infographics_w_ocr - 3800: [('infographics_w_ocr/anls_total_score', 0.6465777910239343), ('infographics_w_ocr/mllm_evaluation_anls_score', 0.5956844353866315), ('infographics_w_ocr/answer_type_multi_span_score', 0.5321523182587027), ('infographics_w_ocr/answer_type_non_extractive_score', 0.638779815723758), ('infographics_w_ocr/answer_type_question_span_score', 0.6960717669710882), ('infographics_w_ocr/answer_type_single_span_score', 0.6598077568921017), ('infographics_w_ocr/evidence_type_figure_score', 0.627244964614269), ('infographics_w_ocr/evidence_type_map_score', 0.5873794110180248), ('infographics_w_ocr/evidence_type_table_list_score', 0.6430205201144769), ('infographics_w_ocr/evidence_type_text_score', 0.7007880602575256), ('infographics_w_ocr/evidence_type_visual_layout_score', 0.5689540112345787), ('infographics_w_ocr/reasoning_type_arithmetic_score', 0.6256115459882582), ('infographics_w_ocr/reasoning_type_comparison_score', 0.5353694962307665), ('infographics_w_ocr/reasoning_type_counting_score', 0.6344988344988345)]\n",
      "Got result for infographics - 3800: [('infographics/anls_total_score', 0.5462979824952026), ('infographics/mllm_evaluation_anls_score', 0.4831643531581884), ('infographics/answer_type_multi_span_score', 0.3811784973782347), ('infographics/answer_type_non_extractive_score', 0.5436857897979058), ('infographics/answer_type_question_span_score', 0.6914723631069785), ('infographics/answer_type_single_span_score', 0.5585001179081762), ('infographics/evidence_type_figure_score', 0.5339068782328559), ('infographics/evidence_type_map_score', 0.5076392933410988), ('infographics/evidence_type_table_list_score', 0.505617724731024), ('infographics/evidence_type_text_score', 0.5899017580794799), ('infographics/evidence_type_visual_layout_score', 0.5166286708060807), ('infographics/reasoning_type_arithmetic_score', 0.5059642982588186), ('infographics/reasoning_type_comparison_score', 0.4820025249966273), ('infographics/reasoning_type_counting_score', 0.5829170829170829)]\n",
      "Got result for mmbench - 3800: [('mmbench/attribute_comparison', 0.5681818181818182), ('mmbench/attribute_recognition', 0.8450704225352113), ('mmbench/celebrity_recognition', 0.9595959595959596), ('mmbench/function_reasoning', 0.8607594936708861), ('mmbench/future_prediction', 0.625), ('mmbench/image_quality', 0.5853658536585366), ('mmbench/image_scene', 0.9519230769230769), ('mmbench/image_style', 0.8679245283018868), ('mmbench/image_topic', 0.8888888888888888), ('mmbench/nature_relation', 0.8333333333333334), ('mmbench/object_localization', 0.4567901234567901), ('mmbench/ocr', 0.8205128205128205), ('mmbench/physical_property_reasoning', 0.6133333333333333), ('mmbench/physical_relation', 0.4166666666666667), ('mmbench/spatial_relationship', 0.4), ('mmbench/structuralized_imagetext_understanding', 0.6493506493506493), ('mmbench/overall', 0.7414173634937057)]\n",
      "4000 eval/logs/job_dict_stage2_MH19_336px_128nodes_exp_4000.json\n",
      "Got result for mmmu - 4000: [('mmmu/accounting', 0.5), ('mmmu/agriculture', 0.6333333333333333), ('mmmu/architecture_and_engineering', 0.23333333333333334), ('mmmu/art', 0.7), ('mmmu/art_theory', 0.8), ('mmmu/basic_medical_science', 0.7), ('mmmu/biology', 0.3333333333333333), ('mmmu/chemistry', 0.4), ('mmmu/clinical_medicine', 0.6), ('mmmu/computer_science', 0.7333333333333333), ('mmmu/design', 0.7666666666666667), ('mmmu/diagnostics_and_laboratory_medicine', 0.4), ('mmmu/economics', 0.5333333333333333), ('mmmu/electronics', 0.3), ('mmmu/energy_and_power', 0.5333333333333333), ('mmmu/finance', 0.4666666666666667), ('mmmu/geography', 0.6), ('mmmu/history', 0.8333333333333334), ('mmmu/literature', 0.8333333333333334), ('mmmu/manage', 0.5333333333333333), ('mmmu/marketing', 0.5), ('mmmu/materials', 0.4), ('mmmu/math', 0.43333333333333335), ('mmmu/mechanical_engineering', 0.36666666666666664), ('mmmu/music', 0.3), ('mmmu/pharmacy', 0.6666666666666666), ('mmmu/physics', 0.4666666666666667), ('mmmu/psychology', 0.5333333333333333), ('mmmu/public_health', 0.6666666666666666), ('mmmu/sociology', 0.7333333333333333), ('mmmu/accuracy', 0.55), ('mmmu/mllm_eval_accuracy', 0.5655555555555556)]\n",
      "Got result for docvqa - 4000: [('docvqa/anls_total_score', 0.6638353050311572), ('docvqa/mllm_evaluation_anls_score', 0.6635608945241366), ('docvqa/mmllm_fixed_anls_score', 0.7007195639643756)]\n",
      "Got result for mathvista - 4000: [('mathvista/accuracy', 0.397)]\n",
      "Got result for ai2d - 4000: [('ai2d/accuracy', 0.7908031088082902)]\n",
      "Got result for chartqa - 4000: [('chartqa/accuracy', 0.5120386010834749)]\n",
      "Got result for vqa - 4000: [('vqa/accuracy', 0.7281759999999776), ('vqa/recall', 0.7565479999999756), ('vqa/bleu', 0.023881062865257263), ('vqa/mllm_evaluation_accuracy', 0.751255999999977)]\n",
      "Got result for textvqa - 4000: [('textvqa/accuracy', 68.79800000000034), ('textvqa/mllm_eval_accuracy', 73.24600000000038)]\n",
      "Got result for infographics_w_ocr - 4000: [('infographics_w_ocr/anls_total_score', 0.639619658756057), ('infographics_w_ocr/mllm_evaluation_anls_score', 0.5871979608324914), ('infographics_w_ocr/answer_type_multi_span_score', 0.5167015009137605), ('infographics_w_ocr/answer_type_non_extractive_score', 0.6394733355854516), ('infographics_w_ocr/answer_type_question_span_score', 0.6793956824647361), ('infographics_w_ocr/answer_type_single_span_score', 0.6514077794543481), ('infographics_w_ocr/evidence_type_figure_score', 0.6222197764554883), ('infographics_w_ocr/evidence_type_map_score', 0.586554328509774), ('infographics_w_ocr/evidence_type_table_list_score', 0.6389060223586145), ('infographics_w_ocr/evidence_type_text_score', 0.6818067502022553), ('infographics_w_ocr/evidence_type_visual_layout_score', 0.53589167955617), ('infographics_w_ocr/reasoning_type_arithmetic_score', 0.6249272417080635), ('infographics_w_ocr/reasoning_type_comparison_score', 0.5264517082179011), ('infographics_w_ocr/reasoning_type_counting_score', 0.6286713286713287)]\n",
      "Got result for infographics - 4000: [('infographics/anls_total_score', 0.553377349607767), ('infographics/mllm_evaluation_anls_score', 0.49012452921508914), ('infographics/answer_type_multi_span_score', 0.3789344164972565), ('infographics/answer_type_non_extractive_score', 0.5550825003808731), ('infographics/answer_type_question_span_score', 0.6676841854726471), ('infographics/answer_type_single_span_score', 0.5671087354420487), ('infographics/evidence_type_figure_score', 0.5460545267846331), ('infographics/evidence_type_map_score', 0.5520251055486932), ('infographics/evidence_type_table_list_score', 0.5221322629807379), ('infographics/evidence_type_text_score', 0.5897991623267063), ('infographics/evidence_type_visual_layout_score', 0.5085972289449961), ('infographics/reasoning_type_arithmetic_score', 0.5058582969541873), ('infographics/reasoning_type_comparison_score', 0.45285362534681767), ('infographics/reasoning_type_counting_score', 0.5944638694638694)]\n",
      "Got result for mmbench - 4000: [('mmbench/attribute_comparison', 0.5681818181818182), ('mmbench/attribute_recognition', 0.8591549295774648), ('mmbench/celebrity_recognition', 0.9494949494949495), ('mmbench/function_reasoning', 0.8354430379746836), ('mmbench/future_prediction', 0.65), ('mmbench/image_quality', 0.5609756097560976), ('mmbench/image_scene', 0.9519230769230769), ('mmbench/image_style', 0.8867924528301887), ('mmbench/image_topic', 0.8888888888888888), ('mmbench/nature_relation', 0.8125), ('mmbench/object_localization', 0.48148148148148145), ('mmbench/ocr', 0.8205128205128205), ('mmbench/physical_property_reasoning', 0.6533333333333333), ('mmbench/physical_relation', 0.375), ('mmbench/spatial_relationship', 0.4), ('mmbench/structuralized_imagetext_understanding', 0.6493506493506493), ('mmbench/overall', 0.7394341674884854)]\n",
      "4200 eval/logs/job_dict_stage2_MH19_336px_128nodes_exp_4200.json\n",
      "Got result for mmmu - 4200: [('mmmu/accounting', 0.5333333333333333), ('mmmu/agriculture', 0.5333333333333333), ('mmmu/architecture_and_engineering', 0.3333333333333333), ('mmmu/art', 0.6666666666666666), ('mmmu/art_theory', 0.8333333333333334), ('mmmu/basic_medical_science', 0.6666666666666666), ('mmmu/biology', 0.43333333333333335), ('mmmu/chemistry', 0.43333333333333335), ('mmmu/clinical_medicine', 0.5333333333333333), ('mmmu/computer_science', 0.6), ('mmmu/design', 0.6666666666666666), ('mmmu/diagnostics_and_laboratory_medicine', 0.4), ('mmmu/economics', 0.6333333333333333), ('mmmu/electronics', 0.4), ('mmmu/energy_and_power', 0.6), ('mmmu/finance', 0.5333333333333333), ('mmmu/geography', 0.5), ('mmmu/history', 0.8666666666666667), ('mmmu/literature', 0.8666666666666667), ('mmmu/manage', 0.5333333333333333), ('mmmu/marketing', 0.5666666666666667), ('mmmu/materials', 0.3333333333333333), ('mmmu/math', 0.4666666666666667), ('mmmu/mechanical_engineering', 0.4), ('mmmu/music', 0.3333333333333333), ('mmmu/pharmacy', 0.5333333333333333), ('mmmu/physics', 0.36666666666666664), ('mmmu/psychology', 0.7), ('mmmu/public_health', 0.5), ('mmmu/sociology', 0.5666666666666667), ('mmmu/accuracy', 0.5444444444444444), ('mmmu/mllm_eval_accuracy', 0.5411111111111111)]\n",
      "Got result for docvqa - 4200: [('docvqa/anls_total_score', 0.6654590780706102), ('docvqa/mllm_evaluation_anls_score', 0.6634939321224607), ('docvqa/mmllm_fixed_anls_score', 0.7014731985007547)]\n",
      "Got result for mathvista - 4200: [('mathvista/accuracy', 0.385)]\n",
      "Got result for ai2d - 4200: [('ai2d/accuracy', 0.7943652849740933)]\n",
      "Got result for chartqa - 4200: [('chartqa/accuracy', 0.5135012984250816)]\n",
      "Got result for vqa - 4200: [('vqa/accuracy', 0.7239439999999766), ('vqa/recall', 0.7538879999999742), ('vqa/bleu', 0.023069756105542183), ('vqa/mllm_evaluation_accuracy', 0.7478439999999751)]\n",
      "Got result for textvqa - 4200: [('textvqa/accuracy', 69.11800000000038), ('textvqa/mllm_eval_accuracy', 73.70000000000041)]\n",
      "Got result for infographics_w_ocr - 4200: [('infographics_w_ocr/anls_total_score', 0.6480012644357671), ('infographics_w_ocr/mllm_evaluation_anls_score', 0.5943138508713856), ('infographics_w_ocr/answer_type_multi_span_score', 0.5395363560727504), ('infographics_w_ocr/answer_type_non_extractive_score', 0.6394816154309827), ('infographics_w_ocr/answer_type_question_span_score', 0.7004215838209051), ('infographics_w_ocr/answer_type_single_span_score', 0.6603548033746832), ('infographics_w_ocr/evidence_type_figure_score', 0.6262296275973861), ('infographics_w_ocr/evidence_type_map_score', 0.5936500380807311), ('infographics_w_ocr/evidence_type_table_list_score', 0.6547058701066608), ('infographics_w_ocr/evidence_type_text_score', 0.6926244806151663), ('infographics_w_ocr/evidence_type_visual_layout_score', 0.5633052172612127), ('infographics_w_ocr/reasoning_type_arithmetic_score', 0.6367579908675798), ('infographics_w_ocr/reasoning_type_comparison_score', 0.544022030878238), ('infographics_w_ocr/reasoning_type_counting_score', 0.6311188811188811)]\n",
      "Got result for infographics - 4200: [('infographics/anls_total_score', 0.5425830774462975), ('infographics/mllm_evaluation_anls_score', 0.4797971188207303), ('infographics/answer_type_multi_span_score', 0.3900616811709289), ('infographics/answer_type_non_extractive_score', 0.544308434181852), ('infographics/answer_type_question_span_score', 0.6514284326784328), ('infographics/answer_type_single_span_score', 0.5543465593999105), ('infographics/evidence_type_figure_score', 0.5320936165918101), ('infographics/evidence_type_map_score', 0.5010386332750922), ('infographics/evidence_type_table_list_score', 0.49799591553747263), ('infographics/evidence_type_text_score', 0.5837858283938127), ('infographics/evidence_type_visual_layout_score', 0.514470924619566), ('infographics/reasoning_type_arithmetic_score', 0.5099973656480504), ('infographics/reasoning_type_comparison_score', 0.44134443464461104), ('infographics/reasoning_type_counting_score', 0.5716783216783217)]\n",
      "Got result for mmbench - 4200: [('mmbench/attribute_comparison', 0.6136363636363636), ('mmbench/attribute_recognition', 0.8591549295774648), ('mmbench/celebrity_recognition', 0.9393939393939394), ('mmbench/function_reasoning', 0.8481012658227848), ('mmbench/future_prediction', 0.575), ('mmbench/image_quality', 0.5121951219512195), ('mmbench/image_scene', 0.9519230769230769), ('mmbench/image_style', 0.8867924528301887), ('mmbench/image_topic', 0.8888888888888888), ('mmbench/nature_relation', 0.7916666666666666), ('mmbench/object_localization', 0.49382716049382713), ('mmbench/ocr', 0.7948717948717948), ('mmbench/physical_property_reasoning', 0.6533333333333333), ('mmbench/physical_relation', 0.4166666666666667), ('mmbench/spatial_relationship', 0.4), ('mmbench/structuralized_imagetext_understanding', 0.6753246753246753), ('mmbench/overall', 0.7373213318922573)]\n",
      "4400 eval/logs/job_dict_stage2_MH19_336px_128nodes_exp_4400.json\n",
      "Got result for mmmu - 4400: [('mmmu/accounting', 0.4666666666666667), ('mmmu/agriculture', 0.5666666666666667), ('mmmu/architecture_and_engineering', 0.4666666666666667), ('mmmu/art', 0.6666666666666666), ('mmmu/art_theory', 0.9), ('mmmu/basic_medical_science', 0.6666666666666666), ('mmmu/biology', 0.43333333333333335), ('mmmu/chemistry', 0.4), ('mmmu/clinical_medicine', 0.5333333333333333), ('mmmu/computer_science', 0.6333333333333333), ('mmmu/design', 0.7666666666666667), ('mmmu/diagnostics_and_laboratory_medicine', 0.3333333333333333), ('mmmu/economics', 0.5666666666666667), ('mmmu/electronics', 0.43333333333333335), ('mmmu/energy_and_power', 0.43333333333333335), ('mmmu/finance', 0.5333333333333333), ('mmmu/geography', 0.5), ('mmmu/history', 0.8), ('mmmu/literature', 0.8333333333333334), ('mmmu/manage', 0.5), ('mmmu/marketing', 0.5333333333333333), ('mmmu/materials', 0.4666666666666667), ('mmmu/math', 0.4), ('mmmu/mechanical_engineering', 0.36666666666666664), ('mmmu/music', 0.2), ('mmmu/pharmacy', 0.6666666666666666), ('mmmu/physics', 0.4666666666666667), ('mmmu/psychology', 0.6666666666666666), ('mmmu/public_health', 0.6333333333333333), ('mmmu/sociology', 0.6), ('mmmu/accuracy', 0.5477777777777778), ('mmmu/mllm_eval_accuracy', 0.55)]\n",
      "Got result for docvqa - 4400: [('docvqa/anls_total_score', 0.6577835036688473), ('docvqa/mllm_evaluation_anls_score', 0.6582541095077417), ('docvqa/mmllm_fixed_anls_score', 0.6963264761710404)]\n",
      "Got result for mathvista - 4400: [('mathvista/accuracy', 0.384)]\n",
      "Got result for ai2d - 4400: [('ai2d/accuracy', 0.8005181347150259)]\n",
      "Got result for chartqa - 4400: [('chartqa/accuracy', 0.4991762741209335)]\n",
      "Got result for vqa - 4400: [('vqa/accuracy', 0.7234039999999777), ('vqa/recall', 0.7527559999999749), ('vqa/bleu', 0.01938352733850479), ('vqa/mllm_evaluation_accuracy', 0.7470599999999753)]\n",
      "Got result for textvqa - 4400: [('textvqa/accuracy', 68.61400000000032), ('textvqa/mllm_eval_accuracy', 73.15600000000038)]\n",
      "Got result for infographics_w_ocr - 4400: [('infographics_w_ocr/anls_total_score', 0.6441712683161956), ('infographics_w_ocr/mllm_evaluation_anls_score', 0.592151199201444), ('infographics_w_ocr/answer_type_multi_span_score', 0.542195857955229), ('infographics_w_ocr/answer_type_non_extractive_score', 0.6345314269816984), ('infographics_w_ocr/answer_type_question_span_score', 0.6972164556157769), ('infographics_w_ocr/answer_type_single_span_score', 0.6570649688924293), ('infographics_w_ocr/evidence_type_figure_score', 0.6223226352659003), ('infographics_w_ocr/evidence_type_map_score', 0.5568513582127443), ('infographics_w_ocr/evidence_type_table_list_score', 0.6485196267161363), ('infographics_w_ocr/evidence_type_text_score', 0.6850861006639555), ('infographics_w_ocr/evidence_type_visual_layout_score', 0.5905931652218812), ('infographics_w_ocr/reasoning_type_arithmetic_score', 0.6239584901399967), ('infographics_w_ocr/reasoning_type_comparison_score', 0.553092497102961), ('infographics_w_ocr/reasoning_type_counting_score', 0.6328671328671329)]\n",
      "Got result for infographics - 4400: [('infographics/anls_total_score', 0.5427382446906195), ('infographics/mllm_evaluation_anls_score', 0.4805578932362299), ('infographics/answer_type_multi_span_score', 0.3943458312960511), ('infographics/answer_type_non_extractive_score', 0.5389742264968306), ('infographics/answer_type_question_span_score', 0.67802747466209), ('infographics/answer_type_single_span_score', 0.5535217133635124), ('infographics/evidence_type_figure_score', 0.5281696747337464), ('infographics/evidence_type_map_score', 0.5429002416156735), ('infographics/evidence_type_table_list_score', 0.5099792044432347), ('infographics/evidence_type_text_score', 0.5845648038746332), ('infographics/evidence_type_visual_layout_score', 0.5284417721023548), ('infographics/reasoning_type_arithmetic_score', 0.4996098650208238), ('infographics/reasoning_type_comparison_score', 0.455277659407749), ('infographics/reasoning_type_counting_score', 0.5635198135198136)]\n",
      "Got result for mmbench - 4400: [('mmbench/attribute_comparison', 0.6136363636363636), ('mmbench/attribute_recognition', 0.8591549295774648), ('mmbench/celebrity_recognition', 0.9393939393939394), ('mmbench/function_reasoning', 0.8481012658227848), ('mmbench/future_prediction', 0.6), ('mmbench/image_quality', 0.5853658536585366), ('mmbench/image_scene', 0.9615384615384616), ('mmbench/image_style', 0.9056603773584906), ('mmbench/image_topic', 0.8888888888888888), ('mmbench/nature_relation', 0.8125), ('mmbench/object_localization', 0.4691358024691358), ('mmbench/ocr', 0.7948717948717948), ('mmbench/physical_property_reasoning', 0.68), ('mmbench/physical_relation', 0.375), ('mmbench/spatial_relationship', 0.4), ('mmbench/structuralized_imagetext_understanding', 0.6103896103896104), ('mmbench/overall', 0.7404643794534864)]\n",
      "4600 eval/logs/job_dict_stage2_MH19_336px_128nodes_exp_4600.json\n",
      "Got result for mmmu - 4600: [('mmmu/accounting', 0.5), ('mmmu/agriculture', 0.6), ('mmmu/architecture_and_engineering', 0.26666666666666666), ('mmmu/art', 0.6666666666666666), ('mmmu/art_theory', 0.8666666666666667), ('mmmu/basic_medical_science', 0.7333333333333333), ('mmmu/biology', 0.36666666666666664), ('mmmu/chemistry', 0.5), ('mmmu/clinical_medicine', 0.5666666666666667), ('mmmu/computer_science', 0.6333333333333333), ('mmmu/design', 0.7666666666666667), ('mmmu/diagnostics_and_laboratory_medicine', 0.43333333333333335), ('mmmu/economics', 0.6333333333333333), ('mmmu/electronics', 0.3), ('mmmu/energy_and_power', 0.36666666666666664), ('mmmu/finance', 0.43333333333333335), ('mmmu/geography', 0.6333333333333333), ('mmmu/history', 0.8666666666666667), ('mmmu/literature', 0.9), ('mmmu/manage', 0.6), ('mmmu/marketing', 0.5666666666666667), ('mmmu/materials', 0.36666666666666664), ('mmmu/math', 0.5), ('mmmu/mechanical_engineering', 0.5), ('mmmu/music', 0.36666666666666664), ('mmmu/pharmacy', 0.6333333333333333), ('mmmu/physics', 0.5333333333333333), ('mmmu/psychology', 0.6333333333333333), ('mmmu/public_health', 0.6), ('mmmu/sociology', 0.6333333333333333), ('mmmu/accuracy', 0.5655555555555556), ('mmmu/mllm_eval_accuracy', 0.5833333333333334)]\n",
      "Got result for docvqa - 4600: [('docvqa/anls_total_score', 0.6649139118450663), ('docvqa/mllm_evaluation_anls_score', 0.6664944150599198), ('docvqa/mmllm_fixed_anls_score', 0.7036872840615839)]\n",
      "Got result for mathvista - 4600: [('mathvista/accuracy', 0.396)]\n",
      "Got result for ai2d - 4600: [('ai2d/accuracy', 0.7865932642487047)]\n",
      "Got result for chartqa - 4600: [('chartqa/accuracy', 0.5067031887108536)]\n",
      "Got result for vqa - 4600: [('vqa/accuracy', 0.7231519999999776), ('vqa/recall', 0.752971999999975), ('vqa/bleu', 0.028394801542162895), ('vqa/mllm_evaluation_accuracy', 0.7475439999999761)]\n",
      "Got result for textvqa - 4600: [('textvqa/accuracy', 68.3180000000003), ('textvqa/mllm_eval_accuracy', 72.77000000000035)]\n",
      "Got result for infographics_w_ocr - 4600: [('infographics_w_ocr/anls_total_score', 0.6433603004791333), ('infographics_w_ocr/mllm_evaluation_anls_score', 0.5912851946288605), ('infographics_w_ocr/answer_type_multi_span_score', 0.5177825851123312), ('infographics_w_ocr/answer_type_non_extractive_score', 0.6307091190906744), ('infographics_w_ocr/answer_type_question_span_score', 0.6975598622091835), ('infographics_w_ocr/answer_type_single_span_score', 0.6566383586330448), ('infographics_w_ocr/evidence_type_figure_score', 0.6236438921927718), ('infographics_w_ocr/evidence_type_map_score', 0.5573464077176947), ('infographics_w_ocr/evidence_type_table_list_score', 0.6365635749629702), ('infographics_w_ocr/evidence_type_text_score', 0.6895555646007121), ('infographics_w_ocr/evidence_type_visual_layout_score', 0.5868064096004332), ('infographics_w_ocr/reasoning_type_arithmetic_score', 0.6095278864970644), ('infographics_w_ocr/reasoning_type_comparison_score', 0.538524967067676), ('infographics_w_ocr/reasoning_type_counting_score', 0.6416083916083916)]\n",
      "Got result for infographics - 4600: [('infographics/anls_total_score', 0.5465704977363636), ('infographics/mllm_evaluation_anls_score', 0.48339642069589106), ('infographics/answer_type_multi_span_score', 0.3552702863567235), ('infographics/answer_type_non_extractive_score', 0.5460481953248681), ('infographics/answer_type_question_span_score', 0.7087509178855332), ('infographics/answer_type_single_span_score', 0.5580794874915083), ('infographics/evidence_type_figure_score', 0.5357241784906924), ('infographics/evidence_type_map_score', 0.551946224034168), ('infographics/evidence_type_table_list_score', 0.5176125767609223), ('infographics/evidence_type_text_score', 0.5782280019500535), ('infographics/evidence_type_visual_layout_score', 0.49255177096170427), ('infographics/reasoning_type_arithmetic_score', 0.5163173014200411), ('infographics/reasoning_type_comparison_score', 0.46498154371650674), ('infographics/reasoning_type_counting_score', 0.5685314685314685)]\n",
      "Got result for mmbench - 4600: [('mmbench/attribute_comparison', 0.5909090909090909), ('mmbench/attribute_recognition', 0.8732394366197183), ('mmbench/celebrity_recognition', 0.9393939393939394), ('mmbench/function_reasoning', 0.8481012658227848), ('mmbench/future_prediction', 0.6), ('mmbench/image_quality', 0.5365853658536586), ('mmbench/image_scene', 0.9615384615384616), ('mmbench/image_style', 0.9245283018867925), ('mmbench/image_topic', 0.8888888888888888), ('mmbench/nature_relation', 0.8333333333333334), ('mmbench/object_localization', 0.4444444444444444), ('mmbench/ocr', 0.7948717948717948), ('mmbench/physical_property_reasoning', 0.6666666666666666), ('mmbench/physical_relation', 0.4166666666666667), ('mmbench/spatial_relationship', 0.4), ('mmbench/structuralized_imagetext_understanding', 0.6493506493506493), ('mmbench/overall', 0.7417084303855573)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmmu_v2</th>\n",
       "      <th>mmmu_v1</th>\n",
       "      <th>docvqa</th>\n",
       "      <th>mathvista</th>\n",
       "      <th>ai2d</th>\n",
       "      <th>chartqa</th>\n",
       "      <th>vqa</th>\n",
       "      <th>textvqa</th>\n",
       "      <th>infographics_w_ocr</th>\n",
       "      <th>infographics</th>\n",
       "      <th>mmbench</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>0.5689</td>\n",
       "      <td>0.5611</td>\n",
       "      <td>0.6641</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.7908</td>\n",
       "      <td>0.5031</td>\n",
       "      <td>0.7282</td>\n",
       "      <td>0.69406</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.5443</td>\n",
       "      <td>0.7392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>0.5767</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.6663</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.7924</td>\n",
       "      <td>0.5096</td>\n",
       "      <td>0.7283</td>\n",
       "      <td>0.68548</td>\n",
       "      <td>0.6471</td>\n",
       "      <td>0.5472</td>\n",
       "      <td>0.7447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>0.5467</td>\n",
       "      <td>0.5456</td>\n",
       "      <td>0.6673</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.5096</td>\n",
       "      <td>0.7249</td>\n",
       "      <td>0.68496</td>\n",
       "      <td>0.6484</td>\n",
       "      <td>0.5497</td>\n",
       "      <td>0.7347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>0.5844</td>\n",
       "      <td>0.5678</td>\n",
       "      <td>0.6617</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.7924</td>\n",
       "      <td>0.5189</td>\n",
       "      <td>0.7257</td>\n",
       "      <td>0.68294</td>\n",
       "      <td>0.6466</td>\n",
       "      <td>0.5463</td>\n",
       "      <td>0.7414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>0.5656</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.7908</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.7282</td>\n",
       "      <td>0.68798</td>\n",
       "      <td>0.6396</td>\n",
       "      <td>0.5534</td>\n",
       "      <td>0.7394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>0.5411</td>\n",
       "      <td>0.5444</td>\n",
       "      <td>0.6655</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.7944</td>\n",
       "      <td>0.5135</td>\n",
       "      <td>0.7239</td>\n",
       "      <td>0.69118</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>0.7373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.7234</td>\n",
       "      <td>0.68614</td>\n",
       "      <td>0.6442</td>\n",
       "      <td>0.5427</td>\n",
       "      <td>0.7405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.5656</td>\n",
       "      <td>0.6649</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.7866</td>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>0.68318</td>\n",
       "      <td>0.6434</td>\n",
       "      <td>0.5466</td>\n",
       "      <td>0.7417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mmmu_v2 mmmu_v1  docvqa mathvista    ai2d chartqa     vqa  textvqa  \\\n",
       "3200  0.5689  0.5611  0.6641     0.379  0.7908  0.5031  0.7282  0.69406   \n",
       "3400  0.5767  0.5622  0.6663     0.393  0.7924  0.5096  0.7283  0.68548   \n",
       "3600  0.5467  0.5456  0.6673      0.39   0.807  0.5096  0.7249  0.68496   \n",
       "3800  0.5844  0.5678  0.6617     0.387  0.7924  0.5189  0.7257  0.68294   \n",
       "4000  0.5656    0.55  0.6638     0.397  0.7908   0.512  0.7282  0.68798   \n",
       "4200  0.5411  0.5444  0.6655     0.385  0.7944  0.5135  0.7239  0.69118   \n",
       "4400    0.55  0.5478  0.6578     0.384  0.8005  0.4992  0.7234  0.68614   \n",
       "4600  0.5833  0.5656  0.6649     0.396  0.7866  0.5067  0.7232  0.68318   \n",
       "\n",
       "     infographics_w_ocr infographics mmbench  \n",
       "3200             0.6429       0.5443  0.7392  \n",
       "3400             0.6471       0.5472  0.7447  \n",
       "3600             0.6484       0.5497  0.7347  \n",
       "3800             0.6466       0.5463  0.7414  \n",
       "4000             0.6396       0.5534  0.7394  \n",
       "4200              0.648       0.5426  0.7373  \n",
       "4400             0.6442       0.5427  0.7405  \n",
       "4600             0.6434       0.5466  0.7417  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for c in checkpoints:\n",
    "    # for c in [200]:\n",
    "    job_dict_file = f\"eval/logs/job_dict_stage2_MH19_336px_128nodes_exp_{c}.json\"\n",
    "    with open(job_dict_file, 'r') as f:\n",
    "        job_dict = json.load(f)\n",
    "\n",
    "    print(c, job_dict_file)\n",
    "    df_c = eval_helper.get_eval_scores(job_dict)\n",
    "\n",
    "    df = pd.concat([df, df_c])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('stage2_eval_3200_4600.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
