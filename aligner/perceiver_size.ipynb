{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use aligner_v7 kernel\n",
    "\n",
    "import sys\n",
    "add_paths = [\n",
    "    \"/fsx_0/user/tranx/rsync\", # ALIGNER_PARENT_DIR\n",
    "    \"/fsx_0/user/tranx/rsync/llm_mm_aligner/replicated\", # ALIGNER_PARENT_DIR/llm_mm_aligner/replicated\n",
    "    # \"/data/home/tranx/conda/envs/aligner_20240822_v2/python-packages\", #CONDA_PREFIX/python-packages\n",
    "    # \"/data/home/kapilk/.conda/envs/aligner_20240822_v2/python-packages\"\n",
    "    \"/fsx_0/shared/conda/aligner_20241030/python-packages\"\n",
    "]\n",
    "\n",
    "for p in add_paths:\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "        \n",
    "# device = \"cuda:2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PerceptionTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPerceiverV3Tokenizer\u001b[39;00m(\u001b[43mPerceptionTokenizer\u001b[49m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m nn\u001b[38;5;241m.\u001b[39mModule:\n\u001b[1;32m      3\u001b[0m         num_heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_args\u001b[38;5;241m.\u001b[39mperceiver_num_heads\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PerceptionTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "class PerceiverV3Tokenizer(PerceptionTokenizer):\n",
    "    def get_model(self) -> nn.Module:\n",
    "        num_heads = self.model_args.perceiver_num_heads\n",
    "        if self.model_args.perceiver_dim_override:\n",
    "            dim = self.model_args.perceiver_dim_override\n",
    "        else:\n",
    "            dim = self.feature_dim\n",
    "\n",
    "        mult = num_heads * 64  # dim head should be a multiple of 64\n",
    "        dim = int(ceil(dim / mult)) * mult\n",
    "\n",
    "        return PerceiverResamplerV3(\n",
    "            in_dim=self.feature_dim,\n",
    "            dim=dim,\n",
    "            out_dim=self.embedding_size,\n",
    "            depth=self.model_args.perception_tokenizer_num_layers,\n",
    "            ff_mult=self.model_args.perceiver_ff_mult,\n",
    "            num_latents=self.model_args.perceiver_num_latents,\n",
    "            heads=num_heads,\n",
    "            kv_heads=self.model_args.perceiver_num_kv_heads,\n",
    "            hidden_dropout_p=self.model_args.perception_tokenizer_hidden_dropout_p,\n",
    "            attention_dropout_p=self.model_args.perception_tokenizer_attention_dropout_p,\n",
    "            num_img_chunks=self.data_args.num_image_chunks,\n",
    "            cat_latents=self.model_args.perceiver_cat_latents,\n",
    "            collapse_chunks=self.model_args.perceiver_collapse_chunks,\n",
    "            enable_query_aware=self.model_args.perceiver_enable_query_aware,\n",
    "            enable_moe=self.model_args.perceiver_enable_moe,\n",
    "            moe_num_experts=self.model_args.perceiver_num_experts,\n",
    "            moe_num_activated_experts=self.model_args.perceiver_num_activated_experts,\n",
    "            add_output_norm=self.model_args.perceiver_add_output_norm,\n",
    "            enforce_uniform_emb_variance=self.model_args.enforce_uniform_emb_variance,\n",
    "            use_temporal_position_encoding=self.model_args.perceiver_temporal_position_encoding,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_mm_aligner.lib.tokenizers.perceiverIO_projector import PerceiverResamplerV3\n",
    "from math import ceil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "in_dim=4096, mult=2048, dim=2048, num_layers=22\n",
      "Model size (B) = 1.34\n",
      "--------------------------------------------------\n",
      "in_dim=4096, mult=2048, dim=3072, num_layers=22\n",
      "Model size (B) = 2.18\n",
      "--------------------------------------------------\n",
      "in_dim=4096, mult=2048, dim=5120, num_layers=22\n",
      "Model size (B) = 6.98\n",
      "--------------------------------------------------\n",
      "in_dim=4096, mult=2048, dim=6144, num_layers=22\n",
      "Model size (B) = 8.72\n"
     ]
    }
   ],
   "source": [
    "dim = 4096\n",
    "num_heads = 32\n",
    "num_layers = 22\n",
    "\n",
    "# in_dim = 4096\n",
    "# in_dim = dim\n",
    "# mult = num_heads * 64\n",
    "# dim = int(ceil(dim / mult)) * mult\n",
    "\n",
    "# for num_layers in [14,18,22,26,30]:\n",
    "for dim in [2048, 3072, 5120, 6144]:\n",
    "    model = PerceiverResamplerV3(\n",
    "        in_dim=dim,\n",
    "        dim=dim,\n",
    "        out_dim=dim,\n",
    "        depth=num_layers,\n",
    "        heads=num_heads,\n",
    "        kv_heads=8, # per job config, true for both 8B and 70B\n",
    "    )\n",
    "\n",
    "    # self.model_args.perceiver_num_kv_heads: default = 16\n",
    "\n",
    "    # https://fburl.com/code/29v9guvf\n",
    "    # self.to_q = nn.Linear(self.dim, self.dim_head * self.heads, bias=False)\n",
    "    # self.to_k = nn.Linear(self.dim, self.dim_head * self.kv_heads, bias=False)\n",
    "    # self.to_v = nn.Linear(self.dim, self.dim_head * self.kv_heads, bias=False)\n",
    "\n",
    "    # model\n",
    "    print(\"-\"*50)\n",
    "    print(f\"{dim=}, {num_heads=}, {num_layers=}\")\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Model size (B) = {np.round(total_params/1e9, 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aligner_v7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
