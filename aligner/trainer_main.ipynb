{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using conda env: aligner_v7\n",
      "Pytorch version: 2.3.0\n",
      "Available GPUs:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hpcaas/.mounts/fs-036153e63d56f4dc2/home/tranx/conda/envs/aligner_v7/lib/python3.10/site-packages/torch/cuda/__init__.py:624: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys \n",
    "import os\n",
    "\n",
    "dep_paths = [\n",
    "    '/fsx_0/user/tranx',\n",
    "    '/fsx_0/user/tranx/llm_mm_aligner/replicated'\n",
    "]\n",
    "\n",
    "for p in dep_paths:\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "print(\"Using conda env:\", os.environ['CONDA_DEFAULT_ENV'])\n",
    "\n",
    "import torch \n",
    "print(\"Pytorch version:\", torch.__version__)\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hpcaas/.mounts/fs-04cb39659581b642e/home/tranx/conda/envs/aligner_v1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "fused sequence parallel available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moe_matmul not found\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import replace\n",
    "from itertools import chain\n",
    "from typing import Any, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "\n",
    "import transformers  # @manual=fbsource//third-party/pypi/transformers:transformers\n",
    "\n",
    "from llm_mm_aligner.lib.callbacks.train import (\n",
    "    tensorboard_callback,\n",
    "    trainer_callback_factory_builder,\n",
    ")\n",
    "\n",
    "from llm_mm_aligner.lib.checkpoints import (\n",
    "    checkpoint_downloader_factory,\n",
    "    checkpoint_utils,\n",
    ")\n",
    "# from llm_mm_aligner.lib.clip_trainer import CLIPFSDPTrainer\n",
    "from llm_mm_aligner.lib.configs import (\n",
    "    DataTrainingArguments,\n",
    "    ModelArguments,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from llm_mm_aligner.lib.data_collators import get_collator\n",
    "from llm_mm_aligner.lib.datasets.hive import get_hive_dataset\n",
    "from llm_mm_aligner.lib.datasets.mm_datasets import DatasetType, get_mm_dataset\n",
    "from llm_mm_aligner.lib.datasets.web_dataset import get_wb_dataset\n",
    "from llm_mm_aligner.lib.file_utils import (\n",
    "    move_model_resources_to_local,\n",
    "    set_max_manifold_parallel,\n",
    ")\n",
    "from llm_mm_aligner.lib.metaformers_bridge import model_parallel_cuda_manual_seed\n",
    "from llm_mm_aligner.lib.models.clip_model import MMModelForCLIP\n",
    "from llm_mm_aligner.lib.models.mm_model import MMModel\n",
    "from llm_mm_aligner.lib.mpu import (\n",
    "    get_model_parallel_group,\n",
    "    get_pipeline_model_parallel_rank,\n",
    "    initialize_model_parallel,\n",
    ")\n",
    "from llm_mm_aligner.lib.preemption import preemption_monitor_factory\n",
    "from llm_mm_aligner.lib.profilers import profilers\n",
    "from llm_mm_aligner.lib.trainers import (\n",
    "    DPOTrainer,\n",
    "    FSDPTrainer,\n",
    "    MMLLMBaseTrainer,\n",
    "    SimPOTrainer,\n",
    ")\n",
    "from llm_mm_aligner.lib.utils import (\n",
    "    clamp,\n",
    "    get_global_rank,\n",
    "    get_local_process_group,\n",
    "    get_local_rank,\n",
    "    k_at_a_time,\n",
    ")\n",
    "\n",
    "from torch import distributed as dist\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# @manual=fbsource//third-party/pypi/transformers:transformers\n",
    "from transformers import HfArgumentParser, set_seed, TrainerCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load args for main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "arg_path = \"/data/home/yastashonok/TEMP/pickle/\"\n",
    "\n",
    "with open(os.path.join(arg_path, \"model_args.pkl\"), \"rb\") as f:\n",
    "    model_args = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(arg_path, \"data_args.pkl\"), \"rb\") as f:\n",
    "    data_args = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(arg_path, \"training_args.pkl\"), \"rb\") as f:\n",
    "    training_args = pickle.load(f)\n",
    "\n",
    "tb_writer = None\n",
    "\n",
    "# Adapt path to AWS environment\n",
    "base_path = \"/data/home/yastashonok/mm6_pretrain\"\n",
    "data_path = \"/data/home/yastashonok/MH13-aws/data\"\n",
    "model_path = \"/data/home/yastashonok/MH13-aws/input\"\n",
    "run_name = \"mm6_pretrain\"\n",
    "\n",
    "data_args.base_path = base_path\n",
    "data_args.wd_data_path = data_path\n",
    "\n",
    "model_args.model_name_or_path = f\"{model_path}/Meta-Llama-3-8B-Instruct\"\n",
    "model_args.tokenizer_path = f\"{model_path}/Meta-Llama-3-8B-Instruct\"\n",
    "model_args.modality_tokenizer_name = f\"{model_path}/MetaCLIP-BigG-336-f536822271-8k\"\n",
    "training_args.output_dir = f\"{base_path}/output/{run_name}\"\n",
    "training_args.run_name = run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_training_args = {'output_dir': '/data/home/yastashonok/mm6_pretrain/output/mm6_pretrain', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 1, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.0001, 'weight_decay': 0.1, 'adam_beta1': 0.9, 'adam_beta2': 0.95, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 1.0, 'max_steps': -1, 'lr_scheduler_type': 'cosine', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 200, 'log_level': 'info', 'log_level_replica': 'info', 'log_on_each_node': True, 'logging_dir': '/data/home/yastashonok/mm6_pretrain/output/mm6_pretrain/runs/Jul19_15-08-44_h100-st-p548xlarge-36', 'logging_strategy': 'steps', 'logging_first_step': True, 'logging_steps': 10, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 250, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 2024, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': True, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 7, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 250.0, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'mm6_pretrain', 'disable_tqdm': False, 'remove_unused_columns': False, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'greater_is_better': False, 'ignore_data_skip': False, 'fsdp': ['full_shard', 'auto_wrap'], 'fsdp_min_num_params': 0, 'fsdp_config': {'forward_prefetch': False, 'backward_prefetch': 'backward_pre', 'limit_all_gathers': True, 'transformer_layer_cls_to_wrap': ['DecoderLayer',\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             'EncoderLayer', 'PerceptionTokenizer', 'MetaFormersBlock'], 'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': False, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': 'no', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'save_top_k': 1, 'load_latest_k': 1, 'checkpoints_optimizer': None, 'checkpoints_scheduler': None, 'dpo_alpha': 0.0, 'dpo_beta': 0.1, 'dpo_reference_free': False, 'dpo_label_smoothing': 0.0, 'ipo': False, 'simpo_beta': 2.0, 'simpo_gamma': 1.0, 'mixin_gamma': 1.0, 'load_best_model': False, 'clip_head_weight_decay': None, 'lm_text_lr_scale': 1.0, 'perception_lr_scale': 1.0, 'tb_logdir': None, 'eval_ckpt': None, 'eval_type': None, 'cosine_decay_to': 0.01}\n",
    "parse_model_args = {'model_name_or_path': '/data/home/yastashonok/MH13-aws/input/Meta-Llama-3-8B-Instruct', 'tokenizer_path': '/data/home/yastashonok/MH13-aws/input/Meta-Llama-3-8B-Instruct', 'use_metaformers': True, 'recompute_attn': True, 'recompute_fc1_fc3': True, 'pretraining_tp': 1, 'model_parallel_size': 1, 'context_parallel_size': 1, 'use_te': False, 'parallelize_llm': True, 'parallelize_perception_tokenizer': True, 'use_sdpa': True, 'use_fused_layernorm': True, 'max_parallel_model_loading': 8, 'model_type': None, 'config_overrides': None, 'config_name': None, 'lm_mh_tokenizer_version': 'tiktoken_v5', 'tokenizer_name': None, 'ensemble_tokenizer_params': '{}', 'use_ensemble_modality_tokenizer': False, 'modality_tokenizer_name': '/data/home/yastashonok/MH13-aws/input/MetaCLIP-BigG-336-f536822271-8k', 'cache_dir': None, 'use_fast_tokenizer': True, 'model_revision': 'main', 'n_prefix_embs': 65, 'seq2seq': False, 'num_classes': None, 'routing_classifier': False, 'integrity_classifier': False, 'freeze_perception': True, 'freeze_perception_except_pos_emb': False, 'ignore_mismatched_sizes': False, 'freeze_tokenizer': False, 'freeze_lm': True, 'lm_bits': -1, 'checkpoints_lm': None, 'perception_tokenizer_name': None, 'checkpoints_perception': None, 'checkpoints_perception_tokenizer': None, 'checkpoints_logit_scale': None, 'checkpoints_logit_bias': None, 'tokenizer_type': 'PerceiverV3', 'modality': 'image', 'mixin_modality': 'image', 'lora': False, 'lora_rank': 8, 'lora_dropout': 0.1, 'lora_alpha': 32, 'lora_checkpoint': None, 'lora_target_modules':\n",
    "                    \"['q_proj', 'v_proj']\", 'lora_tokenizer': False, 'lora_tokenizer_rank': 8, 'lora_tokenizer_dropout': 0.1, 'lora_tokenizer_alpha': 32, 'lora_tokenizer_checkpoint': None, 'lora_tokenizer_target_modules': \"['to_q', 'to_kv']\", 'lora_perception': False, 'lora_perception_rank': 8, 'lora_perception_dropout': 0.1, 'lora_perception_alpha': 32, 'lora_perception_checkpoint': None, 'lora_perception_target_modules': \"['k_proj', 'v_proj', 'q_proj', 'out_proj', 'fc1', 'fc2', 'visual_projection']\", 'speech_adapter_type': 0, 'num_media_embeds': 4, 'perception_tokenizer_num_layers': 8, 'perception_tokenizer_project_in_dim': None, 'perception_tokenizer_project_out_from_dim': None, 'perception_tokenizer_attention_dropout_p': 0.05, 'perception_tokenizer_hidden_dropout_p': 0.1, 'perception_tokenizer_ensemble_type': 'pool', 'custom_FSDP': False, 'device_map': 'cpu', 'load_in_8bit': False, 'low_cpu_mem_usage': True, 'add_bos_token': False, 'add_eos_token': False, 'manifold_bucket': None, 'perception_output_processor': 'layer', 'keep_vision_hidden_states': False, 'vision_hidden_state_layer': -2, 'gradient_checkpointing_llm': True, 'layer_ckpt': 'none', 'gradient_checkpointing_perception_tokenizer': True, 'gradient_checkpointing_perception': False, 'clip_patch_dropout': None, 'center_crop': False, 'clip_loss_weight': None, 'clip_logit_scale': 2.6592, 'clip_n_registers': None, 'clip_enable_mi': False, 'debug_logs': False, 'llama_seq_cls_dropout_p': None, 'add_grounding_tokens': False, 'grounding_bin_size': 42, 'grounding_image_size': 336, 'add_grounding_llm_head_if_available': True, 'checkpoints_lm_embedding': None, 'checkpoints_lm_head': None, 'checkpoints_lm_cls_head': None, 'perceiver_num_heads': 32, 'perceiver_dim_override': 4096, 'perceiver_num_kv_heads': 8, 'perceiver_num_latents': 64, 'perceiver_source_num_latents': 64, 'perceiver_ff_mult': 4, 'perceiver_use_pos_embs': True, 'perceiver_pos_emb_type': 'learned', 'perceiver_enable_query_aware': False, 'clip_num_embeddings': 577, 'encoder_frame_stride': None, 'mi_image_encoder_frame_stride': None, 'encoder_num_frames': None, 'encoder_use_predictor': True, 'perceiver_cat_latents': True, 'perceiver_collapse_chunks': False, 'perceiver_enable_mi': False, 'treat_frames_as_images': False, 'perceiver_max_img_frames': 16, 'block_sparse': True, 'perceiver_num_frames_per_chunk': 4, 'perceiver_add_eof': True, 'perceiver_collapse_frame_chunks': False, 'perceiver_dynamic_frame_resizing': True, 'perceiver_enable_latent_compression': False, 'perceiver_interleaved_outputs': False, 'perceiver_collapse_modalities': False, 'replace_llama_attention': True, 'ensemble_meta_perceiver_option': None, 'ensemble_freeze_modality': None, 'enable_multi_transformer_blocks': False, 'n_multi_transformer_blocks': 35, 'n_layers_per_multi_transformer_block': 2, 'enable_modality_aggregator': False, 'modality_aggregator_split_dim': 2, 'modality_aggregator_merge_dim': 1, 'perceiver_enable_moe': False, 'perceiver_num_experts': 8, 'perceiver_num_activated_experts': 2, 'use_scaled_rope': True, 'rope_scale_factor': 8, 'high_freq_factor': 32, 'low_freq_factor': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.fsdp_config['fsdp_transformer_layer_cls_to_wrap'] = [\n",
    "    'DecoderLayer', 'EncoderLayer', 'PerceptionTokenizer', 'MetaFormersBlock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (1916843494.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[70], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    kw = {'process_group': '<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f98d0b26930>', 'sharding_strategy': \"<ShardingStrategy.FULL_SHARD: 1>\",\" 'auto_wrap_policy': \"functools.partial(<function transformer_auto_wrap_policy at 0x7f9b74cff7f0>\", transformer_layer_cls={<class 'llm_mm_aligner.lib.tokenizers.mm_tokenizer.PerceptionTokenizer'>, MetaLayer(infix='EncoderLayer'), <class 'llm_mm_aligner.metaformers_clone.src.llama3.model.transformer.TransformerBlock'>, MetaLayer(infix='DecoderLayer')}), 'cpu_offload': CPUOffload(offload_params=False), 'mixed_precision': MixedPrecision(param_dtype=torch.bfloat16, reduce_dtype=torch.bfloat16, buffer_dtype=None, keep_low_precision_grads=False, cast_forward_inputs=True, cast_root_forward_inputs=True, _module_classes_to_ignore=(<class 'torch.nn.modules.batchnorm._BatchNorm'>,)), 'device_id': device(type='cuda', index=3), 'backward_prefetch': 'backward_pre', 'forward_prefetch': False, 'limit_all_gathers': True, 'use_orig_params': True}\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "kw = {\n",
    "    'process_group': '<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f98d0b26930>', \n",
    "    'sharding_strategy': \"<ShardingStrategy.FULL_SHARD: 1>\",\" \n",
    "    'auto_wrap_policy': \"functools.partial(<function transformer_auto_wrap_policy at 0x7f9b74cff7f0>\", \n",
    "    transformer_layer_cls={<class 'llm_mm_aligner.lib.tokenizers.mm_tokenizer.PerceptionTokenizer'>, \n",
    "        MetaLayer(infix='EncoderLayer'), \n",
    "        <class 'llm_mm_aligner.metaformers_clone.src.llama3.model.transformer.TransformerBlock'>, \n",
    "        MetaLayer(infix='DecoderLayer')}), \n",
    "        'cpu_offload': CPUOffload(offload_params=False), \n",
    "        'mixed_precision': MixedPrecision(param_dtype=torch.bfloat16, reduce_dtype=torch.bfloat16, buffer_dtype=None, keep_low_precision_grads=False, cast_forward_inputs=True, cast_root_forward_inputs=True, _module_classes_to_ignore=(<class 'torch.nn.modules.batchnorm._BatchNorm'>,)), \n",
    "        'device_id': device(type='cuda', index=3), \n",
    "        'backward_prefetch': 'backward_pre', 'forward_prefetch': False, 'limit_all_gathers': True, 'use_orig_params': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_model_args['custom_FSDP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DecoderLayer', 'EncoderLayer', 'PerceptionTokenizer', 'MetaFormersBlock']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse_training_args['fsdp_config']['fsdp_transformer_layer_cls_to_wrap']\n",
    "parse_training_args['fsdp_config']['transformer_layer_cls_to_wrap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.accelerator_config.use_configured_state = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'split_batches': False,\n",
       " 'dispatch_batches': None,\n",
       " 'even_batches': True,\n",
       " 'use_seedable_sampler': True,\n",
       " 'non_blocking': False,\n",
       " 'gradient_accumulation_kwargs': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.accelerator_config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = {'output_dir': '/data/home/yastashonok/mm6_pretrain/output/mm6_pretrain', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 1, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.0001, 'weight_decay': 0.1, 'adam_beta1': 0.9, 'adam_beta2': 0.95, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 1.0, 'max_steps': -1, 'lr_scheduler_type': 'cosine', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 200, 'log_level': 'info', 'log_level_replica': 'info', 'log_on_each_node': True, 'logging_dir': '/data/home/yastashonok/mm6_pretrain/output/mm6_pretrain/runs/Jul19_14-55-59_h100-st-p548xlarge-36', 'logging_strategy': 'steps', 'logging_first_step': True, 'logging_steps': 10, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 250, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 2024, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': True, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 4, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 250.0, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'mm6_pretrain', 'disable_tqdm': False, 'remove_unused_columns': False, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'greater_is_better': False, 'ignore_data_skip': False, 'fsdp': ['full_shard', 'auto_wrap'], 'fsdp_min_num_params': 0, 'fsdp_config': {'forward_prefetch': False, 'backward_prefetch': 'backward_pre', 'limit_all_gathers': True, 'transformer_layer_cls_to_wrap': ['DecoderLayer',\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           'EncoderLayer', 'PerceptionTokenizer', 'MetaFormersBlock'], 'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': False, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': 'no', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'save_top_k': 1, 'load_latest_k': 1, 'checkpoints_optimizer': None, 'checkpoints_scheduler': None, 'dpo_alpha': 0.0, 'dpo_beta': 0.1, 'dpo_reference_free': False, 'dpo_label_smoothing': 0.0, 'ipo': False, 'simpo_beta': 2.0, 'simpo_gamma': 1.0, 'mixin_gamma': 1.0, 'load_best_model': False, 'clip_head_weight_decay': None, 'lm_text_lr_scale': 1.0, 'perception_lr_scale': 1.0, 'tb_logdir': None, 'eval_ckpt': None, 'eval_type': None, 'cosine_decay_to': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.eval_on_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'forward_prefetch': False,\n",
       " 'backward_prefetch': 'backward_pre',\n",
       " 'limit_all_gathers': True,\n",
       " 'transformer_layer_cls_to_wrap': ['DecoderLayer',\n",
       "  'EncoderLayer',\n",
       "  'PerceptionTokenizer',\n",
       "  'MetaFormersBlock'],\n",
       " 'min_num_params': 0,\n",
       " 'xla': False,\n",
       " 'xla_fsdp_v2': False,\n",
       " 'xla_fsdp_grad_ckpt': False}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.fsdp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.fsdp_config = {'forward_prefetch': False,\n",
    "                             'backward_prefetch': 'backward_pre',\n",
    "                             'limit_all_gathers': True,\n",
    "                             'transformer_layer_cls_to_wrap': ['DecoderLayer',\n",
    "                                                               'EncoderLayer',\n",
    "                                                               'PerceptionTokenizer',\n",
    "                                                               'MetaFormersBlock'],\n",
    "                             'min_num_params': 0,\n",
    "                             'xla': False,\n",
    "                             'xla_fsdp_v2': False,\n",
    "                             'xla_fsdp_grad_ckpt': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'forward_prefetch': False,\n",
       " 'backward_prefetch': 'backward_pre',\n",
       " 'limit_all_gathers': True,\n",
       " 'transformer_layer_cls_to_wrap': ['DecoderLayer',\n",
       "  'EncoderLayer',\n",
       "  'PerceptionTokenizer',\n",
       "  'MetaFormersBlock'],\n",
       " 'min_num_params': 0,\n",
       " 'xla': False,\n",
       " 'xla_fsdp_v2': False,\n",
       " 'xla_fsdp_grad_ckpt': False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"fsdp_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'eval_on_start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_on_start\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'eval_on_start'"
     ]
    }
   ],
   "source": [
    "s[\"eval_on_start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.eval_on_start = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataTrainingArguments' object has no attribute 'to_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m meta_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_args\u001b[39m\u001b[38;5;124m\"\u001b[39m: training_args\u001b[38;5;241m.\u001b[39mto_dict(),\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_args\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_args\u001b[38;5;241m.\u001b[39mto_dict(),\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_args\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mdata_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m()\n\u001b[1;32m      5\u001b[0m }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataTrainingArguments' object has no attribute 'to_dict'"
     ]
    }
   ],
   "source": [
    "meta_args = {\n",
    "    \"training_args\": training_args.to_dict(),\n",
    "    \"model_args\": model_args.to_dict(),\n",
    "    \"data_args\": data_args.to_dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataTrainingArguments' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data_args:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(item)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataTrainingArguments' object is not iterable"
     ]
    }
   ],
   "source": [
    "for item in data_args:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llm_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'llm_common' from '/fsx_0/user/tranx/xlformers/src/finetune/packages/llm_common/llm_common/__init__.py'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_training_axioms(\n",
    "    model_args: ModelArguments,\n",
    "    data_args: DataTrainingArguments,\n",
    "    training_args: TrainingArguments,\n",
    "):\n",
    "    \"\"\"This function sets what should always be true for the training process\"\"\"\n",
    "    if model_args.lora_tokenizer:\n",
    "        model_args.parallelize_perception_tokenizer = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_training_axioms(model_args, data_args, training_args)\n",
    "\n",
    "# Get GPU ranks\n",
    "local_rank = get_local_rank()\n",
    "global_rank = get_global_rank()\n",
    "\n",
    "preemption_monitor_factory.create_preemption_monitor(global_rank)\n",
    "\n",
    "mixin_model_args = replace(\n",
    "    model_args,\n",
    "    modality=model_args.mixin_modality,\n",
    ")\n",
    "\n",
    "mixin_data_args = replace(\n",
    "    data_args,\n",
    "    train_file=data_args.mixin_file,\n",
    "    filetype=data_args.mixin_filetype,\n",
    "    max_train_samples=None,\n",
    "    use_hive_dataset=False,\n",
    "    task_type=data_args.mixin_task_type,\n",
    "    instr_prompt=data_args.mixin_instr_prompt,\n",
    "    dataset_name=\"MMdataset\",\n",
    ")\n",
    "\n",
    "# handle ensemble case\n",
    "if model_args.use_ensemble_modality_tokenizer:\n",
    "    # parse modality_tokenizer_name into a list of modality_tokenizers\n",
    "    model_args.modality_tokenizer_name = ast.literal_eval(\n",
    "        model_args.modality_tokenizer_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TrainingArguments' object has no attribute 'auto_wrap_policy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_wrap_policy\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TrainingArguments' object has no attribute 'auto_wrap_policy'"
     ]
    }
   ],
   "source": [
    "training_args."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_num_params': 0,\n",
       " 'xla': False,\n",
       " 'xla_fsdp_v2': False,\n",
       " 'xla_fsdp_grad_ckpt': False,\n",
       " 'fsdp_transformer_layer_cls_to_wrap': ['DecoderLayer',\n",
       "  'EncoderLayer',\n",
       "  'PerceptionTokenizer',\n",
       "  'MetaFormersBlock'],\n",
       " 'forward_prefetch': False,\n",
       " 'backward_prefetch': 'backward_pre',\n",
       " 'limit_all_gathers': True}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.fsdp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "DistStoreError",
     "evalue": "Timed out after 601 seconds waiting for clients. 1/8 clients joined.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDistStoreError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMASTER_ADDR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMASTER_PORT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m29500\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_process_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnccl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mis_initialized()\n",
      "File \u001b[0;32m/opt/hpcaas/.mounts/fs-04cb39659581b642e/home/tranx/conda/envs/aligner_v1/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:75\u001b[0m, in \u001b[0;36m_exception_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     77\u001b[0m         msg_dict \u001b[38;5;241m=\u001b[39m _get_msg_dict(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/hpcaas/.mounts/fs-04cb39659581b642e/home/tranx/conda/envs/aligner_v1/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:89\u001b[0m, in \u001b[0;36m_time_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[1;32m     88\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n\u001b[0;32m---> 89\u001b[0m     func_return \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns() \u001b[38;5;241m-\u001b[39m t1\n\u001b[1;32m     92\u001b[0m     msg_dict \u001b[38;5;241m=\u001b[39m _get_msg_dict(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/hpcaas/.mounts/fs-04cb39659581b642e/home/tranx/conda/envs/aligner_v1/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:1305\u001b[0m, in \u001b[0;36minit_process_group\u001b[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options, device_id)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m store \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1302\u001b[0m     rendezvous_iterator \u001b[38;5;241m=\u001b[39m rendezvous(\n\u001b[1;32m   1303\u001b[0m         not_none(init_method), rank, world_size, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1304\u001b[0m     )\n\u001b[0;32m-> 1305\u001b[0m     store, rank, world_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrendezvous_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1306\u001b[0m     store\u001b[38;5;241m.\u001b[39mset_timeout(timeout)\n\u001b[1;32m   1308\u001b[0m     \u001b[38;5;66;03m# Use a PrefixStore to avoid accidental overrides of keys used by\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;66;03m# different systems (e.g. RPC) in case the store is multi-tenant.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/hpcaas/.mounts/fs-04cb39659581b642e/home/tranx/conda/envs/aligner_v1/lib/python3.10/site-packages/torch/distributed/rendezvous.py:246\u001b[0m, in \u001b[0;36m_env_rendezvous_handler\u001b[0;34m(url, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m master_port \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(_get_env_or_raise(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMASTER_PORT\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    244\u001b[0m use_libuv \u001b[38;5;241m=\u001b[39m query_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_libuv\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSE_LIBUV\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 246\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c10d_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaster_addr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster_port\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_libuv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m (store, rank, world_size)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# If this configuration is invalidated, there is nothing we can do about it\u001b[39;00m\n",
      "File \u001b[0;32m/opt/hpcaas/.mounts/fs-04cb39659581b642e/home/tranx/conda/envs/aligner_v1/lib/python3.10/site-packages/torch/distributed/rendezvous.py:174\u001b[0m, in \u001b[0;36m_create_c10d_store\u001b[0;34m(hostname, port, rank, world_size, timeout, use_libuv)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     start_daemon \u001b[38;5;241m=\u001b[39m rank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTCPStore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhostname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_daemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_tenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_libuv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_libuv\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mDistStoreError\u001b[0m: Timed out after 601 seconds waiting for clients. 1/8 clients joined."
     ]
    }
   ],
   "source": [
    "import torch.distributed as dist\n",
    "os.environ['RANK'] = '0'\n",
    "os.environ['WORLD_SIZE'] = '8'\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '29500'\n",
    "\n",
    "dist.init_process_group(backend='nccl')\n",
    "torch.distributed.is_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_args\u001b[38;5;241m.\u001b[39muse_ensemble_modality_tokenizer:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# parse modality_tokenizer_name into a list of modality_tokenizers\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     model_args\u001b[38;5;241m.\u001b[39mmodality_tokenizer_name \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(\n\u001b[1;32m      5\u001b[0m         model_args\u001b[38;5;241m.\u001b[39mmodality_tokenizer_name\n\u001b[1;32m      6\u001b[0m     )\n\u001b[0;32m----> 8\u001b[0m \u001b[43minitialize_model_parallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor_model_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_parallel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline_model_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvirtual_pipeline_model_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline_model_parallel_split_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_fp8\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43malternate_pp_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_parallel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackground_nccl_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshared_kv_head_group_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/fsx_0/user/tranx/llm_mm_aligner/lib/mpu.py:188\u001b[0m, in \u001b[0;36minitialize_model_parallel\u001b[0;34m(tensor_model_parallel_size, pipeline_model_parallel_size, virtual_pipeline_model_parallel_size, pipeline_model_parallel_split_rank, use_fp8, alternate_pp_config, context_parallel_size, background_nccl_init, shared_kv_head_group_size)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize model data parallel groups.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    tensor_model_parallel_size (int, default = 1):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03mranks 8 to 15 belong to the second box.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# Get world size and rank. Ensure some consistencies.\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mis_initialized()\n\u001b[1;32m    189\u001b[0m world_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mget_world_size()\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    192\u001b[0m     world_size\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    199\u001b[0m ):\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "initialize_model_parallel(\n",
    "    tensor_model_parallel_size=model_args.model_parallel_size,\n",
    "    pipeline_model_parallel_size=1,\n",
    "    virtual_pipeline_model_parallel_size=None,\n",
    "    pipeline_model_parallel_split_rank=None,\n",
    "    use_fp8=False,\n",
    "    alternate_pp_config=False,\n",
    "    context_parallel_size=model_args.context_parallel_size,\n",
    "    background_nccl_init=False,\n",
    "    shared_kv_head_group_size=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error: Could not infer dtype of numpy.uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.as_tensor([3, 4], dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "as_tensor(): argument 'dtype' must be torch.dtype, not type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: as_tensor(): argument 'dtype' must be torch.dtype, not type"
     ]
    }
   ],
   "source": [
    "t = torch.as_tensor([3, 4], dtype=np.uint8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
