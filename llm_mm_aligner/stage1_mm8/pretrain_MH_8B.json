{
  "scheduler_type": "mast_grand_teton",
  "hpc_job_oncall": "sg_scene_ai",
  "num_gpus": 8,
  "num_nodes": 64,
  "trainer_args": {
    "gradient_checkpointing_perception_tokenizer": true,
    "model_name_or_path": "/fsx_0/checkpoints/tranx/Meta-Llama-3-8B-Instruct",
    "tokenizer_path": "/fsx_0/checkpoints/tranx/Meta-Llama-3-8B-Instruct",
    "lm_mh_tokenizer_version": "tiktoken_v5",
    "use_metaformers": true,
    "block_sparse": true,
    "modality_tokenizer_name": "/fsx_0/checkpoints/tranx/MetaCLIP-BigG-504-0701",
    "perceiver_dim_override": 4096,
    "perceiver_num_heads": 32,
    "perceiver_num_kv_heads": 8,
    "model_parallel_size": 1,
    "max_parallel_model_loading": 8,
    "freeze_perception": true,
    "freeze_tokenizer": false,
    "freeze_lm": true,
    "use_face_detector": false,
    "task_type": "captioning",
    "n_prefix_embs": 65,
    "perceiver_num_latents": 64,
    "perceiver_collapse_chunks": false,
    "hive_batch_size": 64,
    "onbox_num_python_transform_workers": 4,
    "onbox_dpp_server_num_worker_threads": 4,
    "onbox_dpp_server_worker_buffer_size": 64,
    "onbox_dpp_client_num_prefetch_threads": 4,
    "onbox_dpp_client_prefetch_capacity": 64,
    "use_hive_dataset": false,
    "wd_data_path": "/fsx_2/datasets_30days/sg_mmllm_stage1_m2c2v3_sstk_10x_arxiv_pdf_mix_v6/20240723",
    "wd_chunk_size": 1000,
    "filetype": "jsonlines",
    "dataset_name": "RecipeBaseDataset",
    "add_bos_token": false,
    "add_eos_token": false,
    "instruction_model_type": "TikTokv5ChatFormat",
    "output_dir": "/fsx_0/checkpoints/tranx/Aligner-Pretrain-8B/output_n2_retrain",
    "vision_hidden_state_layer": -2,
    "do_train": null,
    "logging_steps": 10,
    "max_seq_len": 512,
    "overwrite_output_dir": null,
    "num_train_epochs": 1,
    "logging_first_step": null,
    "per_device_train_batch_size": 32,
    "per_device_eval_batch_size": 32,
    "gradient_accumulation_steps": 1,
    "dataloader_pin_memory": false,
    "learning_rate": 0.0001,
    "adam_beta1": 0.9,
    "adam_beta2": 0.95,
    "weight_decay": 0.1,
    "warmup_steps": 200,
    "lr_scheduler_type": "cosine",
    "cosine_decay_to": 0.01,
    "remove_unused_columns": false,
    "log_level": "info",
    "log_level_replica": "info",
    "run_name": "$name",
    "half_precision_backend": "auto",
    "optim": "adamw_torch",
    "report_to": "tensorboard",
    "modality": "image",
    "tokenizer_type": "PerceiverV3",
    "perception_tokenizer_num_layers": 8,
    "perception_tokenizer_attention_dropout_p": 0.05,
    "perception_tokenizer_hidden_dropout_p": 0.1,
    "bf16": true,
    "save_strategy": "steps",
    "save_steps": 250,
    "evaluation_strategy": "no",
    "eval_steps": 250,
    "metric_for_best_model": "eval_loss",
    "greater_is_better": false,
    "seed": 2024,
    "custom_FSDP": null,
    "num_image_chunks": 3,
    "add_resized_image": true,
    "chunk_size": 504,
    "resize_longest": true,
    "pad_to_full_batch": true,
    "max_tokens_in_batch_row": 512,
    "max_tokens_in_batch": 1024
  },
  "fsdp_config": {
    "fsdp_transformer_layer_cls_to_wrap": [
      "EncoderLayer",
      "MMTokenizer",
      "PerceptionTokenizer",
      "MetaFormersBlock"
    ],
    "forward_prefetch": false,
    "backward_prefetch": "backward_pre",
    "limit_all_gathers": true,
    "fsdp": [
      "full_shard",
      "auto_wrap"
    ]
  },
  "datarecipe": {
    "table": {
      "name": "sg_mmllm_stage1_m2c2v3_sstk_10x_arxiv_pdf_mix_v6",
      "namespace": "arvr",
      "partitions": {
        "ds": "2024-07-01"
      },
      "filters": [],
      "schema": {
        "image_manifold_path": "str",
        "text": "str"
      },
      "enrichment_configs": [
        {
          "name": "manifold",
          "lookup_value": "image_manifold_path",
          "output_column": "manifold_image"
        }
      ],
      "retention_days": 90,
      "n_buckets": 16384
    },
    "sources": []
  }
}