{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "import time\n",
    "\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "def read_file_lines(file_path: str):\n",
    "    try:\n",
    "        # with open(file_path, 'r') as f:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        return lines\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "def get_loss_values(job_log):\n",
    "    lines = read_file_lines(job_log)\n",
    "    loss_values = []\n",
    "    \n",
    "    for line in lines:\n",
    "        match = re.search(r\"'loss': (\\d+\\.\\d+)\", line)\n",
    "        if match:\n",
    "            loss_value = float(match.group(1))\n",
    "            loss_values.append(loss_value)\n",
    "    \n",
    "    return loss_values\n",
    "\n",
    "def plot_train_loss(\n",
    "    loss_dict: Dict[str, List[float]], \n",
    "    title: Optional[str] = None, \n",
    "    skip_steps: Optional[Dict[str, int]]= None\n",
    "):\n",
    "    \"\"\"\n",
    "    loss_dict = {\n",
    "        name: [loss array],\n",
    "        name2: [loss array2],\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    if skip_steps is None:\n",
    "        skip_steps = {}\n",
    "        \n",
    "    fig = go.Figure()\n",
    "\n",
    "    for name, loss_array in loss_dict.items():\n",
    "        skip = skip_steps.get(name, 0)\n",
    "        steps = [skip + 10*i for i in range(len(loss_array))]\n",
    "        fig.add_trace(go.Scatter(x=steps, y=loss_array, name=name))\n",
    "\n",
    "    fig.update_layout(title=f'Train Loss: {name}',\n",
    "                      xaxis_title='Step',\n",
    "                      yaxis_title='Loss')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MM8 Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict = {\n",
    "    # \"70b_8node_yury_6717\": \"/data/home/yastashonok/logs/output_6717.txt\",\n",
    "    # \"70b_64node_harry_6733\": \"/fsx_0/user/tranx/output/slurm_logs/output_6733.txt\",\n",
    "    # \"70b_128node_harry_6743\": \"/fsx_0/user/tranx/output/slurm_logs/output_6743.txt\",\n",
    "    # \"70b_8node_harry_6815_w_BroadcastDataset\": \"/fsx_0/user/tranx/output/slurm_logs/output_6815.txt\",\n",
    "    # \"70b_128node_harry_6839_w_BroadcastDataset\": \"/fsx_0/user/tranx/output/slurm_logs/output_6839.txt\",\n",
    "    # \"70b_160node_harry_6840_w_BroadcastDataset\": \"/fsx_0/user/tranx/output/slurm_logs/output_6840.txt\"\n",
    "    \"70B_160node_AWS\": \"/fsx_0/user/tranx/output/slurm_logs/output_6840.txt\"\n",
    "}\n",
    "\n",
    "loss_values = {}\n",
    "for name, log in log_dict.items():\n",
    "    print(name, log)\n",
    "    loss_values[name] = get_loss_values(log)\n",
    "\n",
    "fig = go.Figure()\n",
    "for name, losses in loss_values.items():\n",
    "    steps = list(range(len(losses)))\n",
    "\n",
    "    if name == \"70b_128node_harry_6839_w_BroadcastDataset\":\n",
    "        gap = len(loss_values[\"70b_128node_harry_6743\"])\n",
    "        steps = [s + gap for s in steps]\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=steps, y=losses, name=name))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 70B - fixed pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    \"70B_160node_AWS-1\": \"/fsx_0/user/tranx/output/slurm_logs/output_6840.txt\",\n",
    "    \"70B_256node_AWS-2\": \"/fsx_0/user/tranx/output/slurm_logs/output_6926.txt\",\n",
    "    \"70B_256node_AWS-3\": \"/fsx_0/user/tranx/output/slurm_logs/output_6939.txt\"\n",
    "}\n",
    "\n",
    "checkpoint_interval = 200\n",
    "\n",
    "loss_values = {}\n",
    "for name, log in runs.items():\n",
    "    print(name, log)\n",
    "    loss_values[name] = get_loss_values(log)\n",
    "\n",
    "fig = go.Figure()\n",
    "resume_step = 0\n",
    "\n",
    "for name, losses in loss_values.items():\n",
    "    steps = [resume_step + 10*i for i in range(len(losses))]\n",
    "    resume_step = steps[-1]\n",
    "    resume_step = checkpoint_interval * (resume_step // checkpoint_interval)\n",
    "    fig.add_trace(go.Scatter(x=steps, y=losses, name=name))\n",
    "\n",
    "fig.update_layout(title='Loss Values',\n",
    "                  xaxis_title='Steps',\n",
    "                  yaxis_title='Loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [\n",
    "    \"/fsx_0/user/tranx/output/slurm_logs/output_6840.txt\",\n",
    "    \"/fsx_0/user/tranx/output/slurm_logs/output_6926.txt\",\n",
    "    \"/fsx_0/user/tranx/output/slurm_logs/output_6939.txt\"\n",
    "]\n",
    "\n",
    "aws_loss = []\n",
    "for log in runs:\n",
    "    loss = get_loss_values(log)\n",
    "    aws_loss.extend(loss)\n",
    "aws_steps = [10*i for i in range(len(aws_loss))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/train_loss_f578009631.csv\")\n",
    "fbl_steps = df.step\n",
    "fbl_loss = df.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fbl_steps = [10, 70, 800, 1000, 2000]  # , 4000]\n",
    "# fbl_loss = [9.581, 2.498, 1.348, 1.225, 1.121]  # , 1.065]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=aws_steps, y=aws_loss, name=\"AWS\"))\n",
    "fig.add_trace(go.Scatter(x=fbl_steps, y=fbl_loss, name=\"FBL\"))\n",
    "# fig.add_trace(go.Scatter(x=fbl_steps, y=fbl_loss, name=\"FBL\",\n",
    "#               mode=\"markers\", marker_symbol=\"star\", marker_size=10))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='AWS vs. FBL comparison: 70B MM8 train loss',\n",
    "    xaxis_title='Steps',\n",
    "    yaxis_title='Loss',\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MM9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict = {\n",
    "    \"MM9_70B_2nodes\": \"/fsx_0/user/tranx/output/slurm_logs/output_6955.txt\"\n",
    "}\n",
    "\n",
    "loss_values = {}\n",
    "for name, log in log_dict.items():\n",
    "    print(name, log)\n",
    "    loss_values[name] = get_loss_values(log)\n",
    "\n",
    "fig = go.Figure()\n",
    "for name, losses in loss_values.items():\n",
    "    steps = [10*i for i in range(len(losses))]\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=steps, y=losses, name=name))\n",
    "\n",
    "fig.update_layout(title='Train Loss',\n",
    "                  xaxis_title='Step',\n",
    "                  yaxis_title='Loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [6973, 6977]\n",
    "losses = []\n",
    "for j in runs:\n",
    "    log = f\"/fsx_0/user/tranx/output/slurm_logs/output_{j}.txt\"\n",
    "    print(f\"reading losses from {log}\")\n",
    "    log_losses = get_loss_values(log)\n",
    "    losses.extend(log_losses)\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "steps = [10*i for i in range(len(losses))]\n",
    "\n",
    "name = \"MM9_70B_Llama3.1\"\n",
    "fig.add_trace(go.Scatter(x=steps, y=losses, name=\"MM9_70B_Llama3.1\"))\n",
    "\n",
    "fig.update_layout(title=f'Train Loss: {name}',\n",
    "                  xaxis_title='Step',\n",
    "                  yaxis_title='Loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MM9_70B_Llama3.1_336px_128nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FBL config\n",
    "\n",
    "runs = [7024]\n",
    "losses = []\n",
    "for j in runs:\n",
    "    log = f\"/fsx_0/user/tranx/output/slurm_logs/output_{j}.txt\"\n",
    "    print(f\"reading losses from {log}\")\n",
    "    log_losses = get_loss_values(log)\n",
    "    losses.extend(log_losses)\n",
    "\n",
    "\n",
    "plot_train_loss(\n",
    "    loss_dict={\"MM9_70B_Llama3.1\": losses},\n",
    "    title=\"MM9_70B_Llama3.1_336px_128nodes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MM9 - all runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\n",
    "    # \"/data/home/tranx/run_516421604076231-4-train_loss.csv\",\n",
    "    \"/data/home/tranx/train_loss_f578009631_0806.csv\",\n",
    "    # \"train_loss_f578009631_0806.csv\"\n",
    "    header=None, skiprows=1\n",
    ")\n",
    "df.columns = ['step', 'loss']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    # \"#1 MM9_70B_Llama3.1_336px_128nodes\": [7024],\n",
    "    # \"#1.1 MM9_70B_Llama3.1_336px_128nodes_fixed\": [7204],\n",
    "    \"#1.2 MM9_70B_Llama3.1_336px_128nodes_bz32_retrain\": [7260],\n",
    "    # \"#1.3 MM9_70B_Llama3.1_336px_128nodes_fixed_norm_loss\": [7304],\n",
    "    # \"#2 MM9_70B_Llama3.1_504px_128nodes\": [7047],\n",
    "    # \"#3 MM9_70B_MH19_336px_128nodes\": [7044, 7118],\n",
    "    # \"#3.1 MM9_70B_MH19_336px_128nodes_bz64\": [7119],\n",
    "    \"#3.2 MM9_70B_MH19_336px_128nodes_fixed\": [7144],\n",
    "    \"#3.3 MM9_70B_MH19_336px_128nodes_bz32_retrain\": [7261],\n",
    "    # \"#3.4 MM9_70B_MH19_336px_128nodes_bz48_retrain\": [7339],\n",
    "    \"#3.5 MM9_70B_MH19_336px_384nodes_bz32\": [7343],\n",
    "    \"#3.6 MM9_70B_MH19_336px_256nodes_bz32\": [7465],\n",
    "\n",
    "    # \"#4 MM9_70B_Llama3.1_336px_256nodes\": [7083]\n",
    "\n",
    "    # \"#1.3 MM9_70B_Llama3.1_336px_128nodes_fixed_norm_loss\": [7304],\n",
    "}\n",
    "\n",
    "skip_steps = {\n",
    "    \"#1.1 MM9_70B_Llama3.1_336px_128nodes_fixed\": 1200,\n",
    "    \"#3.1 MM9_70B_MH19_336px_128nodes_bz64\": 2300,\n",
    "    \"#3.2 MM9_70B_MH19_336px_128nodes_fixed\": 3300,  # 1000\n",
    "    \"#4 MM9_70B_Llama3.1_336px_256nodes\": 3000,\n",
    "    \"#3.5 MM9_70B_MH19_336px_384nodes_bz32\": 2100,\n",
    "    # \"#1.2 MM9_70B_Llama3.1_336px_128nodes__retrain\": -100,\n",
    "    # \"#3.3 MM9_70B_MH19_336px_128nodes_fixed_retrain\": -100,\n",
    "    \"#3.6 MM9_70B_MH19_336px_256nodes_bz32\": 7500\n",
    "}\n",
    "\n",
    "\n",
    "def plot_scheme_loss(scheme):\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for s in schemes:\n",
    "        # read loss from jobs\n",
    "        if \"jobs\" in s:\n",
    "            s[\"loss\"] = []\n",
    "            for j in s[\"jobs\"]:\n",
    "                log = f\"/fsx_0/user/tranx/output/slurm_logs/output_{j}.txt\"\n",
    "                print(f\"Reading loss from {log}\")\n",
    "                loss_j = get_loss_values(log)\n",
    "                s[\"loss\"].extend(loss_j)\n",
    "\n",
    "        steps = [s[\"resume_step\"] + i*s[\"step_scale\"]\n",
    "                 for i in range(len(s[\"loss\"]))]\n",
    "\n",
    "        if 'color' in s:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=steps, y=s[\"loss\"], name=s[\"name\"], mode='lines', line=dict(color=s['color'])))\n",
    "        else:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=steps, y=s[\"loss\"], name=s[\"name\"], mode='lines'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Train Loss', xaxis_title='Step', yaxis_title='Loss',\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02),\n",
    "        yaxis=dict(range=[0.8, 1.6])\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "schemes = [\n",
    "    {\n",
    "        \"name\": \"#5 f587797729_70B_Llama3.1_336px_128nodes_bz64\",\n",
    "        \"loss\": df['loss'],\n",
    "        \"resume_step\": 0,\n",
    "        \"step_scale\": 10,  # 10 for bz=32, gradient_accumulation_step=4, nodes=128\n",
    "        \"color\": \"black\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"#1.2 MM9_70B_Llama3.1_336px_128nodes_bz32_retrain\",\n",
    "        \"jobs\": [7260, 7499],\n",
    "        \"resume_step\": 0,\n",
    "        \"step_scale\": 10,  # 10 for bz=32, gradient_accumulation_step=4, nodes=128\n",
    "        \"color\": \"blue\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"#3.2 MM9_70B_MH19_336px_128nodes_fixed\",\n",
    "        \"jobs\": [7144],\n",
    "        \"resume_step\": 3300,\n",
    "        \"step_scale\": 10,\n",
    "        \"color\": \"red\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"#3.3 MM9_70B_MH19_336px_128nodes_retrain\",\n",
    "        \"jobs\": [7261],\n",
    "        \"resume_step\": 0,\n",
    "        \"step_scale\": 10,\n",
    "        \"color\": \"red\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"#3.5 MM9_70B_MH19_336px_384nodes\",\n",
    "        \"jobs\": [7343],\n",
    "        \"resume_step\": 2100,\n",
    "        \"step_scale\": 30,\n",
    "        \"color\": \"red\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"#3.6 MM9_70B_MH19_336px_256nodes\",\n",
    "        \"jobs\": [7465],\n",
    "        \"resume_step\": 7500,\n",
    "        \"step_scale\": 20,\n",
    "        \"color\": \"red\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"#3.7 MM9_70B_MH19_336px_128nodes_resume\",\n",
    "        \"jobs\": [7700],\n",
    "        \"resume_step\": 8500,\n",
    "        \"step_scale\": 10,\n",
    "        \"color\": \"red\"\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "plot_scheme_loss(schemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_loss2(\n",
    "    loss_dict: Dict[str, List[float]],\n",
    "    title: Optional[str] = None,\n",
    "    skip_steps: Optional[Dict[str, int]] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    loss_dict = {\n",
    "        name: [loss array],\n",
    "        name2: [loss array2],\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    if skip_steps is None:\n",
    "        skip_steps = {}\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for name, loss_array in loss_dict.items():\n",
    "        skip = skip_steps.get(name, 0)\n",
    "        log_step = 10\n",
    "\n",
    "        if name in [\n",
    "            # \"f587797729_70B_Llama3.1_336px_128nodes\",\n",
    "            \"MM9_70B_Llama3.1_336px_256nodes\",\n",
    "            \"#3.6 MM9_70B_MH19_336px_256nodes_bz32\",\n",
    "        ]:\n",
    "            log_step = 20\n",
    "        elif name == \"#3.5 MM9_70B_MH19_336px_384nodes_bz32\":\n",
    "            log_step = 30\n",
    "\n",
    "        steps = [skip + log_step*i for i in range(len(loss_array))]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=steps, y=loss_array, name=name, mode='lines'))\n",
    "\n",
    "    fig.update_layout(title=f'Train Loss',\n",
    "                      #   xaxis_title='Step (normalized per 128 nodes x bz 32 x grad_accm. 4)',\n",
    "                      xaxis_title='Step',\n",
    "                      yaxis_title='Loss',\n",
    "                      #   legend=dict(orientation=\"h\"),\n",
    "                      legend=dict(\n",
    "                            orientation=\"h\",\n",
    "                            yanchor=\"bottom\", y=1.02\n",
    "                            # xanchor=\"center\"\n",
    "                      ),\n",
    "                      yaxis=dict(range=[0.8, 1.4])\n",
    "                      #   xaxis=dict(range=[0, 7000]), yaxis=dict(range=[1.0, 1.4]),\n",
    "                      #   width=800, height=600,\n",
    "                      )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "runs = {\n",
    "    # \"#1 MM9_70B_Llama3.1_336px_128nodes\": [7024],\n",
    "    # \"#1.1 MM9_70B_Llama3.1_336px_128nodes_fixed\": [7204],\n",
    "    \"#1.2 MM9_70B_Llama3.1_336px_128nodes_bz32_retrain\": [7260],\n",
    "    # \"#1.3 MM9_70B_Llama3.1_336px_128nodes_fixed_norm_loss\": [7304],\n",
    "    # \"#2 MM9_70B_Llama3.1_504px_128nodes\": [7047],\n",
    "    # \"#3 MM9_70B_MH19_336px_128nodes\": [7044, 7118],\n",
    "    # \"#3.1 MM9_70B_MH19_336px_128nodes_bz64\": [7119],\n",
    "    \"#3.2 MM9_70B_MH19_336px_128nodes_fixed\": [7144],\n",
    "    \"#3.3 MM9_70B_MH19_336px_128nodes_bz32_retrain\": [7261],\n",
    "    # \"#3.4 MM9_70B_MH19_336px_128nodes_bz48_retrain\": [7339],\n",
    "    \"#3.5 MM9_70B_MH19_336px_384nodes_bz32\": [7343],\n",
    "    \"#3.6 MM9_70B_MH19_336px_256nodes_bz32\": [7465],\n",
    "\n",
    "    # \"#4 MM9_70B_Llama3.1_336px_256nodes\": [7083]\n",
    "\n",
    "    # \"#1.3 MM9_70B_Llama3.1_336px_128nodes_fixed_norm_loss\": [7304],\n",
    "}\n",
    "\n",
    "skip_steps = {\n",
    "    \"#1.1 MM9_70B_Llama3.1_336px_128nodes_fixed\": 1200,\n",
    "    \"#3.1 MM9_70B_MH19_336px_128nodes_bz64\": 2300,\n",
    "    \"#3.2 MM9_70B_MH19_336px_128nodes_fixed\": 3300,  # 1000\n",
    "    \"#4 MM9_70B_Llama3.1_336px_256nodes\": 3000,\n",
    "    \"#3.5 MM9_70B_MH19_336px_384nodes_bz32\": 2100,\n",
    "    # \"#1.2 MM9_70B_Llama3.1_336px_128nodes__retrain\": -100,\n",
    "    # \"#3.3 MM9_70B_MH19_336px_128nodes_fixed_retrain\": -100,\n",
    "    \"#3.6 MM9_70B_MH19_336px_256nodes_bz32\": 7500\n",
    "}\n",
    "\n",
    "\n",
    "loss_dict = {}\n",
    "for name in runs:\n",
    "    loss_dict[name] = []\n",
    "    for j in runs[name]:\n",
    "        log = f\"/fsx_0/user/tranx/output/slurm_logs/output_{j}.txt\"\n",
    "        print(f\"Reading loss from {log}\")\n",
    "        loss_j = get_loss_values(log)\n",
    "        loss_dict[name].extend(loss_j)\n",
    "\n",
    "# add fb reference loss\n",
    "loss_dict[\"#5 f587797729_70B_Llama3.1_336px_128nodes_bz64\"] = df['loss']\n",
    "\n",
    "plot_train_loss2(loss_dict, skip_steps=skip_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def get_checkpoint_time(dir):\n",
    "    start_ts = os.path.getctime(os.path.join(dir, \"runs\"))\n",
    "    chk_folders = [c for c in os.listdir(dir) if c.startswith('checkpoint')]\n",
    "    chk_folders\n",
    "\n",
    "    chk_list = [[int(c.split('-')[-1]), c] for c in chk_folders]\n",
    "    chk_list = sorted(chk_list)\n",
    "    chk_list\n",
    "\n",
    "    for step, folder in chk_list:\n",
    "        ts = os.path.getctime(os.path.join(dir, folder))\n",
    "        elasped_ts = ts - start_ts\n",
    "        start_ts = ts\n",
    "\n",
    "        print(step, elasped_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir160 = '/fsx_0/checkpoints/tranx/Aligner-Pretrain-70B/output_n160_retrain'\n",
    "dir256 = '/fsx_0/checkpoints/tranx/Aligner-Pretrain-70B/output_n256'\n",
    "get_checkpoint_time(dir160)\n",
    "get_checkpoint_time(dir256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "t160 = int(np.mean([6737.0, 6805.0, 6970.0]))\n",
    "t256 = int(np.mean([8526.0, 8497, 8668]))\n",
    "\n",
    "t160, t256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_200_steps = t160\n",
    "nodes = 160\n",
    "\n",
    "num_images_per_200_steps = 200 * 32 * nodes * 8\n",
    "num_images_per_day = num_images_per_200_steps * 86400 / time_per_200_steps\n",
    "mm_images_per_day = num_images_per_day/1e6\n",
    "int(mm_images_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_200_steps = t256\n",
    "nodes = 256\n",
    "\n",
    "num_images_per_200_steps = 200 * 32 * nodes * 8\n",
    "num_images_per_day = num_images_per_200_steps * 86400 / time_per_200_steps\n",
    "mm_images_per_day = num_images_per_day/1e6\n",
    "int(mm_images_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fbl per 7 days\n",
    "days = 7.768\n",
    "steps = 11840\n",
    "steps_per_day = steps / days\n",
    "num_images_per_day = steps_per_day * 32 * 160 * 8\n",
    "mm_images_per_day = num_images_per_day/1e6\n",
    "int(mm_images_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fbl per 1st day\n",
    "days = 1\n",
    "steps = 1700\n",
    "steps_per_day = steps / days\n",
    "num_images_per_day = steps_per_day * 32 * 160 * 8\n",
    "mm_images_per_day = num_images_per_day/1e6\n",
    "int(mm_images_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = (45739 - 19500) * 32 * 64 * 8  # step x batch_size x nodes x GPUs\n",
    "trained_time = 24 + 14  # hours\n",
    "tput_per_day = num_images / (trained_time/24)\n",
    "tput_M_per_day = tput_per_day / 1e6\n",
    "print(tput_M_per_day)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
