{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import socket\n",
    "import psutil\n",
    "import sys \n",
    "import os\n",
    "from typing import Any\n",
    "from functools import partial\n",
    "import json\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_recent_config_json(directory, file_name='config.json', max_depth=2):\n",
    "    \"\"\"\n",
    "    Find the most recently written config.json file in a directory tree, up to 2 levels deep.\n",
    "    Args:\n",
    "        directory (str): The root directory to search in.\n",
    "    Returns:\n",
    "        str: The path to the most recently written config.json file, or None if no such file is found.\n",
    "    \"\"\"\n",
    "    most_recent_file = None\n",
    "    most_recent_timestamp = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        depth = root.replace(directory, '').count(os.sep)\n",
    "        if max_depth is not None and depth > max_depth:\n",
    "            continue\n",
    "        for file in files:\n",
    "            if file == file_name:\n",
    "                file_path = os.path.join(root, file)\n",
    "                timestamp = os.path.getmtime(file_path)\n",
    "                if timestamp > most_recent_timestamp:\n",
    "                    most_recent_timestamp = timestamp\n",
    "                    most_recent_file = file_path\n",
    "                    \n",
    "    if most_recent_file is not None:\n",
    "        with open(most_recent_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            return data\n",
    "        \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_trainer_state(output_dir: str):\n",
    "    checkpoint_dirs = glob.glob(f\"{output_dir}/checkpoint-*\")\n",
    "    checkpoints = [int(d.split(\"/\")[-1].split(\"-\")[-1]) for d in checkpoint_dirs]\n",
    "    if len(checkpoints) == 0:\n",
    "        return None, None \n",
    "    \n",
    "    checkpoint_latest = max(checkpoints)\n",
    "    # print(f\"{checkpoint_latest=}\")\n",
    "\n",
    "    trainer_state_file = os.path.join(\n",
    "        output_dir,\n",
    "        f\"checkpoint-{checkpoint_latest}\",\n",
    "        \"trainer_state.json\"\n",
    "    )\n",
    "\n",
    "    with open(trainer_state_file, 'r') as file:\n",
    "        state = json.load(file)\n",
    "        \n",
    "    return checkpoint_latest, state\n",
    "\n",
    "\n",
    "def get_train_summary(state, config):\n",
    "    grad_accumulation_steps = config['trainer_args']['gradient_accumulation_steps']\n",
    "    num_nodes = config['slurm_args']['nodes']\n",
    "    num_gpus = config['slurm_args']['gpus_per_task']\n",
    "\n",
    "    mp = config['trainer_args'].get(\"model_parallel_size\", 1)\n",
    "    cp = config['trainer_args'].get(\"context_parallel_size\", 1)\n",
    "    pp = config['trainer_args'].get(\"pipeline_parallel_size\", 1)\n",
    "\n",
    "    num_batches_per_step =  state['logging_steps'] * (num_gpus * num_nodes * grad_accumulation_steps) / (mp * pp * cp)\n",
    "    num_input_tokens = 0\n",
    "    num_modality_tokens = 0\n",
    "\n",
    "    for record in state['log_history'][1:]:\n",
    "        # skipping the first record, which always report step=1\n",
    "        # the subsequent record are for step = 10, 20, 30, ... (assuming logging_step = 10)\n",
    "        num_input_tokens += num_batches_per_step * record['num_input_tokens_per_batch']\n",
    "        num_modality_tokens += num_batches_per_step * record['num_modality_embs_per_batch']\n",
    "        \n",
    "    num_input_tokens, num_modality_tokens\n",
    "    total_tokens = num_input_tokens + num_modality_tokens\n",
    "\n",
    "    # calculate VE tokens\n",
    "    chunk_size = config['trainer_args']['chunk_size']\n",
    "    patch_size = 14\n",
    "    cls_token = False\n",
    "    n_prefix_embs = config['trainer_args']['n_prefix_embs']\n",
    "\n",
    "    compression_ratio = ((chunk_size/patch_size)**2 + int(cls_token)) / n_prefix_embs\n",
    "\n",
    "    summary = {\n",
    "        \"num_steps\": state['global_step'],\n",
    "        \"billion_text_tokens\": int(num_input_tokens/1e9),\n",
    "        \"billion_modality_tokens\": int(num_modality_tokens/1e9),\n",
    "        \"billion_llm_tokens\": int(total_tokens/1e9),\n",
    "        \"billion_visual_tokens\": int(compression_ratio * num_modality_tokens/1e9)\n",
    "    }\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fsx_3/bucket/tranx/checkpoints/perceiver_sizing/Llama3.1_70B_ViTG_layers18_dim4096_heads32_latents64_bz64_step4\n",
      "Llama3.1_70B_ViTG_layers18_dim4096_heads32_latents64_bz64_step4, checkpoint_latest=10600\n",
      "/fsx_3/bucket/tranx/checkpoints/perceiver_sizing/Llama3.1_70B_ViTG_layers22_dim4096_heads32_latents64_bz64_step8\n",
      "Llama3.1_70B_ViTG_layers22_dim4096_heads32_latents64_bz64_step8, checkpoint_latest=11200\n",
      "/fsx_3/bucket/tranx/checkpoints/perceiver_sizing/Llama3.1_70B_ViTG_layers22_dim4096_heads32_latents128_bz32_step8\n",
      "Llama3.1_70B_ViTG_layers22_dim4096_heads32_latents128_bz32_step8, checkpoint_latest=10100\n",
      "/fsx_3/bucket/tranx/checkpoints/perceiver_sizing/Llama3.1_70B_ViTG_layers26_dim4096_heads32_latents64_bz64_step4\n",
      "Llama3.1_70B_ViTG_layers26_dim4096_heads32_latents64_bz64_step4, checkpoint_latest=10300\n",
      "/fsx_3/bucket/tranx/checkpoints/perceiver_sizing/Llama3.1_70B_ViTG_layers14_dim4096_heads32_latents64_bz64_step4\n",
      "Llama3.1_70B_ViTG_layers14_dim4096_heads32_latents64_bz64_step4, checkpoint_latest=10000\n",
      "/fsx_3/bucket/tranx/checkpoints/perceiver_sizing/Llama3.1_70B_ViTG_layers22_dim4096_heads32_latents32_bz64_step4\n",
      "Llama3.1_70B_ViTG_layers22_dim4096_heads32_latents32_bz64_step4, checkpoint_latest=10800\n",
      "/fsx_3/bucket/tranx/checkpoints/perceiver_sizing/Llama3.1_70B_ViTG_layers30_dim4096_heads32_latents64_bz64_step4\n",
      "Llama3.1_70B_ViTG_layers30_dim4096_heads32_latents64_bz64_step4, checkpoint_latest=10300\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/fsx_3/bucket/tranx/checkpoints/perceiver_sizing\"\n",
    "output_dirs = glob.glob(f\"{base_dir}/Llama3*\")\n",
    "for d in output_dirs:\n",
    "    print(d)\n",
    "    name = d.split(\"/\")[-1]\n",
    "    checkpoint_latest, state = get_trainer_state(d)\n",
    "    \n",
    "    print(f\"{name}, {checkpoint_latest=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_steps': 10300,\n",
       " 'billion_text_tokens': 57,\n",
       " 'billion_modality_tokens': 51,\n",
       " 'billion_llm_tokens': 109,\n",
       " 'billion_visual_tokens': 616,\n",
       " 'last_checkpoint': 10300}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"/fsx_3/bucket/tranx/checkpoints/perceiver_sizing/Llama3.1_70B_ViTG_layers18_dim4096_heads32_latents64_bz64_step4\"\n",
    "\n",
    "checkpoint_latest, state = get_trainer_state(d)\n",
    "config = find_most_recent_config_json(output_dir)\n",
    "summary = get_train_summary(state, config)\n",
    "summary['last_checkpoint'] = checkpoint_latest\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-dos:\n",
    "- count GPU hours total\n",
    "- count GPU hours per step \n",
    "- smoothing loss\n",
    "- fit losses/evals on log scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLOPS calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1.849626e+09\n",
      "flops: 1.5e+12\n"
     ]
    }
   ],
   "source": [
    "def flops_metaclip(tokens, depth, width, mlp):\n",
    "    \n",
    "    N = depth*(width*(width + 1)*4 + 4*width + 2*(width + 1)*mlp)\n",
    "    print(f\"Number of parameters: {N:e}\")\n",
    "    \n",
    "    flops = tokens*depth*(4*width*width + 2*tokens*width + 2*mlp*width)\n",
    "    \n",
    "    return flops\n",
    "    \n",
    "flops = flops_metaclip(\n",
    "    tokens=(392/14)**2,\n",
    "    depth=50,\n",
    "    width=1536,\n",
    "    mlp=1536*5.833333334\n",
    ")\n",
    "\n",
    "print(f\"flops: {flops:.2g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_params: 3.974103e+09\n",
      "Detailed Method FLOPs: 6.245241e+12\n",
      "Simplified Method FLOPs: 6.231394e+12\n"
     ]
    }
   ],
   "source": [
    "def calculate_detailed_flops(L, d_in, d_proj, d_kv, d_ff, num_layers):\n",
    "    # Input Projector FLOPs\n",
    "    flops_in_projector = 2 * L * d_in * d_proj\n",
    "\n",
    "    # Attention FLOPs per layer\n",
    "    flops_q = 2 * L * d_proj * d_proj\n",
    "    flops_kv = 2 * L * d_proj * d_kv * 2  # Key and Value\n",
    "    flops_attention_scores = L**2 * d_kv  # QK^T\n",
    "    flops_attention_output = 2 * L * d_kv * d_proj  # Weighted sum and output projection\n",
    "\n",
    "    flops_attention_total = flops_q + flops_kv + flops_attention_scores + flops_attention_output\n",
    "\n",
    "    # Feed-Forward Network (SwiGLU) FLOPs per layer\n",
    "    flops_ff_expand = 2 * L * d_proj * d_ff  # Expansion to d_ff\n",
    "    flops_ff_reduce = 2 * L * (d_ff // 2) * d_proj  # Reduction back to d_proj\n",
    "\n",
    "    flops_ff_total = flops_ff_expand + flops_ff_reduce\n",
    "\n",
    "    # Total FLOPs per layer\n",
    "    flops_per_layer = flops_attention_total + flops_ff_total\n",
    "\n",
    "    # Total FLOPs for all layers\n",
    "    flops_all_layers = num_layers * flops_per_layer\n",
    "\n",
    "    # Total FLOPs for the entire architecture\n",
    "    return flops_in_projector + flops_all_layers\n",
    "\n",
    "def calculate_simplified_flops(L, d_in, d_proj, d_kv, d_ff, num_layers):\n",
    "    # Calculate number of parameters (N)\n",
    "    # Input projector parameters\n",
    "    params_in_projector = d_in * d_proj\n",
    "\n",
    "    # Attention mechanism parameters per layer\n",
    "    params_q = d_proj * d_proj  # Query\n",
    "    params_kv = 2 * d_proj * d_kv  # Key and Value\n",
    "    params_output = d_kv * d_proj  # Output projection\n",
    "\n",
    "    params_attention = params_q + params_kv + params_output\n",
    "\n",
    "    # Feed-forward network parameters per layer (SwiGLU)\n",
    "    params_ff_expand = d_proj * d_ff  # Expansion\n",
    "    params_ff_reduce = (d_ff // 2) * d_proj  # Reduction\n",
    "    params_ff = params_ff_expand + params_ff_reduce\n",
    "\n",
    "    # Total parameters per layer\n",
    "    params_per_layer = params_attention + params_ff\n",
    "\n",
    "    # Total parameters for all layers\n",
    "    params_all_layers = num_layers * params_per_layer\n",
    "\n",
    "    # Total parameters in the model\n",
    "    total_params = params_in_projector + params_all_layers\n",
    "    print(f\"total_params: {total_params:e}\")\n",
    "\n",
    "    # FLOPs estimation using 2 * N * D\n",
    "    return 2 * total_params * L\n",
    "\n",
    "# Example Usage\n",
    "L = 784  # Sequence length (example)\n",
    "d_in = 1536  # Input dimension\n",
    "d_proj = 4096  # Projected dimension\n",
    "d_kv = 1024  # Key/Value dimension\n",
    "d_ff = 24576  # Feed-forward expansion\n",
    "num_layers = 22  # Number of layers\n",
    "\n",
    "# Calculate FLOPs\n",
    "flops_detailed = calculate_detailed_flops(L, d_in, d_proj, d_kv, d_ff, num_layers)\n",
    "flops_simplified = calculate_simplified_flops(L, d_in, d_proj, d_kv, d_ff, num_layers)\n",
    "\n",
    "# Print results\n",
    "print(f\"Detailed Method FLOPs: {flops_detailed:e}\")\n",
    "print(f\"Simplified Method FLOPs: {flops_simplified:e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.136"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceiver_N = 784\n",
    "perceiver_D = 4*1e9\n",
    "\n",
    "perceiver_D*perceiver_N /1e12\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
