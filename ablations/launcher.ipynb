{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import socket\n",
    "import psutil\n",
    "import sys \n",
    "import os\n",
    "from typing import Any\n",
    "from functools import partial\n",
    "import json\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# lib_path = ['/fsx_0/user/tranx/experiments']\n",
    "import_paths = [\n",
    "    \"/fsx_0/user/tranx/experiments\",\n",
    "    # \"/fsx_0/user/tranx\",\n",
    "    # \"/fsx_0/user/tranx/rsync\",\n",
    "    # \"/fsx_0/user/tranx/experiments/lib\"\n",
    "]\n",
    "for path in import_paths:\n",
    "    if path not in sys.path:\n",
    "        sys.path.append(path)\n",
    "        \n",
    "from lib.ablations import Launcher\n",
    "\n",
    "      \n",
    "rsync_launcher = Launcher(\n",
    "    config_base_dir=\"/fsx_0/user/tranx/rsync/llm_mm_aligner/experiments/aws\",\n",
    "    aligner_parent_dir=\"/fsx_0/user/tranx/rsync\"\n",
    ")\n",
    "\n",
    "moe_launcher = Launcher(\n",
    "    config_base_dir=\"/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws\",\n",
    "    aligner_parent_dir=\"/fsx_0/user/tranx/moe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MM9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/mm9.2/MM9.2_Stage1_70B/LLama3.1_70B_ViTH_336px_R1_recap/241031_21_42_52_857541/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/mm9.2/MM9.2_Stage1_70B/LLama3.1_70B_ViTH_336px_R1_recap/241031_21_42_52_857541/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/mm9.2/MM9.2_Stage1_70B/LLama3.1_70B_ViTH_336px_R1_recap/241031_21_42_52_857541/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/mm9.2/MM9.2_Stage1_70B/LLama3.1_70B_ViTH_336px_R1_recap/241031_21_42_52_857541/launch_script.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', 'LLama3.1_70B_ViTH_336px_R1_recap'),\n",
      "             ('note', None),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 128),\n",
      "             ('timestamp', '2024-10-31 17:42:52'),\n",
      "             ('input_config',\n",
      "              'mm9.2/stage1/LLama3.1_70B_ViTH_336px_R1_recap_20241031.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/rsync/llm_mm_aligner/experiments/aws'),\n",
      "             ('trainer_args_overrides', None),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/MM9.2_Stage1_70B.json\n"
     ]
    }
   ],
   "source": [
    "rsync_launcher.run(\n",
    "    config=\"mm9.2/stage1/LLama3.1_70B_ViTH_336px_R1_recap_20241031.json\",\n",
    "    nodes=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46340.95001184158"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**15.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/mm9.2/MM9.2_Stage1_70B/LLama3.1_70B_ViTH_336px_R1_recap_test/241101_02_47_52_852463/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/mm9.2/MM9.2_Stage1_70B/LLama3.1_70B_ViTH_336px_R1_recap_test/241101_02_47_52_852463/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/mm9.2/MM9.2_Stage1_70B/LLama3.1_70B_ViTH_336px_R1_recap_test/241101_02_47_52_852463/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/mm9.2/MM9.2_Stage1_70B/LLama3.1_70B_ViTH_336px_R1_recap_test/241101_02_47_52_852463/launch_script.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', 'LLama3.1_70B_ViTH_336px_R1_recap_test'),\n",
      "             ('note', 'test max_tokens_in_batch'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 32),\n",
      "             ('timestamp', '2024-10-31 22:47:52'),\n",
      "             ('input_config',\n",
      "              'mm9.2/stage1/LLama3.1_70B_ViTH_336px_R1_recap_20241031.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/rsync/llm_mm_aligner/experiments/aws'),\n",
      "             ('trainer_args_overrides',\n",
      "              {'checkpoints_perception_tokenizer': '/fsx_0/checkpoints/mm9.2/MM9.2_Stage1_70B/LLama3.1_70B_ViTH_336px_R1_recap/checkpoint-600/perception_tokenizer.pt',\n",
      "               'gradient_accumulation_steps': 1,\n",
      "               'max_tokens_in_batch': 50000,\n",
      "               'max_tokens_in_batch_row': 32000,\n",
      "               'output_dir': '/fsx_0/checkpoints/mm9.2/MM9.2_Stage1_70B/LLama3.1_70B_ViTH_336px_R1_recap_test',\n",
      "               'per_device_train_batch_size': 64,\n",
      "               'resume_from_checkpoint': '/fsx_0/checkpoints/mm9.2/MM9.2_Stage1_70B/LLama3.1_70B_ViTH_336px_R1_recap/checkpoint-600/'}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/MM9.2_Stage1_70B.json\n"
     ]
    }
   ],
   "source": [
    "rsync_launcher.run(\n",
    "    config=\"mm9.2/stage1/LLama3.1_70B_ViTH_336px_R1_recap_20241031.json\",\n",
    "    nodes=32,\n",
    "    note=\"test max_tokens_in_batch\",\n",
    "    trainer_args={\n",
    "        \"checkpoints_perception_tokenizer\": \"/fsx_0/checkpoints/mm9.2/MM9.2_Stage1_70B/LLama3.1_70B_ViTH_336px_R1_recap/checkpoint-600/perception_tokenizer.pt\",\n",
    "        \"resume_from_checkpoint\": \"/fsx_0/checkpoints/mm9.2/MM9.2_Stage1_70B/LLama3.1_70B_ViTH_336px_R1_recap/checkpoint-600/\",\n",
    "        \"output_dir\": \"/fsx_0/checkpoints/mm9.2/MM9.2_Stage1_70B/LLama3.1_70B_ViTH_336px_R1_recap_test\",\n",
    "        \"per_device_train_batch_size\": 64,\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"max_tokens_in_batch_row\": 32000,\n",
    "        \"max_tokens_in_batch\": 50000,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MM10.1 Prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # stage 1\n",
    "# rsync_launcher.run(\n",
    "#     config=\"mm10.1/stage1/MH22final_70B_ViTH_336px_R1_recap_20241024_resume.json\",\n",
    "#     nodes=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/mm10.1/MM10.1_Stage1_70B/MH22final_70B_ViTH_336px_idl/241031_14_07_24_819119/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/mm10.1/MM10.1_Stage1_70B/MH22final_70B_ViTH_336px_idl/241031_14_07_24_819119/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/mm10.1/MM10.1_Stage1_70B/MH22final_70B_ViTH_336px_idl/241031_14_07_24_819119/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/mm10.1/MM10.1_Stage1_70B/MH22final_70B_ViTH_336px_idl/241031_14_07_24_819119/launch_script.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', 'MH22final_70B_ViTH_336px_idl'),\n",
      "             ('note', None),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 32),\n",
      "             ('timestamp', '2024-10-31 10:07:24'),\n",
      "             ('input_config',\n",
      "              'mm10.1/stage1/MH22final_70B_ViTH_336px_idl_20241031.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/rsync/llm_mm_aligner/experiments/aws'),\n",
      "             ('trainer_args_overrides', None),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/mm10.1_stage1.json\n"
     ]
    }
   ],
   "source": [
    "rsync_launcher.run(\n",
    "    config=\"mm10.1/stage1/MH22final_70B_ViTH_336px_idl_20241031.json\",\n",
    "    nodes=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/moe/70B_stage2_baseline/241030_21_33_34_013530/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/moe/70B_stage2_baseline/241030_21_33_34_013530/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/moe/70B_stage2_baseline/241030_21_33_34_013530/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/moe/70B_stage2_baseline/241030_21_33_34_013530/launch_script.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', '70B_stage2_baseline'),\n",
      "             ('note', None),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 32),\n",
      "             ('timestamp', '2024-10-30 17:33:34'),\n",
      "             ('input_config',\n",
      "              'mm10.1/stage2/MH22final_70B_ViTH_336px_stage2_exp30d.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/rsync/llm_mm_aligner/experiments/aws'),\n",
      "             ('trainer_args_overrides', None),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/tranx_test.json\n"
     ]
    }
   ],
   "source": [
    "# # stage 2 baseline to compare with moe\n",
    "# rsync_launcher.run(\n",
    "#     config=\"mm10.1/stage2/MH22final_70B_ViTH_336px_stage2_exp30d.json\",\n",
    "#     nodes=32\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/mm10.1/MM10.1_Stage2_70B/MH22final_70B_ViTHft_336px_stage2_r2a/241101_14_21_33_415065/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/mm10.1/MM10.1_Stage2_70B/MH22final_70B_ViTHft_336px_stage2_r2a/241101_14_21_33_415065/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/mm10.1/MM10.1_Stage2_70B/MH22final_70B_ViTHft_336px_stage2_r2a/241101_14_21_33_415065/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/mm10.1/MM10.1_Stage2_70B/MH22final_70B_ViTHft_336px_stage2_r2a/241101_14_21_33_415065/launch_script.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', 'MH22final_70B_ViTHft_336px_stage2_r2a'),\n",
      "             ('note', 'r2a'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 32),\n",
      "             ('timestamp', '2024-11-01 10:21:33'),\n",
      "             ('input_config',\n",
      "              'mm10.1/stage2/MH22final_70B_ViTHft_336px_stage2_r2a_20241101.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/rsync/llm_mm_aligner/experiments/aws'),\n",
      "             ('trainer_args_overrides', None),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/mm10.1_stage2.json\n"
     ]
    }
   ],
   "source": [
    "rsync_launcher.run(\n",
    "    config=\"mm10.1/stage2/MH22final_70B_ViTHft_336px_stage2_r2a_20241101.json\",\n",
    "    nodes=32,\n",
    "    note=\"r2a\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/mm10.1/MM10.1_Stage2_70B/MH22final_70B_ViTHft_336px_stage2_pdfa/241101_00_02_58_082508/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/mm10.1/MM10.1_Stage2_70B/MH22final_70B_ViTHft_336px_stage2_pdfa/241101_00_02_58_082508/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/mm10.1/MM10.1_Stage2_70B/MH22final_70B_ViTHft_336px_stage2_pdfa/241101_00_02_58_082508/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/mm10.1/MM10.1_Stage2_70B/MH22final_70B_ViTHft_336px_stage2_pdfa/241101_00_02_58_082508/launch_script.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', 'MH22final_70B_ViTHft_336px_stage2_pdfa'),\n",
      "             ('note', 'pdfa + idl'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 4),\n",
      "             ('timestamp', '2024-10-31 20:02:58'),\n",
      "             ('input_config',\n",
      "              'mm10.1/stage2/MH22final_70B_ViTHft_336px_stage2_20241030.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/rsync/llm_mm_aligner/experiments/aws'),\n",
      "             ('trainer_args_overrides',\n",
      "              {'output_dir': '/fsx_0/checkpoints/mm10.1/MM10.1_Stage2_70B/MH22final_70B_ViTHft_336px_stage2_pdfa',\n",
      "               'wd_data_path': ['/fsx_3/dataset01/pdfa-eng-wds-converted',\n",
      "                                '/fsx_0/user/yetian12/datasets/idl-wds_v2']}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/mm10.1_stage2.json\n"
     ]
    }
   ],
   "source": [
    "rsync_launcher.run(\n",
    "    config=\"mm10.1/stage2/MH22final_70B_ViTHft_336px_stage2_20241030.json\",\n",
    "    nodes=4,\n",
    "    note=\"pdfa + idl\",\n",
    "    trainer_args={\n",
    "        \"wd_data_path\": [\n",
    "            \"/fsx_3/dataset01/pdfa-eng-wds-converted\",\n",
    "            \"/fsx_0/user/yetian12/datasets/idl-wds_v2\"\n",
    "        ],\n",
    "        \"output_dir\": \"/fsx_0/checkpoints/mm10.1/MM10.1_Stage2_70B/MH22final_70B_ViTHft_336px_stage2_pdfa\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try canceling job 61530 if running\n",
      "Try canceling job 61529 if running\n",
      "Try canceling job 61528 if running\n",
      "Try canceling job 61527 if running\n",
      "Try canceling job 61526 if running\n",
      "Try canceling job 61525 if running\n",
      "Try canceling job 61524 if running\n",
      "Try canceling job 61523 if running\n",
      "Try canceling job 61522 if running\n"
     ]
    }
   ],
   "source": [
    "moe_launcher = Launcher(\n",
    "    config_base_dir=\"/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws\",\n",
    "    aligner_parent_dir=\"/fsx_0/user/tranx/moe\"\n",
    ")\n",
    "\n",
    "moe_launcher.cancel(\n",
    "    wandb_project_name=\"tranx_test\",\n",
    "    experiment=\"bz_x_max_tokens_no_cp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Test limit on batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_config = \"mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_8x1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_5000/241028_16_06_49_077917/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_5000/241028_16_06_49_077917/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_5000/241028_16_06_49_077917/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_5000/241028_16_06_49_077917/launch_script.sh\n",
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_13000/241028_16_06_49_146971/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_13000/241028_16_06_49_146971/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_13000/241028_16_06_49_146971/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_13000/241028_16_06_49_146971/launch_script.sh\n",
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_32000/241028_16_06_49_207884/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_32000/241028_16_06_49_207884/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_32000/241028_16_06_49_207884/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_32000/241028_16_06_49_207884/launch_script.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 5000\n",
      "/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_5000\n",
      "OrderedDict([('name', '70B_moe_22x8x2_meta_dev_resume'),\n",
      "             ('note', 'Test batch_size and max_tokens'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 8),\n",
      "             ('timestamp', '2024-10-28 12:06:49'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_8x1.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.max_tokens_in_batch': 5000,\n",
      "               'trainer_args.max_tokens_in_batch_row': 5000,\n",
      "               'trainer_args.output_dir': '/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_5000',\n",
      "               'trainer_args.per_device_train_batch_size': 8}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/tranx_test.json\n",
      "8 13000\n",
      "/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_13000\n",
      "OrderedDict([('name', '70B_moe_22x8x2_meta_dev_resume'),\n",
      "             ('note', 'Test batch_size and max_tokens'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 8),\n",
      "             ('timestamp', '2024-10-28 12:06:49'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_8x1.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.max_tokens_in_batch': 13000,\n",
      "               'trainer_args.max_tokens_in_batch_row': 13000,\n",
      "               'trainer_args.output_dir': '/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_13000',\n",
      "               'trainer_args.per_device_train_batch_size': 8}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/tranx_test.json\n",
      "8 32000\n",
      "/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_32000\n",
      "OrderedDict([('name', '70B_moe_22x8x2_meta_dev_resume'),\n",
      "             ('note', 'Test batch_size and max_tokens'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 8),\n",
      "             ('timestamp', '2024-10-28 12:06:49'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_8x1.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.max_tokens_in_batch': 32000,\n",
      "               'trainer_args.max_tokens_in_batch_row': 32000,\n",
      "               'trainer_args.output_dir': '/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1_max_tokens_32000',\n",
      "               'trainer_args.per_device_train_batch_size': 8}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_5000/241028_16_06_49_271103/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_5000/241028_16_06_49_271103/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_5000/241028_16_06_49_271103/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_5000/241028_16_06_49_271103/launch_script.sh\n",
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_13000/241028_16_06_49_333016/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_13000/241028_16_06_49_333016/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_13000/241028_16_06_49_333016/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_13000/241028_16_06_49_333016/launch_script.sh\n",
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_32000/241028_16_06_49_398957/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_32000/241028_16_06_49_398957/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_32000/241028_16_06_49_398957/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_32000/241028_16_06_49_398957/launch_script.sh\n",
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_5000/241028_16_06_49_461869/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_5000/241028_16_06_49_461869/run_log.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/tranx_test.json\n",
      "16 5000\n",
      "/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_5000\n",
      "OrderedDict([('name', '70B_moe_22x8x2_meta_dev_resume'),\n",
      "             ('note', 'Test batch_size and max_tokens'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 8),\n",
      "             ('timestamp', '2024-10-28 12:06:49'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_8x1.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.max_tokens_in_batch': 5000,\n",
      "               'trainer_args.max_tokens_in_batch_row': 5000,\n",
      "               'trainer_args.output_dir': '/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_5000',\n",
      "               'trainer_args.per_device_train_batch_size': 16}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/tranx_test.json\n",
      "16 13000\n",
      "/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_13000\n",
      "OrderedDict([('name', '70B_moe_22x8x2_meta_dev_resume'),\n",
      "             ('note', 'Test batch_size and max_tokens'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 8),\n",
      "             ('timestamp', '2024-10-28 12:06:49'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_8x1.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.max_tokens_in_batch': 13000,\n",
      "               'trainer_args.max_tokens_in_batch_row': 13000,\n",
      "               'trainer_args.output_dir': '/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_13000',\n",
      "               'trainer_args.per_device_train_batch_size': 16}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/tranx_test.json\n",
      "16 32000\n",
      "/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_32000\n",
      "OrderedDict([('name', '70B_moe_22x8x2_meta_dev_resume'),\n",
      "             ('note', 'Test batch_size and max_tokens'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 8),\n",
      "             ('timestamp', '2024-10-28 12:06:49'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_8x1.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.max_tokens_in_batch': 32000,\n",
      "               'trainer_args.max_tokens_in_batch_row': 32000,\n",
      "               'trainer_args.output_dir': '/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_16x1_max_tokens_32000',\n",
      "               'trainer_args.per_device_train_batch_size': 16}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/tranx_test.json\n",
      "32 5000\n",
      "/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_5000\n",
      "OrderedDict([('name', '70B_moe_22x8x2_meta_dev_resume'),\n",
      "             ('note', 'Test batch_size and max_tokens'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 8),\n",
      "             ('timestamp', '2024-10-28 12:06:49'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_8x1.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.max_tokens_in_batch': 5000,\n",
      "               'trainer_args.max_tokens_in_batch_row': 5000,\n",
      "               'trainer_args.output_dir': '/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_5000',\n",
      "               'trainer_args.per_device_train_batch_size': 32}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_5000/241028_16_06_49_461869/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_5000/241028_16_06_49_461869/launch_script.sh\n",
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_13000/241028_16_06_49_702547/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_13000/241028_16_06_49_702547/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_13000/241028_16_06_49_702547/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_13000/241028_16_06_49_702547/launch_script.sh\n",
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_32000/241028_16_06_49_767939/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_32000/241028_16_06_49_767939/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_32000/241028_16_06_49_767939/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_32000/241028_16_06_49_767939/launch_script.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/tranx_test.json\n",
      "32 13000\n",
      "/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_13000\n",
      "OrderedDict([('name', '70B_moe_22x8x2_meta_dev_resume'),\n",
      "             ('note', 'Test batch_size and max_tokens'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 8),\n",
      "             ('timestamp', '2024-10-28 12:06:49'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_8x1.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.max_tokens_in_batch': 13000,\n",
      "               'trainer_args.max_tokens_in_batch_row': 13000,\n",
      "               'trainer_args.output_dir': '/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_13000',\n",
      "               'trainer_args.per_device_train_batch_size': 32}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/tranx_test.json\n",
      "32 32000\n",
      "/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_32000\n",
      "OrderedDict([('name', '70B_moe_22x8x2_meta_dev_resume'),\n",
      "             ('note', 'Test batch_size and max_tokens'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 8),\n",
      "             ('timestamp', '2024-10-28 12:06:49'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_8x1.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.max_tokens_in_batch': 32000,\n",
      "               'trainer_args.max_tokens_in_batch_row': 32000,\n",
      "               'trainer_args.output_dir': '/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_32x1_max_tokens_32000',\n",
      "               'trainer_args.per_device_train_batch_size': 32}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/tranx_test.json\n"
     ]
    }
   ],
   "source": [
    "for bz in [8, 16, 32]:\n",
    "    for max_tokens in [5000, 13000, 32000]:\n",
    "        print(bz, max_tokens)\n",
    "        output = f\"/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_{bz}x1_max_tokens_{max_tokens}\"\n",
    "        print(output)\n",
    "        moe_launcher.run(\n",
    "            note = \"Test batch_size and max_tokens\",\n",
    "            config=base_config,\n",
    "            nodes=8,\n",
    "            overrides_dict={\n",
    "                \"trainer_args.output_dir\": output,\n",
    "                \"trainer_args.per_device_train_batch_size\": bz,\n",
    "                \"trainer_args.max_tokens_in_batch_row\": max_tokens,\n",
    "                \"trainer_args.max_tokens_in_batch\": max_tokens,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_32x1_cp4.json/241028_19_13_19_909836/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_32x1_cp4.json/241028_19_13_19_909836/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_32x1_cp4.json/241028_19_13_19_909836/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_32x1_cp4.json/241028_19_13_19_909836/launch_script.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', '70B_moe_22x8x2_bz_32x1_cp4'),\n",
      "             ('note', 'Test CP'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 32),\n",
      "             ('timestamp', '2024-10-28 15:13:19'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_32x1_cp4.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.context_parallel_size': 4,\n",
      "               'trainer_args.output_dir': 'mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_32x1_cp4.json'}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/tranx_test.json\n"
     ]
    }
   ],
   "source": [
    "moe_launcher = Launcher(\n",
    "    config_base_dir=\"/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws\",\n",
    "    aligner_parent_dir=\"/fsx_0/user/tranx/moe\"\n",
    ")\n",
    "\n",
    "base_config = \"mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_32x1_cp4.json\"\n",
    "\n",
    "moe_launcher.run(\n",
    "    note = \"Test CP\",\n",
    "    config=base_config,\n",
    "    nodes=32,\n",
    "    experiment=\"test_cp\",\n",
    "    overrides_dict={\n",
    "        \"trainer_args.output_dir\": \"mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_32x1_cp4.json\",\n",
    "        \"trainer_args.context_parallel_size\": 4\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_16x1_cp4.json/241028_19_16_56_528849/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_16x1_cp4.json/241028_19_16_56_528849/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_16x1_cp4.json/241028_19_16_56_528849/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_16x1_cp4.json/241028_19_16_56_528849/launch_script.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', '70B_moe_22x8x2_bz_32x1_cp4'),\n",
      "             ('note', 'Test CP'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 32),\n",
      "             ('timestamp', '2024-10-28 15:16:56'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_32x1_cp4.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.context_parallel_size': 4,\n",
      "               'trainer_args.output_dir': 'mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_16x1_cp4.json',\n",
      "               'trainer_args.per_device_train_batch_size': 16}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/tranx_test.json\n"
     ]
    }
   ],
   "source": [
    "moe_launcher.run(\n",
    "    note = \"Test CP\",\n",
    "    config=base_config,\n",
    "    nodes=32,\n",
    "    experiment=\"test_cp\",\n",
    "    overrides_dict={\n",
    "        \"trainer_args.output_dir\": \"mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_16x1_cp4.json\",\n",
    "        \"trainer_args.context_parallel_size\": 4,\n",
    "        \"trainer_args.per_device_train_batch_size\": 16\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_config = \"mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_8x1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:llm_mm_aligner.experiments.aws.launch_job:stdout is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x2/241027_03_50_53_309031/run_log.txt\n",
      "WARNING:llm_mm_aligner.experiments.aws.launch_job:stderr is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x2/241027_03_50_53_309031/run_log.txt\n",
      "WARNING:llm_mm_aligner.experiments.aws.launch_job:stdout is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x2/241027_03_50_53_309031/run_log.txt\n",
      "WARNING:llm_mm_aligner.experiments.aws.launch_job:stderr is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x2/241027_03_50_53_309031/run_log.txt\n",
      "WARNING:llm_mm_aligner.experiments.aws.launch_job:Config file written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x2/241027_03_50_53_309031/config.json\n",
      "WARNING:llm_mm_aligner.experiments.aws.launch_job:script written to: /fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x2/241027_03_50_53_309031/launch_script.sh\n"
     ]
    }
   ],
   "source": [
    "run(\n",
    "    config=base_config,\n",
    "    nodes=8,\n",
    "    overrides_dict={\n",
    "        \"trainer_args.gradient_accumulation_steps\": 2,\n",
    "        \"trainer_args.output_dir\": \"/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x2\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bz in [16, 32]:\n",
    "    run(\n",
    "        config=f\"mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_{bz}x1.json\",\n",
    "        nodes=8,\n",
    "        overrides_dict={\n",
    "            \"trainer_args.output_dir\": \"/fsx_0/checkpoints/tranx/moe/70B_moe_22x8x2_n8_bz_8x1\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers/241030_03_01_51_776499/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers/241030_03_01_51_776499/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers/241030_03_01_51_776499/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers/241030_03_01_51_776499/launch_script.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', 'LLama3_8B_ViTH_336px_8layers'),\n",
      "             ('note', 'baseline'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 4),\n",
      "             ('timestamp', '2024-10-29 23:01:51'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/stage1/pretrain_8B_Llama3_ViTH_336px_8layers.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides', None),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/mm_stage1_8B.json\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "\n",
    "moe_launcher.run(\n",
    "    note = \"baseline\",\n",
    "    config=\"mm10.1_moe/stage1/pretrain_8B_Llama3_ViTH_336px_8layers.json\",\n",
    "    nodes=4,\n",
    "    experiment=\"8B_stage1\",\n",
    "    # overrides_dict={\n",
    "    #     # \"trainer_args.output_dir\": \"mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_16x1_cp4.json\",\n",
    "    #     # \"trainer_args.context_parallel_size\": 4,\n",
    "    #     \"trainer_args.per_device_train_batch_size\": 32,\n",
    "    #     \"trainer_args.gradient_accumulation_steps\": 4\n",
    "    # }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_1x1/241030_04_02_28_283458/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_1x1/241030_04_02_28_283458/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_1x1/241030_04_02_28_283458/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_1x1/241030_04_02_28_283458/launch_script.sh\n",
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_2x1/241030_04_02_28_333573/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_2x1/241030_04_02_28_333573/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_2x1/241030_04_02_28_333573/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_2x1/241030_04_02_28_333573/launch_script.sh\n",
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_4x1/241030_04_02_28_379673/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_4x1/241030_04_02_28_379673/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_4x1/241030_04_02_28_379673/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_4x1/241030_04_02_28_379673/launch_script.sh\n",
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_4x2/241030_04_02_28_417928/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_4x2/241030_04_02_28_417928/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_4x2/241030_04_02_28_417928/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_4x2/241030_04_02_28_417928/launch_script.sh\n",
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_8x2/241030_04_02_28_458578/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_8x2/241030_04_02_28_458578/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_8x2/241030_04_02_28_458578/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_8x2/241030_04_02_28_458578/launch_script.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', 'LLama3_8B_ViTH_336px_8layers'),\n",
      "             ('note', ''),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 4),\n",
      "             ('timestamp', '2024-10-30 00:02:28'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/pretrain_8B_Llama3_ViTH_336px_8layers_moe_2x1.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.output_dir': '/fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_1x1',\n",
      "               'trainer_args.perceiver_num_activated_experts': 1,\n",
      "               'trainer_args.perceiver_num_experts': 1}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/mm_stage1_8B.json\n",
      "OrderedDict([('name', 'LLama3_8B_ViTH_336px_8layers'),\n",
      "             ('note', ''),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 4),\n",
      "             ('timestamp', '2024-10-30 00:02:28'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/pretrain_8B_Llama3_ViTH_336px_8layers_moe_2x1.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.output_dir': '/fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_2x1',\n",
      "               'trainer_args.perceiver_num_activated_experts': 1,\n",
      "               'trainer_args.perceiver_num_experts': 2}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/mm_stage1_8B.json\n",
      "OrderedDict([('name', 'LLama3_8B_ViTH_336px_8layers'),\n",
      "             ('note', ''),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 4),\n",
      "             ('timestamp', '2024-10-30 00:02:28'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/pretrain_8B_Llama3_ViTH_336px_8layers_moe_2x1.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.output_dir': '/fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_4x1',\n",
      "               'trainer_args.perceiver_num_activated_experts': 1,\n",
      "               'trainer_args.perceiver_num_experts': 4}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/mm_stage1_8B.json\n",
      "OrderedDict([('name', 'LLama3_8B_ViTH_336px_8layers'),\n",
      "             ('note', ''),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 4),\n",
      "             ('timestamp', '2024-10-30 00:02:28'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/pretrain_8B_Llama3_ViTH_336px_8layers_moe_2x1.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.output_dir': '/fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_4x2',\n",
      "               'trainer_args.perceiver_num_activated_experts': 2,\n",
      "               'trainer_args.perceiver_num_experts': 4}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/mm_stage1_8B.json\n",
      "OrderedDict([('name', 'LLama3_8B_ViTH_336px_8layers'),\n",
      "             ('note', ''),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 4),\n",
      "             ('timestamp', '2024-10-30 00:02:28'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/moe/pretrain_8B_Llama3_ViTH_336px_8layers_moe_2x1.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.output_dir': '/fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_8x2',\n",
      "               'trainer_args.perceiver_num_activated_experts': 2,\n",
      "               'trainer_args.perceiver_num_experts': 8}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/mm_stage1_8B.json\n"
     ]
    }
   ],
   "source": [
    "moe_8b_base = \"mm10.1_moe/moe/pretrain_8B_Llama3_ViTH_336px_8layers_moe_2x1.json\"\n",
    "\n",
    "# for num_experts, active_experts in [(1,1), (2,1)]: \n",
    "for num_experts, active_experts in [(1,1), (2,1), (4,1), (4,2), (8,2)]:\n",
    "    moe_launcher.run(\n",
    "        note=\"\",\n",
    "        config=moe_8b_base,\n",
    "        nodes=4,\n",
    "        experiment=\"8B_stage1\",\n",
    "        name=f\"LLama3_8B_ViTH_336px_8layers_moe_{num_experts}x{active_experts}\",\n",
    "        overrides_dict={\n",
    "            \"trainer_args.perceiver_num_experts\": num_experts,\n",
    "            \"trainer_args.perceiver_num_activated_experts\": active_experts,\n",
    "            \"trainer_args.output_dir\": f\"/fsx_0/checkpoints/tranx/Aligner_Pretrain_LLama3_8B/LLama3_8B_ViTH_336px_8layers_moe_{num_experts}x{active_experts}\"\n",
    "        }\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "2 1\n",
      "4 1\n",
      "4 2\n",
      "8 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for num_experts, active_experts in [(1,1), (2,1), (4,1), (4,2), (8,2)]:\n",
    "    print(num_experts, active_experts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upcycling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Slurm config is missing. Default values are used: {'nodes': 1, 'gpus_per_task': 8, 'cpus_per_task': 24, 'mem': 0, 'time': '168:00:00', 'account': 'midpri', 'qos': 'midpri', 'wait_all_nodes': 1, 'conda_env': '/fsx_0/shared/conda/latest', 'job_name': 'test_name', 'job_type': 'train', 'output': '', 'error': '', 'output_file': None}\n",
      "WARNING:lib.launch_job_tranx:stdout is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_stage2_upcycling_22x8x2/241030_02_44_07_156434/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:stderr is redirected to /fsx_0/checkpoints/tranx/moe/70B_moe_stage2_upcycling_22x8x2/241030_02_44_07_156434/run_log.txt\n",
      "WARNING:lib.launch_job_tranx:Config file written to: /fsx_0/checkpoints/tranx/moe/70B_moe_stage2_upcycling_22x8x2/241030_02_44_07_156434/config.json\n",
      "WARNING:lib.launch_job_tranx:script written to: /fsx_0/checkpoints/tranx/moe/70B_moe_stage2_upcycling_22x8x2/241030_02_44_07_156434/launch_script.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', '70B_moe_stage2_upcycling_22x8x2'),\n",
      "             ('note', 'load on cpu'),\n",
      "             ('job_id', None),\n",
      "             ('nodes', 32),\n",
      "             ('timestamp', '2024-10-29 22:44:07'),\n",
      "             ('input_config',\n",
      "              'mm10.1_moe/stage2/MH22final_70B_ViTH_336px_stage2_upcycling_moe_22x8x2.json'),\n",
      "             ('config_base',\n",
      "              '/fsx_0/user/tranx/moe/llm_mm_aligner/experiments/aws'),\n",
      "             ('overrides',\n",
      "              {'trainer_args.gradient_accumulation_steps': 4,\n",
      "               'trainer_args.per_device_train_batch_size': 32}),\n",
      "             ('conda_env',\n",
      "              '/fsx_0/user/ahmadyan/.conda/envs/aligner_20240822')])\n",
      "Save run log to /fsx_0/user/tranx/experiments/ablations/run_log/tranx_test.json\n"
     ]
    }
   ],
   "source": [
    "moe_launcher.run(\n",
    "    note = \"load on cpu\",\n",
    "    config=\"mm10.1_moe/stage2/MH22final_70B_ViTH_336px_stage2_upcycling_moe_22x8x2.json\",\n",
    "    nodes=32,\n",
    "    experiment=\"stage2_upcycling\",\n",
    "    overrides_dict={\n",
    "        # \"trainer_args.output_dir\": \"mm10.1_moe/moe/MH22final_70B_ViTH_336px_R1_moe_22x8x2_bz_16x1_cp4.json\",\n",
    "        # \"trainer_args.context_parallel_size\": 4,\n",
    "        \"trainer_args.per_device_train_batch_size\": 32,\n",
    "        \"trainer_args.gradient_accumulation_steps\": 4\n",
    "        \n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
