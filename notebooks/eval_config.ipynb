{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys \n",
    "lib_path = '/fsx_0/user/tranx/experiments'\n",
    "if lib_path not in sys.path:\n",
    "    sys.path.append(lib_path)\n",
    "    \n",
    "import glob \n",
    "import os\n",
    "from lib import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'infographics_w_ocr': {'train_file': '/fsx_0/dataset01/infographicsvqa/processed_val.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/infographicsvqa/processed_val.jsonl'},\n",
       " 'infographics': {'train_file': '/fsx_0/dataset01/infographicsvqa/processed_val.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/infographicsvqa/processed_val.jsonl'},\n",
       " 'mmbench': {'train_file': '/fsx_0/dataset01/mmbench/processed_dev_20231212.json',\n",
       "  'validation_file': '/fsx_0/dataset01/mmbench/processed_dev_20231212.json'},\n",
       " 'mathvista': {'train_file': '/fsx_0/dataset01/mathvista/test.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/mathvista/test.jsonl'},\n",
       " 'ai2d': {'train_file': '/fsx_0/dataset01/ai2d/ai2d_test.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/ai2d/ai2d_test.jsonl'},\n",
       " 'docvqa': {'train_file': '/fsx_0/dataset01/docvqa/val.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/docvqa/val.jsonl'},\n",
       " 'textvqa': {'train_file': '/fsx_0/dataset01/textvqa/text_vqa_val_set_updated.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/textvqa/text_vqa_val_set_updated.jsonl'},\n",
       " 'chartqa': {'train_file': '/fsx_0/dataset01/ChartQA/chartqa_test.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/ChartQA/chartqa_test.jsonl'},\n",
       " 'mmmu': {'train_file': '/fsx_0/dataset01/MMMU/mmmu_validation_v3.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/MMMU/mmmu_validation_v3.jsonl'},\n",
       " 'vqa': {'train_file': '/fsx_0/dataset01/vqa/VQAv2_train_processed.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/vqa/VQAv2_val_multians_20231118.json'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve eval dataset file\n",
    "data_files = {}\n",
    "for f in glob.glob(\"/fsx_0/user/tranx/adel_prod/llm_mm_aligner/experiments/aws_adel/eval_sft_babyLora_emb65/eval_*.json\"):\n",
    "    conf = utils.read_json(f)\n",
    "    bm = f.split(\"/\")[-1].replace(\"eval_\", \"\").replace(\".json\", \"\")\n",
    "    # print(bm)\n",
    "    data_files[bm] = {\n",
    "        \"train_file\": conf[\"eval_args\"][\"train_file\"],\n",
    "        \"validation_file\": conf[\"eval_args\"][\"validation_file\"]\n",
    "    }\n",
    "\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'infographics_w_ocr': {'train_file': '/fsx_0/dataset01/infographicsvqa/processed_val.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/infographicsvqa/processed_val.jsonl'},\n",
       " 'infographics': {'train_file': '/fsx_0/dataset01/infographicsvqa/processed_val.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/infographicsvqa/processed_val.jsonl'},\n",
       " 'mmbench': {'train_file': '/fsx_0/dataset01/mmbench/processed_dev_20231212.json',\n",
       "  'validation_file': '/fsx_0/dataset01/mmbench/processed_dev_20231212.json'},\n",
       " 'mathvista': {'train_file': '/fsx_0/dataset01/mathvista/test.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/mathvista/test.jsonl'},\n",
       " 'ai2d': {'train_file': '/fsx_0/dataset01/ai2d/ai2d_test.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/ai2d/ai2d_test.jsonl'},\n",
       " 'docvqa': {'train_file': '/fsx_0/dataset01/docvqa/val.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/docvqa/val.jsonl'},\n",
       " 'textvqa': {'train_file': '/fsx_0/dataset01/textvqa/text_vqa_val_set_updated.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/textvqa/text_vqa_val_set_updated.jsonl'},\n",
       " 'chartqa': {'train_file': '/fsx_0/dataset01/ChartQA/chartqa_test.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/ChartQA/chartqa_test.jsonl'},\n",
       " 'mmmu': {'train_file': '/fsx_0/dataset01/MMMU/mmmu_validation_v3.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/MMMU/mmmu_validation_v3.jsonl'},\n",
       " 'vqa': {'train_file': '/fsx_0/dataset01/vqa/VQAv2_train_processed.jsonl',\n",
       "  'validation_file': '/fsx_0/dataset01/vqa/VQAv2_val_multians_20231118.json'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmbench\n",
      "OrderedDict([('eval_only', True), ('eval_args', OrderedDict([('resume_from_checkpoint', 'CHECKPOINT_PATH'), ('num_beams', 1), ('model_parallel_size', 8), ('train_file', '/fsx_0/dataset01/mmbench/processed_dev_20231212.json'), ('validation_file', '/fsx_0/dataset01/mmbench/processed_dev_20231212.json'), ('max_length', 50), ('max_seq_len', 100), ('max_new_tokens', 32), ('dataloader_num_workers', 8), ('batch_size_generation', 8), ('perception_tokenizer_attention_dropout_p', 0), ('perception_tokenizer_hidden_dropout_p', 0), ('instr_prompt', 'mmbench'), ('task_type', 'instruction_tune'), ('generation_task', 'MMBenchGenerationTask'), ('instruction_model_type', 'MetaAiTikTokv4ChatFormat'), ('add_bos_token', False), ('add_eos_token', False), ('eval_only', True), ('stopping_token_ids', ''), ('tb_logdir', 'TB_LOGDIR'), ('eval_ckpt', 'EVAL_CHECKPOINT'), ('eval_type', 'eval_mmbench'), ('output_dir', 'OUTPUT_DIR'), ('logging_dir', 'LOGGING_DIR'), ('using_fsdp2', False)]))])\n",
      "docvqa\n",
      "OrderedDict([('eval_only', True), ('eval_args', OrderedDict([('resume_from_checkpoint', 'CHECKPOINT_PATH'), ('num_beams', 1), ('model_parallel_size', 8), ('train_file', '/fsx_0/dataset01/docvqa/val.jsonl'), ('validation_file', '/fsx_0/dataset01/docvqa/val.jsonl'), ('max_length', 30), ('max_new_tokens', 32), ('min_new_tokens', 1), ('max_seq_len', 100), ('dataloader_num_workers', 4), ('batch_size_generation', 4), ('perception_tokenizer_attention_dropout_p', 0), ('perception_tokenizer_hidden_dropout_p', 0), ('instr_prompt', 'docvqa'), ('task_type', 'instruction_tune'), ('generation_task', 'DocVQAGenerationTask'), ('instruction_model_type', 'MetaAiTikTokv4ChatFormat'), ('add_bos_token', False), ('add_eos_token', False), ('eval_only', True), ('stopping_token_ids', ''), ('tb_logdir', 'TB_LOGDIR'), ('eval_ckpt', 'EVAL_CHECKPOINT'), ('eval_type', 'eval_docvqa'), ('output_dir', 'OUTPUT_DIR'), ('logging_dir', 'LOGGING_DIR'), ('using_fsdp2', False)]))])\n",
      "chartqa\n",
      "OrderedDict([('eval_only', True), ('eval_args', OrderedDict([('resume_from_checkpoint', 'CHECKPOINT_PATH'), ('num_beams', 1), ('model_parallel_size', 8), ('max_parallel_model_loading', 8), ('train_file', '/fsx_0/dataset01/ChartQA/chartqa_test.jsonl'), ('validation_file', '/fsx_0/dataset01/ChartQA/chartqa_test.jsonl'), ('max_length', 200), ('max_seq_len', 100), ('dataloader_num_workers', 8), ('batch_size_generation', 4), ('perception_tokenizer_attention_dropout_p', 0), ('perception_tokenizer_hidden_dropout_p', 0), ('instruction_model_type', 'MetaAiTikTokv4ChatFormat'), ('instr_prompt', 'chartqa'), ('task_type', 'instruction_tune'), ('generation_task', 'ChartQAGenerationTask'), ('add_bos_token', False), ('add_eos_token', False), ('eval_only', True), ('stopping_token_ids', ''), ('tb_logdir', 'TB_LOGDIR'), ('eval_ckpt', 'EVAL_CHECKPOINT'), ('eval_type', 'eval_chartqa'), ('output_dir', 'OUTPUT_DIR'), ('logging_dir', 'LOGGING_DIR'), ('using_fsdp2', False)]))])\n",
      "mmmu\n",
      "OrderedDict([('eval_only', True), ('eval_args', OrderedDict([('resume_from_checkpoint', 'CHECKPOINT_PATH'), ('num_beams', 1), ('model_parallel_size', 8), ('train_file', '/fsx_0/dataset01/MMMU/mmmu_validation_v3.jsonl'), ('validation_file', '/fsx_0/dataset01/MMMU/mmmu_validation_v3.jsonl'), ('max_length', 50), ('max_seq_len', 1024), ('max_new_tokens', 1024), ('dataloader_num_workers', 4), ('batch_size_generation', 16), ('perception_tokenizer_attention_dropout_p', 0), ('perception_tokenizer_hidden_dropout_p', 0), ('instr_prompt', 'mmmu'), ('task_type', 'instruction_tune'), ('generation_task', 'MMMUGenerationTask'), ('add_bos_token', False), ('add_eos_token', False), ('eval_only', True), ('stopping_token_ids', ''), ('repetition_penalty', 1.05), ('tb_logdir', 'TB_LOGDIR'), ('eval_ckpt', 'EVAL_CHECKPOINT'), ('eval_type', 'eval_mmmu'), ('output_dir', 'OUTPUT_DIR'), ('logging_dir', 'LOGGING_DIR'), ('using_fsdp2', False)]))])\n",
      "infographics_w_ocr\n",
      "OrderedDict([('eval_only', True), ('eval_args', OrderedDict([('resume_from_checkpoint', 'CHECKPOINT_PATH'), ('model_parallel_size', 8), ('num_beams', 1), ('train_file', '/fsx_0/dataset01/infographicsvqa/processed_val.jsonl'), ('validation_file', '/fsx_0/dataset01/infographicsvqa/processed_val.jsonl'), ('dataloader_num_workers', 4), ('max_length', 64), ('max_seq_len', 64), ('batch_size_generation', 2), ('perception_tokenizer_attention_dropout_p', 0), ('perception_tokenizer_hidden_dropout_p', 0), ('instr_prompt', 'infographics_ocr'), ('task_type', 'instruction_tune'), ('generation_task', 'InfographicsVQAGenerationTask'), ('add_bos_token', False), ('add_eos_token', False), ('eval_only', True), ('stopping_token_ids', ''), ('tb_logdir', 'TB_LOGDIR'), ('eval_ckpt', 'EVAL_CHECKPOINT'), ('eval_type', 'eval_infographics_w_ocr'), ('output_dir', 'OUTPUT_DIR'), ('logging_dir', 'LOGGING_DIR'), ('using_fsdp2', False)]))])\n",
      "vqa\n",
      "OrderedDict([('eval_only', True), ('eval_args', OrderedDict([('resume_from_checkpoint', 'CHECKPOINT_PATH'), ('num_beams', 1), ('model_parallel_size', 8), ('max_eval_samples', 25000), ('train_file', '/fsx_0/dataset01/vqa/VQAv2_train_processed.jsonl'), ('validation_file', '/fsx_0/dataset01/vqa/VQAv2_val_multians_20231118.json'), ('max_length', 30), ('max_new_tokens', 32), ('min_new_tokens', 1), ('max_seq_len', 100), ('dataloader_num_workers', 4), ('batch_size_generation', 16), ('perception_tokenizer_attention_dropout_p', 0), ('perception_tokenizer_hidden_dropout_p', 0), ('instr_prompt', 'vqa'), ('task_type', 'instruction_tune'), ('instruction_model_type', 'MetaAiTikTokv4ChatFormat'), ('generation_task', 'InstructionGenerationTask'), ('add_bos_token', False), ('add_eos_token', False), ('eval_only', True), ('stopping_token_ids', ''), ('n_multi_transformer_blocks', 0), ('tb_logdir', 'TB_LOGDIR'), ('eval_ckpt', 'EVAL_CHECKPOINT'), ('eval_type', 'eval_vqa'), ('output_dir', 'OUTPUT_DIR'), ('logging_dir', 'LOGGING_DIR'), ('using_fsdp2', False)]))])\n",
      "infographics\n",
      "OrderedDict([('eval_only', True), ('eval_args', OrderedDict([('resume_from_checkpoint', 'CHECKPOINT_PATH'), ('model_parallel_size', 8), ('num_beams', 1), ('train_file', '/fsx_0/dataset01/infographicsvqa/processed_val.jsonl'), ('validation_file', '/fsx_0/dataset01/infographicsvqa/processed_val.jsonl'), ('dataloader_num_workers', 4), ('max_length', 64), ('max_seq_len', 64), ('batch_size_generation', 2), ('perception_tokenizer_attention_dropout_p', 0), ('perception_tokenizer_hidden_dropout_p', 0), ('instr_prompt', 'infographics'), ('task_type', 'instruction_tune'), ('generation_task', 'InfographicsVQAGenerationTask'), ('add_bos_token', False), ('add_eos_token', False), ('eval_only', True), ('stopping_token_ids', ''), ('tb_logdir', 'TB_LOGDIR'), ('eval_ckpt', 'EVAL_CHECKPOINT'), ('eval_type', 'eval_infographics'), ('output_dir', 'OUTPUT_DIR'), ('logging_dir', 'LOGGING_DIR'), ('using_fsdp2', False)]))])\n",
      "mathvista\n",
      "OrderedDict([('eval_only', True), ('gpu_capability', 'GPU_A100_HOST'), ('eval_args', OrderedDict([('resume_from_checkpoint', 'CHECKPOINT_PATH'), ('num_beams', 1), ('model_parallel_size', 8), ('train_file', '/fsx_0/dataset01/mathvista/test.jsonl'), ('validation_file', '/fsx_0/dataset01/mathvista/test.jsonl'), ('max_length', 200), ('max_seq_len', 100), ('dataloader_num_workers', 4), ('batch_size_generation', 4), ('perception_tokenizer_attention_dropout_p', 0), ('perception_tokenizer_hidden_dropout_p', 0), ('instr_prompt', 'mathvista'), ('task_type', 'instruction_tune'), ('generation_task', 'MathVistaGenerationTask'), ('add_bos_token', False), ('add_eos_token', False), ('eval_only', True), ('stopping_token_ids', ''), ('tb_logdir', 'TB_LOGDIR'), ('eval_ckpt', 'EVAL_CHECKPOINT'), ('eval_type', 'eval_mathvista'), ('output_dir', 'OUTPUT_DIR'), ('logging_dir', 'LOGGING_DIR'), ('using_fsdp2', False)]))])\n",
      "ai2d\n",
      "OrderedDict([('eval_only', True), ('eval_args', OrderedDict([('resume_from_checkpoint', 'CHECKPOINT_PATH'), ('num_beams', 1), ('model_parallel_size', 8), ('train_file', '/fsx_0/dataset01/ai2d/ai2d_test.jsonl'), ('validation_file', '/fsx_0/dataset01/ai2d/ai2d_test.jsonl'), ('max_length', 200), ('max_seq_len', 10), ('dataloader_num_workers', 8), ('batch_size_generation', 8), ('perception_tokenizer_attention_dropout_p', 0), ('perception_tokenizer_hidden_dropout_p', 0), ('instr_prompt', 'ai2d'), ('task_type', 'instruction_tune'), ('generation_task', 'AI2DGenerationTask'), ('add_bos_token', False), ('add_eos_token', False), ('eval_only', True), ('stopping_token_ids', ''), ('n_multi_transformer_blocks', 0), ('tb_logdir', 'TB_LOGDIR'), ('eval_ckpt', 'EVAL_CHECKPOINT'), ('eval_type', 'eval_ai2d'), ('output_dir', 'OUTPUT_DIR'), ('logging_dir', 'LOGGING_DIR'), ('using_fsdp2', False)]))])\n",
      "textvqa\n",
      "OrderedDict([('eval_only', True), ('eval_args', OrderedDict([('resume_from_checkpoint', 'CHECKPOINT_PATH'), ('num_beams', 1), ('model_parallel_size', 8), ('max_parallel_model_loading', 8), ('train_file', '/fsx_0/dataset01/textvqa/text_vqa_val_set_updated.jsonl'), ('validation_file', '/fsx_0/dataset01/textvqa/text_vqa_val_set_updated.jsonl'), ('max_length', 200), ('max_seq_len', 100), ('dataloader_num_workers', 4), ('batch_size_generation', 4), ('perception_tokenizer_attention_dropout_p', 0), ('perception_tokenizer_hidden_dropout_p', 0), ('instr_prompt', 'textvqa'), ('task_type', 'instruction_tune'), ('generation_task', 'TextVQAGenerationTask'), ('add_bos_token', False), ('add_eos_token', False), ('eval_only', True), ('stopping_token_ids', ''), ('tb_logdir', 'TB_LOGDIR'), ('eval_ckpt', 'EVAL_CHECKPOINT'), ('eval_type', 'eval_textvqa'), ('output_dir', 'OUTPUT_DIR'), ('logging_dir', 'LOGGING_DIR'), ('using_fsdp2', False)]))])\n"
     ]
    }
   ],
   "source": [
    "# update eval config overwrites \n",
    "eval_dir = \"/fsx_0/user/tranx/rsync/llm_mm_aligner/experiments/aws/mm10/stage1/eval_overwrite_f587797729-watcher-2024-08-02\"\n",
    "# eval_dir = \"/fsx_0/user/tranx/rsync/llm_mm_aligner/experiments/aws/mm10/stage2/eval_overwrite_f581140842-watcher-2024-07-14\"\n",
    "new_dir = eval_dir \n",
    "\n",
    "for file in glob.glob(f\"{eval_dir}/*.json\"):\n",
    "    benchmark = os.path.basename(file).replace(\".json\", \"\").replace(\"eval_\", \"\")\n",
    "    config = utils.read_json(file)\n",
    "    \n",
    "    for k in [\"scheduler_type\", \"num_gpus\", \"num_nodes\"]:\n",
    "        if k in config:\n",
    "            config.pop(k)\n",
    "        \n",
    "    config[\"eval_args\"].update({\n",
    "        \"using_fsdp2\": False,\n",
    "        \"output_dir\": \"OUTPUT_DIR\",\n",
    "        \"resume_from_checkpoint\": \"CHECKPOINT_PATH\",\n",
    "        \"logging_dir\": \"LOGGING_DIR\",\n",
    "        \"tb_logdir\": \"TB_LOGDIR\",\n",
    "        \"eval_ckpt\": \"EVAL_CHECKPOINT\",\n",
    "        \"train_file\": data_files[benchmark][\"train_file\"],\n",
    "        \"validation_file\": data_files[benchmark][\"validation_file\"]\n",
    "    })\n",
    "        \n",
    "    print(benchmark)\n",
    "    print(config)\n",
    "    new_file = f\"{new_dir}/eval_{benchmark}.json\"\n",
    "    utils.save_json(config, new_file)\n",
    "    \n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
