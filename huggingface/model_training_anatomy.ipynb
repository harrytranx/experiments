{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host name: h100-st-p548xlarge-10\n",
      "Number of CPUs: 192\n",
      "Total memory (GB): 1999.96\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# BOILER PLATE, MUST BE RUN ON SUBMIT NODE\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import socket\n",
    "import psutil\n",
    "import torch \n",
    "\n",
    "hostname = socket.gethostname()\n",
    "print(\"Host name:\", hostname)\n",
    "num_cpus = psutil.cpu_count()\n",
    "print(\"Number of CPUs:\", num_cpus)\n",
    "total_memory = psutil.virtual_memory().total / (1024 ** 3)\n",
    "print(\"Total memory (GB):\", round(total_memory, 2))\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "import pynvml\n",
    "\n",
    "def print_gpu_utilization(devices=0):\n",
    "    pynvml.nvmlInit()\n",
    "    if not isinstance(devices, list):\n",
    "        devices = [devices]\n",
    "    \n",
    "    for device in devices:\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(device)\n",
    "        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        print(f\"GPU-{device} memory occupied: {info.used//1024**2} MB.\")\n",
    "    \n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial\n",
      "GPU-0 memory occupied: 3657 MB.\n",
      "GPU-1 memory occupied: 567 MB.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial\")\n",
    "print_gpu_utilization([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After loading tiny tensor and the kernels\n",
      "GPU-0 memory occupied: 3657 MB.\n",
      "GPU-1 memory occupied: 567 MB.\n"
     ]
    }
   ],
   "source": [
    "print(\"After loading tiny tensor and the kernels\")\n",
    "torch.ones((1, 1)).to(\"cuda\")\n",
    "print_gpu_utilization([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer, logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU-0 memory occupied: 3657 MB.\n",
      "GPU-1 memory occupied: 567 MB.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-large-uncased\").to(\"cuda\")\n",
    "print_gpu_utilization([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len, dataset_size = 512, 512\n",
    "\n",
    "dummy_data = {\n",
    "    \"input_ids\": np.random.randint(100, 30000, (dataset_size, seq_len)),\n",
    "    \"labels\": np.random.randint(0, 1, (dataset_size)),\n",
    "}\n",
    "\n",
    "dummy_data['input_ids'].shape, dummy_data['labels'].shape\n",
    "\n",
    "ds = Dataset.from_dict(dummy_data)\n",
    "ds.set_format(\"pt\")\n",
    "\n",
    "default_args = {\n",
    "    \"output_dir\": \"tmp\",\n",
    "    \"eval_strategy\": \"steps\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hpcaas/.mounts/fs-036153e63d56f4dc2/home/tranx/conda/envs/aws/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 34.1721, 'train_samples_per_second': 14.983, 'train_steps_per_second': 0.468, 'train_loss': 0.20920303463935852, 'epoch': 1.0}\n",
      "Time: 34.17\n",
      "Samples/second: 14.98\n",
      "GPU-0 memory occupied: 13483 MB.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(per_device_train_batch_size=4, **default_args)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hpcaas/.mounts/fs-036153e63d56f4dc2/home/tranx/conda/envs/aws/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 6.9119, 'train_samples_per_second': 74.076, 'train_steps_per_second': 1.157, 'train_loss': 0.04293365031480789, 'epoch': 1.0}\n",
      "Time: 6.91\n",
      "Samples/second: 74.08\n",
      "GPU-0 memory occupied: 16491 MB.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(per_device_train_batch_size=8, **default_args)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hpcaas/.mounts/fs-036153e63d56f4dc2/home/tranx/conda/envs/aws/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 9.2333, 'train_samples_per_second': 55.452, 'train_steps_per_second': 0.433, 'train_loss': 0.005023417994379997, 'epoch': 1.0}\n",
      "Time: 9.23\n",
      "Samples/second: 55.45\n",
      "GPU-0 memory occupied: 23461 MB.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(per_device_train_batch_size=16, **default_args)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
