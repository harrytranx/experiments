{
    "eval_args": {
        "layer_ckpt": "all",
        "model_name_or_path": "/fsx_0/checkpoints/llama3/mh19",
        "tokenizer_path": "/fsx_0/checkpoints/llama3/mh19",
        "use_metaformers": true,
        "block_sparse": true,
        "modality_tokenizer_name": "/fsx_0/checkpoints/clip/MetaCLIP-BigG-336-0712",
        "checkpoints_perception_tokenizer": "/fsx_0/checkpoints/aligner/mm9_stage2/MH19_336px_128nodes_exp28/checkpoint-5800/perception_tokenizer.pt",
        "model_parallel_size": 8,
        "max_parallel_model_loading": 8,
        "freeze_perception": true,
        "freeze_tokenizer": true,
        "freeze_lm": true,
        "neftune_noise_alpha": 10,
        "lora": true,
        "lora_rank": 8,
        "lora_alpha": 32,
        "lora_dropout": 0.1,
        "lora_target_modules": "['q_proj', 'v_proj', 'k_proj', 'o_proj', 'ffn']",
        "lora_tokenizer": true,
        "lora_tokenizer_rank": 8,
        "lora_tokenizer_alpha": 32,
        "lora_tokenizer_dropout": 0.1,
        "lora_tokenizer_target_modules": "['to_q', 'to_k', 'to_v', 'to_o', 'ff.w12', 'ff.w3']",
        "parallelize_perception_tokenizer": false,
        "use_face_detector": false,
        "task_type": "instruction_tune",
        "instr_prompt": "mmbench",
        "instruction_model_type": "MetaAiTikTokv4ChatFormat",
        "n_prefix_embs": 65,
        "perceiver_num_latents": 64,
        "use_hive_dataset": false,
        "add_bos_token": false,
        "add_eos_token": false,
        "output_dir": "/fsx_0/checkpoints/tranx/MM9-SFT-70B/MH19_336px_8800_BabyLora_r17e/tensorboard",
        "vision_hidden_state_layer": -2,
        "do_train": false,
        "logging_steps": 10,
        "max_seq_len": 100,
        "overwrite_output_dir": null,
        "num_train_epochs": 3,
        "logging_first_step": null,
        "per_device_train_batch_size": 1,
        "per_device_eval_batch_size": 1,
        "gradient_accumulation_steps": 2,
        "dataloader_pin_memory": false,
        "learning_rate": 0.0001,
        "adam_beta1": 0.9,
        "adam_beta2": 0.95,
        "weight_decay": 0.1,
        "warmup_steps": 0,
        "lr_scheduler_type": "cosine",
        "remove_unused_columns": false,
        "log_level": "info",
        "log_level_replica": "info",
        "run_name": "$name",
        "half_precision_backend": "auto",
        "optim": "adamw_torch",
        "report_to": "tensorboard",
        "modality": "image",
        "tokenizer_type": "PerceiverV3",
        "perception_tokenizer_num_layers": 22,
        "perceiver_dim_override": 4096,
        "perceiver_num_heads": 32,
        "perceiver_num_kv_heads": 8,
        "perceiver_collapse_chunks": false,
        "perceiver_enable_query_aware": false,
        "perception_tokenizer_attention_dropout_p": 0,
        "perception_tokenizer_hidden_dropout_p": 0,
        "bf16": true,
        "evaluation_strategy": "no",
        "metric_for_best_model": "eval_loss",
        "greater_is_better": false,
        "seed": 2023,
        "custom_FSDP": null,
        "num_image_chunks": 27,
        "max_total_image_chunks": 81,
        "max_tokens_in_batch_row": 5000,
        "max_tokens_in_batch": 5000,
        "add_resized_image": true,
        "chunk_size": 336,
        "resize_longest": true,
        "pad_to_full_batch": true,
        "resume_from_checkpoint": "/fsx_0/checkpoints/tranx/MM9-SFT-70B/MH19_336px_8800_BabyLora_r17e/checkpoint-1000",
        "num_beams": 1,
        "logging_dir": "/fsx_0/checkpoints/tranx/MM9-SFT-70B/MH19_336px_8800_BabyLora_r17e/tensorboard",
        "tb_logdir": "/fsx_0/checkpoints/tranx/MM9-SFT-70B/MH19_336px_8800_BabyLora_r17e/tensorboard",
        "eval_type": "mmbench",
        "eval_ckpt": "1000",
        "filetype": "jsonlines",
        "train_file": "/fsx_0/dataset01/mmbench/processed_dev_20231212.json",
        "validation_file": "/fsx_0/dataset01/mmbench/processed_dev_20231212.json",
        "generation_task": "MMBenchGenerationTask",
        "generation_output_dir": "",
        "max_length": 50,
        "max_new_tokens": 32,
        "dataloader_num_workers": 4,
        "batch_size_generation": 2,
        "eval_only": true,
        "stopping_token_ids": "",
        "n_multi_transformer_blocks": 0,
        "onbox_dpp_server_num_worker_threads": 8,
        "lora_checkpoint": "/fsx_0/checkpoints/tranx/MM9-SFT-70B/MH19_336px_8800_BabyLora_r17e/checkpoint-1000",
        "lora_tokenizer_checkpoint": "/fsx_0/checkpoints/tranx/MM9-SFT-70B/MH19_336px_8800_BabyLora_r17e/checkpoint-1000/adapter_tokenizer"
    },
    "fsdp_config": {
        "fsdp_transformer_layer_cls_to_wrap": [
            "EncoderLayer",
            "MMTokenizer",
            "PerceptionTokenizer",
            "MetaFormersBlock",
            "LoraLinear"
        ],
        "forward_prefetch": false,
        "backward_prefetch": "backward_pre",
        "limit_all_gathers": true,
        "fsdp": [
            "full_shard",
            "auto_wrap"
        ]
    }
}