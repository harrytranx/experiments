{
    "scheduler_type": "mast_grand_teton",
    "hpc_job_oncall": "sg_scene_ai",
    "num_gpus": 8,
    "num_nodes": 1,
    "eval_args": {
        "model_name_or_path": "/fsx_0/checkpoints/llama3/mh19",
        "tokenizer_path": "/fsx_0/checkpoints/llama3/mh19",
        "modality_tokenizer_name": "/fsx_0/checkpoints/clip/MetaCLIP-BigG-336-0712",
        "resume_from_checkpoint": "/fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp30/checkpoint-8600",
        "checkpoints_perception_tokenizer": "/fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp30/checkpoint-8600/perception_tokenizer.pt",

        "num_beams": 1,
        "model_parallel_size": 8,

        "use_metaformers": true,
        "block_sparse": true,
        "use_te": true,
        "logging_dir":"/fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp30/tensorboard",
        "output_dir":"/fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp30/tensorboard",
        "tb_logdir":"/fsx_0/checkpoints/tranx/MM9-Stage2-70B/MH19_336px_128nodes_exp30/tensorboard",
        "eval_ckpt":"8600",
        
        "filetype": "jsonlines",
        "eval_type":"mmmu",
        "train_file": "/fsx_0/dataset01/MMMU/mmmu_validation_v3.jsonl",
        "validation_file": "/fsx_0/dataset01/MMMU/mmmu_validation_v3.jsonl",
        "instr_prompt": "mmmu",
        "task_type": "instruction_tune",
        "generation_task": "MMMUGenerationTask",

        "max_length": 50,
        "max_seq_len": 1024,
        "max_new_tokens": 1024,
        "repetition_penalty": 1.05,

        "dataloader_num_workers": 4,
        "batch_size_generation": 16,
        "perception_tokenizer_attention_dropout_p": 0,
        "perception_tokenizer_hidden_dropout_p": 0,
        
        "instruction_model_type": "MetaAiTikTokv4ChatFormat",
        "add_bos_token": false,
        "add_eos_token": false,
        "eval_only": true,
        "stopping_token_ids": "",
        "n_multi_transformer_blocks": 0,

        "max_parallel_model_loading": 8,
        "freeze_perception": true,
        "freeze_tokenizer": true,
        "freeze_lm": true,
        "use_face_detector": false,
        "n_prefix_embs": 65,
        "perceiver_num_latents": 64,
        "hive_batch_size": 16,
        "onbox_num_python_transform_workers": 4,
        "onbox_dpp_server_num_worker_threads": 8,
        "onbox_dpp_server_worker_buffer_size": 64,
        "onbox_dpp_client_num_prefetch_threads": 4,
        "onbox_dpp_client_prefetch_capacity": 64,
        "use_hive_dataset": false,

        "vision_hidden_state_layer": -2,
        "do_train": false,
        "logging_steps": 10,
    
        "overwrite_output_dir": null,
        "num_train_epochs": 1,
        "logging_first_step": null,
        "per_device_train_batch_size": 32,
        "per_device_eval_batch_size": 48,
        "gradient_accumulation_steps": 2,
        "dataloader_pin_memory": false,
        "learning_rate": 0.0001,
        "adam_beta1": 0.9,
        "adam_beta2": 0.95,
        "weight_decay": 0.1,
        "warmup_steps": 200,
        "lr_scheduler_type": "cosine",
        "remove_unused_columns": false,
        "log_level": "info",
        "log_level_replica": "info",
        "run_name": "$name",
        "half_precision_backend": "auto",
        "optim": "adamw_torch",
        "report_to": "tensorboard",
        "modality": "image",
        "tokenizer_type": "PerceiverV3",
        "perception_tokenizer_num_layers": 22,
        "perceiver_dim_override": 4096,
        "perceiver_num_heads": 32,
        "perceiver_num_kv_heads": 8,
        "perceiver_collapse_chunks": false,
        "perceiver_enable_query_aware": false,
        "bf16": true,
        "save_strategy": "steps",
        "save_steps": 200,
        "evaluation_strategy": "no",
        "eval_steps": 250,
        "metric_for_best_model": "eval_loss",
        "greater_is_better": false,
        "seed": 2023,
        "custom_FSDP": null,
        "num_image_chunks": 3,
        "max_tokens_in_batch_row": 32000,
        "max_tokens_in_batch": 32000,
        "add_resized_image": true,
        "chunk_size": 336,
        "resize_longest": true,
        "pad_to_full_batch": true
        
    }
}

